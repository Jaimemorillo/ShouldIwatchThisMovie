{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nice-movie-model.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jaimemorillo/ShouldIwatchThisMovie/blob/master/nice_movie_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "X4FsDixDIzQ9",
        "colab_type": "code",
        "outputId": "4e3950aa-3e1d-4fb2-c394-421f73711cc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "rl4LFkMQoya5",
        "colab_type": "code",
        "outputId": "98a7e7fb-f22c-4830-8867-a58a18788462",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 833
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import time\n",
        "import numpy as np\n",
        "import json\n",
        "import nltk\n",
        "\n",
        "nltk.download(\"popular\")\n",
        "print(tf.__version__)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "1.13.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "T1urQMU5YkEC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "dataover = pd.read_csv(\"gdrive/My Drive/TFG/tmdb_spanish_overview.csv\",sep='#',lineterminator='\\n')\n",
        "taste = pd.read_csv(\"gdrive/My Drive/TFG/tmdb_spanish_Jaime2.csv\",sep=';', encoding='utf-8')\n",
        "credits = pd.read_csv(\"gdrive/My Drive/TFG/tmdb_5000_credits.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ZKXfq0GiJq6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "taste = taste[~taste['id'].str.contains('/')]\n",
        "taste['id'] = taste['id'].astype(int)\n",
        "credits['movie_id'] = credits['movie_id'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D4mTpGIoaAq1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Merge taste and credits\n",
        "\n",
        "data = taste.merge(dataover[['id','overview']], left_on='id', right_on='id')\n",
        "data = data.merge(credits[['movie_id','cast','crew']], left_on='id', right_on='movie_id')\n",
        "data.drop(['movie_id'],axis=1, inplace= True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lhpyV6W4gXPh",
        "colab_type": "code",
        "outputId": "e63a9798-f22a-41b9-e542-55391530b7e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[~pd.isna(data.overview)]\n",
        "len(data)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4406"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "metadata": {
        "id": "0zId8PUhkQX0",
        "colab_type": "code",
        "outputId": "a402b4f6-7630-4b54-e2ea-3152fb360b50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "data = data.dropna(subset=['like'])\n",
        "data['like'] = data['like'].astype(int)\n",
        "data.reset_index(inplace=True,drop=True)\n",
        "len(data)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "816"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "metadata": {
        "id": "-l7_kcrl_Iv4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Clean overviews ver que ocurre con deadpool y deadpool 2 \n",
        "\n",
        "import string\n",
        "\n",
        "stop_words = pd.read_csv(\"gdrive/My Drive/TFG/stopwords-es.txt\",header=None)\n",
        "stop_words = stop_words[0].tolist() + ['secuela']\n",
        "\n",
        "def normalize(s):\n",
        "    replacements = (\n",
        "        (\"á\", \"a\"),\n",
        "        (\"é\", \"e\"),\n",
        "        (\"í\", \"i\"),\n",
        "        (\"ó\", \"o\"),\n",
        "        (\"ú\", \"u\"),\n",
        "    )\n",
        "    for a, b in replacements:\n",
        "        s = s.replace(a, b).replace(a.upper(), b.upper())\n",
        "    return s\n",
        "\n",
        "def clean_overview(x):\n",
        "    x = normalize(x.lower())\n",
        "    x = x.translate(str.maketrans('','',string.punctuation))\n",
        "    x = x.translate(str.maketrans('','','1234567890ªº'))\n",
        "    return x\n",
        "\n",
        "def delete_stop_words(x):\n",
        "    words = x.split(' ')\n",
        "    words = [word for word in words if word not in stop_words]\n",
        "    x = str(' '.join(words))\n",
        "    return x\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hSEAKnpeVyfk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Steaming overview\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"spanish\", ignore_stopwords=True)\n",
        "\n",
        "def stem_sentence(sentence):\n",
        "    stemmed_text = [stemmer.stem(word) for word in word_tokenize(sentence)]\n",
        "    return \" \".join(stemmed_text)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FR0ULnEis-uV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['overview']=data['overview'].apply(lambda x: clean_overview(str(x)))\n",
        "data['overview']=data['overview'].apply(lambda x: delete_stop_words(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yRCVAywOWjVK",
        "colab_type": "code",
        "outputId": "e151c66b-9a7a-442c-dc3c-12b0711d405b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>like</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>overview</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>La guerra de las galaxias. Episodio IV: Una nu...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.1</td>\n",
              "      <td>princesa leia lider movimiento rebelde desea r...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420dc3a36847f8000437\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>Buscando a Nemo</td>\n",
              "      <td>1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>nemo pececillo hijo unico querido protegido pa...</td>\n",
              "      <td>[{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420ec3a36847f80006b1\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>Forrest Gump</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>forrest gump chico deficiencias mentales profu...</td>\n",
              "      <td>[{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420ec3a36847f800076b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>Piratas del Caribe. La maldición de la Perla N...</td>\n",
              "      <td>1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>aventurero capitan jack sparrow recorre aguas ...</td>\n",
              "      <td>[{\"cast_id\": 12, \"character\": \"Captain Jack Sp...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420fc3a36847f8000f11\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>Kill Bill: Volumen 1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.7</td>\n",
              "      <td>uma thurman asesina boda atacada miembros band...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Beatrix 'The Bri...</td>\n",
              "      <td>[{\"credit_id\": \"56a517709251410c080054d2\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>35</td>\n",
              "      <td>Los Simpson: La película</td>\n",
              "      <td>1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>homer salvar mundo catastrofe provocado comien...</td>\n",
              "      <td>[{\"cast_id\": 2, \"character\": \"Homer / Itchy / ...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4211c3a36847f8001521\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>58</td>\n",
              "      <td>Piratas del Caribe: El cofre del hombre muerto</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>will turner elizabeth swann casar hechos prisi...</td>\n",
              "      <td>[{\"cast_id\": 37, \"character\": \"Captain Jack Sp...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4211c3a36847f8001873\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>62</td>\n",
              "      <td>2001: Una odisea del espacio</td>\n",
              "      <td>1</td>\n",
              "      <td>7.9</td>\n",
              "      <td>historia humanidad diversos estadios futuro na...</td>\n",
              "      <td>[{\"cast_id\": 6, \"character\": \"Dr. Dave Bowman\"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4212c3a36847f8001a05\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>65</td>\n",
              "      <td>8 millas</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>detroit  promesa potencia industrial transform...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Jimmy B. \\\"Rabbi...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4212c3a36847f8001c6b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>70</td>\n",
              "      <td>Million Dollar Baby</td>\n",
              "      <td>1</td>\n",
              "      <td>7.7</td>\n",
              "      <td>frankie dunn entrenado representado mejores pu...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Frankie Dunn\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f800200b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>71</td>\n",
              "      <td>Billy Elliot (Quiero bailar)</td>\n",
              "      <td>1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>huelga mineros condado durham suceden enfrent...</td>\n",
              "      <td>[{\"cast_id\": 16, \"character\": \"Billy Elliot\", ...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f80020c7\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73</td>\n",
              "      <td>American History X</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>derek vinyard edward norton lider grupo neonaz...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Derek Vinyard\", ...</td>\n",
              "      <td>[{\"credit_id\": \"5563a4c1925141271b0021e7\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74</td>\n",
              "      <td>La guerra de los mundos</td>\n",
              "      <td>0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>basada popular novela hg wells narra historia ...</td>\n",
              "      <td>[{\"cast_id\": 13, \"character\": \"Ray Ferrier\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f8002237\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>77</td>\n",
              "      <td>Memento</td>\n",
              "      <td>1</td>\n",
              "      <td>8.1</td>\n",
              "      <td>leonard investigador seguros cuya memoria irre...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Leonard\", \"credi...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4214c3a36847f80024d1\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>78</td>\n",
              "      <td>Blade Runner</td>\n",
              "      <td>1</td>\n",
              "      <td>7.9</td>\n",
              "      <td>principios siglo xxi tyrell corporation desarr...</td>\n",
              "      <td>[{\"cast_id\": 6, \"character\": \"Rick Deckard\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"549e9edcc3a3682f2300824b\", \"de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                              title  like  vote_average  \\\n",
              "0   11  La guerra de las galaxias. Episodio IV: Una nu...     1           8.1   \n",
              "1   12                                    Buscando a Nemo     1           7.6   \n",
              "2   13                                       Forrest Gump     1           8.2   \n",
              "3   22  Piratas del Caribe. La maldición de la Perla N...     1           7.5   \n",
              "4   24                               Kill Bill: Volumen 1     1           7.7   \n",
              "5   35                           Los Simpson: La película     1           6.9   \n",
              "6   58     Piratas del Caribe: El cofre del hombre muerto     1           7.0   \n",
              "7   62                       2001: Una odisea del espacio     1           7.9   \n",
              "8   65                                           8 millas     1           NaN   \n",
              "9   70                                Million Dollar Baby     1           7.7   \n",
              "10  71                       Billy Elliot (Quiero bailar)     1           7.4   \n",
              "11  73                                 American History X     1           8.2   \n",
              "12  74                            La guerra de los mundos     0           6.2   \n",
              "13  77                                            Memento     1           8.1   \n",
              "14  78                                       Blade Runner     1           7.9   \n",
              "\n",
              "                                             overview  \\\n",
              "0   princesa leia lider movimiento rebelde desea r...   \n",
              "1   nemo pececillo hijo unico querido protegido pa...   \n",
              "2   forrest gump chico deficiencias mentales profu...   \n",
              "3   aventurero capitan jack sparrow recorre aguas ...   \n",
              "4   uma thurman asesina boda atacada miembros band...   \n",
              "5   homer salvar mundo catastrofe provocado comien...   \n",
              "6   will turner elizabeth swann casar hechos prisi...   \n",
              "7   historia humanidad diversos estadios futuro na...   \n",
              "8   detroit  promesa potencia industrial transform...   \n",
              "9   frankie dunn entrenado representado mejores pu...   \n",
              "10   huelga mineros condado durham suceden enfrent...   \n",
              "11  derek vinyard edward norton lider grupo neonaz...   \n",
              "12  basada popular novela hg wells narra historia ...   \n",
              "13  leonard investigador seguros cuya memoria irre...   \n",
              "14  principios siglo xxi tyrell corporation desarr...   \n",
              "\n",
              "                                                 cast  \\\n",
              "0   [{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...   \n",
              "1   [{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...   \n",
              "2   [{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...   \n",
              "3   [{\"cast_id\": 12, \"character\": \"Captain Jack Sp...   \n",
              "4   [{\"cast_id\": 3, \"character\": \"Beatrix 'The Bri...   \n",
              "5   [{\"cast_id\": 2, \"character\": \"Homer / Itchy / ...   \n",
              "6   [{\"cast_id\": 37, \"character\": \"Captain Jack Sp...   \n",
              "7   [{\"cast_id\": 6, \"character\": \"Dr. Dave Bowman\"...   \n",
              "8   [{\"cast_id\": 3, \"character\": \"Jimmy B. \\\"Rabbi...   \n",
              "9   [{\"cast_id\": 4, \"character\": \"Frankie Dunn\", \"...   \n",
              "10  [{\"cast_id\": 16, \"character\": \"Billy Elliot\", ...   \n",
              "11  [{\"cast_id\": 4, \"character\": \"Derek Vinyard\", ...   \n",
              "12  [{\"cast_id\": 13, \"character\": \"Ray Ferrier\", \"...   \n",
              "13  [{\"cast_id\": 4, \"character\": \"Leonard\", \"credi...   \n",
              "14  [{\"cast_id\": 6, \"character\": \"Rick Deckard\", \"...   \n",
              "\n",
              "                                                 crew  \n",
              "0   [{\"credit_id\": \"52fe420dc3a36847f8000437\", \"de...  \n",
              "1   [{\"credit_id\": \"52fe420ec3a36847f80006b1\", \"de...  \n",
              "2   [{\"credit_id\": \"52fe420ec3a36847f800076b\", \"de...  \n",
              "3   [{\"credit_id\": \"52fe420fc3a36847f8000f11\", \"de...  \n",
              "4   [{\"credit_id\": \"56a517709251410c080054d2\", \"de...  \n",
              "5   [{\"credit_id\": \"52fe4211c3a36847f8001521\", \"de...  \n",
              "6   [{\"credit_id\": \"52fe4211c3a36847f8001873\", \"de...  \n",
              "7   [{\"credit_id\": \"52fe4212c3a36847f8001a05\", \"de...  \n",
              "8   [{\"credit_id\": \"52fe4212c3a36847f8001c6b\", \"de...  \n",
              "9   [{\"credit_id\": \"52fe4213c3a36847f800200b\", \"de...  \n",
              "10  [{\"credit_id\": \"52fe4213c3a36847f80020c7\", \"de...  \n",
              "11  [{\"credit_id\": \"5563a4c1925141271b0021e7\", \"de...  \n",
              "12  [{\"credit_id\": \"52fe4213c3a36847f8002237\", \"de...  \n",
              "13  [{\"credit_id\": \"52fe4214c3a36847f80024d1\", \"de...  \n",
              "14  [{\"credit_id\": \"549e9edcc3a3682f2300824b\", \"de...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "3UE-Dc9MWMS2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['overview']=data['overview'].apply(lambda x: stem_sentence(x))\n",
        "data['overview']=data['overview'].apply(lambda x: delete_stop_words(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tglTzf6YWb2M",
        "colab_type": "code",
        "outputId": "79e5ca7f-ec73-43dd-f134-0c73e7fe6e9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 780
        }
      },
      "cell_type": "code",
      "source": [
        "data.head(15)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>title</th>\n",
              "      <th>like</th>\n",
              "      <th>vote_average</th>\n",
              "      <th>overview</th>\n",
              "      <th>cast</th>\n",
              "      <th>crew</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>11</td>\n",
              "      <td>La guerra de las galaxias. Episodio IV: Una nu...</td>\n",
              "      <td>1</td>\n",
              "      <td>8.1</td>\n",
              "      <td>princes lei lid movimient rebeld dese reinstau...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420dc3a36847f8000437\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>12</td>\n",
              "      <td>Buscando a Nemo</td>\n",
              "      <td>1</td>\n",
              "      <td>7.6</td>\n",
              "      <td>nem pececill hij unic quer proteg padr captur ...</td>\n",
              "      <td>[{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420ec3a36847f80006b1\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13</td>\n",
              "      <td>Forrest Gump</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>forrest gump chic deficient mental profund inc...</td>\n",
              "      <td>[{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420ec3a36847f800076b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>Piratas del Caribe. La maldición de la Perla N...</td>\n",
              "      <td>1</td>\n",
              "      <td>7.5</td>\n",
              "      <td>aventurer capit jack sparrow recorr agu caribe...</td>\n",
              "      <td>[{\"cast_id\": 12, \"character\": \"Captain Jack Sp...</td>\n",
              "      <td>[{\"credit_id\": \"52fe420fc3a36847f8000f11\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>24</td>\n",
              "      <td>Kill Bill: Volumen 1</td>\n",
              "      <td>1</td>\n",
              "      <td>7.7</td>\n",
              "      <td>uma thurm asesin bod atac miembr band jef bill...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Beatrix 'The Bri...</td>\n",
              "      <td>[{\"credit_id\": \"56a517709251410c080054d2\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>35</td>\n",
              "      <td>Los Simpson: La película</td>\n",
              "      <td>1</td>\n",
              "      <td>6.9</td>\n",
              "      <td>hom salv mund catastrof provoc comienz hom mas...</td>\n",
              "      <td>[{\"cast_id\": 2, \"character\": \"Homer / Itchy / ...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4211c3a36847f8001521\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>58</td>\n",
              "      <td>Piratas del Caribe: El cofre del hombre muerto</td>\n",
              "      <td>1</td>\n",
              "      <td>7.0</td>\n",
              "      <td>will turn elizabeth swann cas hech prisioner l...</td>\n",
              "      <td>[{\"cast_id\": 37, \"character\": \"Captain Jack Sp...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4211c3a36847f8001873\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>62</td>\n",
              "      <td>2001: Una odisea del espacio</td>\n",
              "      <td>1</td>\n",
              "      <td>7.9</td>\n",
              "      <td>histori human divers estadi futur narr pelicul...</td>\n",
              "      <td>[{\"cast_id\": 6, \"character\": \"Dr. Dave Bowman\"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4212c3a36847f8001a05\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>65</td>\n",
              "      <td>8 millas</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>detroit promes potenci industrial transform he...</td>\n",
              "      <td>[{\"cast_id\": 3, \"character\": \"Jimmy B. \\\"Rabbi...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4212c3a36847f8001c6b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>70</td>\n",
              "      <td>Million Dollar Baby</td>\n",
              "      <td>1</td>\n",
              "      <td>7.7</td>\n",
              "      <td>franki dunn entren represent pugil regent gimn...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Frankie Dunn\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f800200b\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>71</td>\n",
              "      <td>Billy Elliot (Quiero bailar)</td>\n",
              "      <td>1</td>\n",
              "      <td>7.4</td>\n",
              "      <td>huelg miner cond durham suced enfrent piquet p...</td>\n",
              "      <td>[{\"cast_id\": 16, \"character\": \"Billy Elliot\", ...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f80020c7\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>73</td>\n",
              "      <td>American History X</td>\n",
              "      <td>1</td>\n",
              "      <td>8.2</td>\n",
              "      <td>derek vinyard edward norton lid grup neonazi v...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Derek Vinyard\", ...</td>\n",
              "      <td>[{\"credit_id\": \"5563a4c1925141271b0021e7\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>74</td>\n",
              "      <td>La guerra de los mundos</td>\n",
              "      <td>0</td>\n",
              "      <td>6.2</td>\n",
              "      <td>bas popul novel hg wells narr histori invasion...</td>\n",
              "      <td>[{\"cast_id\": 13, \"character\": \"Ray Ferrier\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4213c3a36847f8002237\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>77</td>\n",
              "      <td>Memento</td>\n",
              "      <td>1</td>\n",
              "      <td>8.1</td>\n",
              "      <td>leonard investig segur cuy memori irrevers dañ...</td>\n",
              "      <td>[{\"cast_id\": 4, \"character\": \"Leonard\", \"credi...</td>\n",
              "      <td>[{\"credit_id\": \"52fe4214c3a36847f80024d1\", \"de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>78</td>\n",
              "      <td>Blade Runner</td>\n",
              "      <td>1</td>\n",
              "      <td>7.9</td>\n",
              "      <td>principi sigl xxi tyrell corporation desarroll...</td>\n",
              "      <td>[{\"cast_id\": 6, \"character\": \"Rick Deckard\", \"...</td>\n",
              "      <td>[{\"credit_id\": \"549e9edcc3a3682f2300824b\", \"de...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id                                              title  like  vote_average  \\\n",
              "0   11  La guerra de las galaxias. Episodio IV: Una nu...     1           8.1   \n",
              "1   12                                    Buscando a Nemo     1           7.6   \n",
              "2   13                                       Forrest Gump     1           8.2   \n",
              "3   22  Piratas del Caribe. La maldición de la Perla N...     1           7.5   \n",
              "4   24                               Kill Bill: Volumen 1     1           7.7   \n",
              "5   35                           Los Simpson: La película     1           6.9   \n",
              "6   58     Piratas del Caribe: El cofre del hombre muerto     1           7.0   \n",
              "7   62                       2001: Una odisea del espacio     1           7.9   \n",
              "8   65                                           8 millas     1           NaN   \n",
              "9   70                                Million Dollar Baby     1           7.7   \n",
              "10  71                       Billy Elliot (Quiero bailar)     1           7.4   \n",
              "11  73                                 American History X     1           8.2   \n",
              "12  74                            La guerra de los mundos     0           6.2   \n",
              "13  77                                            Memento     1           8.1   \n",
              "14  78                                       Blade Runner     1           7.9   \n",
              "\n",
              "                                             overview  \\\n",
              "0   princes lei lid movimient rebeld dese reinstau...   \n",
              "1   nem pececill hij unic quer proteg padr captur ...   \n",
              "2   forrest gump chic deficient mental profund inc...   \n",
              "3   aventurer capit jack sparrow recorr agu caribe...   \n",
              "4   uma thurm asesin bod atac miembr band jef bill...   \n",
              "5   hom salv mund catastrof provoc comienz hom mas...   \n",
              "6   will turn elizabeth swann cas hech prisioner l...   \n",
              "7   histori human divers estadi futur narr pelicul...   \n",
              "8   detroit promes potenci industrial transform he...   \n",
              "9   franki dunn entren represent pugil regent gimn...   \n",
              "10  huelg miner cond durham suced enfrent piquet p...   \n",
              "11  derek vinyard edward norton lid grup neonazi v...   \n",
              "12  bas popul novel hg wells narr histori invasion...   \n",
              "13  leonard investig segur cuy memori irrevers dañ...   \n",
              "14  principi sigl xxi tyrell corporation desarroll...   \n",
              "\n",
              "                                                 cast  \\\n",
              "0   [{\"cast_id\": 3, \"character\": \"Luke Skywalker\",...   \n",
              "1   [{\"cast_id\": 8, \"character\": \"Marlin (voice)\",...   \n",
              "2   [{\"cast_id\": 7, \"character\": \"Forrest Gump\", \"...   \n",
              "3   [{\"cast_id\": 12, \"character\": \"Captain Jack Sp...   \n",
              "4   [{\"cast_id\": 3, \"character\": \"Beatrix 'The Bri...   \n",
              "5   [{\"cast_id\": 2, \"character\": \"Homer / Itchy / ...   \n",
              "6   [{\"cast_id\": 37, \"character\": \"Captain Jack Sp...   \n",
              "7   [{\"cast_id\": 6, \"character\": \"Dr. Dave Bowman\"...   \n",
              "8   [{\"cast_id\": 3, \"character\": \"Jimmy B. \\\"Rabbi...   \n",
              "9   [{\"cast_id\": 4, \"character\": \"Frankie Dunn\", \"...   \n",
              "10  [{\"cast_id\": 16, \"character\": \"Billy Elliot\", ...   \n",
              "11  [{\"cast_id\": 4, \"character\": \"Derek Vinyard\", ...   \n",
              "12  [{\"cast_id\": 13, \"character\": \"Ray Ferrier\", \"...   \n",
              "13  [{\"cast_id\": 4, \"character\": \"Leonard\", \"credi...   \n",
              "14  [{\"cast_id\": 6, \"character\": \"Rick Deckard\", \"...   \n",
              "\n",
              "                                                 crew  \n",
              "0   [{\"credit_id\": \"52fe420dc3a36847f8000437\", \"de...  \n",
              "1   [{\"credit_id\": \"52fe420ec3a36847f80006b1\", \"de...  \n",
              "2   [{\"credit_id\": \"52fe420ec3a36847f800076b\", \"de...  \n",
              "3   [{\"credit_id\": \"52fe420fc3a36847f8000f11\", \"de...  \n",
              "4   [{\"credit_id\": \"56a517709251410c080054d2\", \"de...  \n",
              "5   [{\"credit_id\": \"52fe4211c3a36847f8001521\", \"de...  \n",
              "6   [{\"credit_id\": \"52fe4211c3a36847f8001873\", \"de...  \n",
              "7   [{\"credit_id\": \"52fe4212c3a36847f8001a05\", \"de...  \n",
              "8   [{\"credit_id\": \"52fe4212c3a36847f8001c6b\", \"de...  \n",
              "9   [{\"credit_id\": \"52fe4213c3a36847f800200b\", \"de...  \n",
              "10  [{\"credit_id\": \"52fe4213c3a36847f80020c7\", \"de...  \n",
              "11  [{\"credit_id\": \"5563a4c1925141271b0021e7\", \"de...  \n",
              "12  [{\"credit_id\": \"52fe4213c3a36847f8002237\", \"de...  \n",
              "13  [{\"credit_id\": \"52fe4214c3a36847f80024d1\", \"de...  \n",
              "14  [{\"credit_id\": \"549e9edcc3a3682f2300824b\", \"de...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "id": "3D5xiv1eRzQ1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Get staff and paste to overview\n",
        "\n",
        "def get_actors(cast):\n",
        "  \n",
        "  try:\n",
        "    \n",
        "    json_cast = json.loads(cast)\n",
        "  \n",
        "  except:\n",
        "    \n",
        "    json_cast = cast\n",
        "  \n",
        "  if len(json_cast) > 2:\n",
        "    up = 3\n",
        "  else:\n",
        "    up = len(json_cast)\n",
        "\n",
        "  actors = ''\n",
        "  \n",
        "  for i in range(0,up):\n",
        "    actor = json_cast[i]['name']\n",
        "    actor = normalize(actor.replace(' ','_').lower())\n",
        "  \n",
        "    actors = actors + ' ' + actor\n",
        "  \n",
        "  return actors\n",
        "\n",
        "def get_director(crew):\n",
        "  \n",
        "  try:\n",
        "    \n",
        "    json_crew = json.loads(crew)\n",
        "  \n",
        "  except:\n",
        "    \n",
        "    json_crew = crew\n",
        "  \n",
        "  directors = [member['name'] for member in json_crew if member['job'] == 'Director']\n",
        "  directors = [normalize(director.replace(' ','_').lower()) for director in directors]\n",
        "  directors = str(' '.join(directors))\n",
        "  \n",
        "  return directors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "urmPevCVtAgS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "data['overview']=data.apply(lambda x: get_actors(x['cast']) + ' ' + x['overview'] , axis=1)\n",
        "data['overview']=data.apply(lambda x: get_director(x['crew']) + x['overview'] , axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qTjFRkmtz-JU",
        "colab_type": "code",
        "outputId": "f498f806-045f-444e-8c66-d96f4af03fb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "cell_type": "code",
      "source": [
        "data['overview'][0]"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'george_lucas mark_hamill harrison_ford carrie_fisher princes lei lid movimient rebeld dese reinstaur republ galaxi tiemp omin imperi captur malevol fuerz imperial capitan implac darth vad sirvient fiel emper intrep luk skywalk ayud capit nav espacial halcon milenari android rd cpo encarg luch enemig rescat princes volv instaur justici sen galaxi'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "mwp9UDLvh5Kw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "overviews = data['overview'].values\n",
        "y = data['like'].values\n",
        "\n",
        "overviews_train, overviews_test, y_train, y_test = train_test_split(overviews, y, test_size=0.1, random_state=777, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j5pooRddATyH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "columns_train = {'Overview': overviews_train, 'Like': y_train}\n",
        "train = pd.DataFrame(data=columns_train)\n",
        "train.to_csv('train' + '.csv', sep=';', encoding='utf-8', index=False)\n",
        "\n",
        "columns_test = {'Comment': overviews_test, 'Like': y_test}\n",
        "test = pd.DataFrame(data=columns_test)\n",
        "test.to_csv('test' + '.csv', sep=';', encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1APEOOWyi-gO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Embedding\n",
        "num_words = 9000\n",
        "maxlen = 90\n",
        "embedding_size = 300\n",
        "\n",
        "# Convolution\n",
        "kernel_size = 5\n",
        "filters = 300\n",
        "pool_size = 2\n",
        "\n",
        "hidden_dims = 300\n",
        "\n",
        "\n",
        "# LSTM\n",
        "lstm_output_size = 70\n",
        "\n",
        "# Training\n",
        "lr=0.000005\n",
        "#lr=0.0001"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lBLAw0i0i5j3",
        "colab_type": "code",
        "outputId": "a75df703-11be-492f-ba10-25ffb15abed7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer(num_words) \n",
        "tokenizer.fit_on_texts(overviews_train)\n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(overviews_train) \n",
        "X_test = tokenizer.texts_to_sequences(overviews_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(overviews_train[2]) \n",
        "print(X_train[2]) \n",
        "print(vocab_size)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "john_g._avildsen ralph_macchio pat_morita william_zabka daniel laruss lleg angel procedent cost unid dispuest amig conviert blanc ataqu cobr hostil grup estudi karat comienz ali antigu novi cabecill grup situacion remedi ped ayud miyagi maestr artes marcial enseñ karat tutel miyagi daniel desarroll aptitud fisic segur necesit super obstacul\n",
            "[8, 2297, 4527, 1179, 4528, 753, 4529, 158, 4530, 300, 4531, 20, 333, 997, 672, 82, 360, 4, 148, 202, 254, 754, 1180, 17, 70, 3014, 75, 149, 118, 97, 3015, 17, 209, 755, 1430, 15, 3016, 533, 2298, 2299, 301, 3014, 4532, 3016, 300, 302, 4533, 998, 134, 334, 485, 1431]\n",
            "8782\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JRXfUryKjQCN",
        "colab_type": "code",
        "outputId": "b4d0ff3f-98ee-4bfb-ff8c-cb001111fc7b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "cell_type": "code",
      "source": [
        "from collections import OrderedDict\n",
        "\n",
        "dictWords = dict(tokenizer.word_counts)\n",
        "\n",
        "print(len(dictWords) + 1)\n",
        "\n",
        "for k,v in list(dictWords.items()):\n",
        "    if v < 2 :\n",
        "        del dictWords[k]\n",
        "        \n",
        "print(len(dictWords) + 1) \n",
        "# Para establecer el tamaño de maxlen\n",
        "\n",
        "len(max(X_train, key=len))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8782\n",
            "4517\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "95"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "metadata": {
        "id": "XHqpVvAjjQY8",
        "colab_type": "code",
        "outputId": "00299d71-c952-4e9f-8235-bbdba2ca60e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n",
        "\n",
        "X_train[1]"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 531, 4518,  671,  102, 1177, 3013,  605, 4519, 4520, 1427, 1776,\n",
              "       4521,  752,   26, 4522,   66, 1427, 4523,  329,    7, 1178,  330,\n",
              "          5,   49,  147,  331,  996,   40,  103, 4524, 2293,  280, 4525,\n",
              "       1428,  330,  860,  331, 1777,  332, 4526,   63, 2294, 2295,  532,\n",
              "        606,  330,  396, 1429, 2296,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "metadata": {
        "id": "0UB9lmFFWab7",
        "colab_type": "code",
        "outputId": "a705d4b8-5738-46af-df1f-4cdb982b7809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "\n",
        "#Optimizer\n",
        "\n",
        "from tensorflow.keras import optimizers\n",
        "\n",
        "adam = optimizers.Adam(lr)\n",
        "\n",
        "\n",
        "es = EarlyStopping(monitor='val_loss',\n",
        "                   min_delta=0,\n",
        "                   patience=30,\n",
        "                   verbose=0, mode='auto')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ifIZiMr2LdSS",
        "colab_type": "code",
        "outputId": "827b1b70-aff4-4dd6-c4ab-6a593a0ddbe0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "class_weights"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.96578947, 1.03672316])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "metadata": {
        "id": "TO2rjJmBj28t",
        "colab_type": "code",
        "outputId": "920b87da-a61f-44c7-ddeb-a59f36a8d4dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        }
      },
      "cell_type": "code",
      "source": [
        "# Model 1\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "model.add(Embedding(vocab_size,embedding_size, input_length=maxlen))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "model.compile(optimizer=adam,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['acc'])\n",
        "\n",
        "model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 90, 300)           2634600   \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d (Global (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 500)               150500    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 500)               250500    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 500)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 501       \n",
            "=================================================================\n",
            "Total params: 3,286,601\n",
            "Trainable params: 3,286,601\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "X3Jtoe5qztD0",
        "colab_type": "code",
        "outputId": "8d14def8-52c1-4907-9e13-a085ae1a1621",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        }
      },
      "cell_type": "code",
      "source": [
        "# Model 2\n",
        "\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "from tensorflow.keras.layers import Embedding, BatchNormalization\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D,GlobalAveragePooling1D\n",
        "\n",
        "model = Sequential()\n",
        "\n",
        "# we start off with an efficient embedding layer which maps\n",
        "# our vocab indices into embedding_dims dimensions\n",
        "model.add(Embedding(vocab_size,\n",
        "                    embedding_size,\n",
        "                    input_length=maxlen))\n",
        "\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# we add a Convolution1D, which will learn filters\n",
        "# word group filters of size filter_length:\n",
        "model.add(Conv1D(filters,\n",
        "                 kernel_size,\n",
        "                 padding='valid',\n",
        "                 strides=1, kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# we use max pooling:\n",
        "\n",
        "model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# We add a vanilla hidden layer:\n",
        "model.add(Dense(150, kernel_initializer='he_uniform'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('elu'))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "# We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "model.add(Dense(1))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Activation('sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_22 (Embedding)     (None, 90, 300)           2634600   \n",
            "_________________________________________________________________\n",
            "dropout_64 (Dropout)         (None, 90, 300)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_20 (Conv1D)           (None, 86, 300)           450300    \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_59 (B (None, 86, 300)           1200      \n",
            "_________________________________________________________________\n",
            "activation_60 (Activation)   (None, 86, 300)           0         \n",
            "_________________________________________________________________\n",
            "dropout_65 (Dropout)         (None, 86, 300)           0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_21 (Glo (None, 300)               0         \n",
            "_________________________________________________________________\n",
            "dense_44 (Dense)             (None, 150)               45150     \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_60 (B (None, 150)               600       \n",
            "_________________________________________________________________\n",
            "activation_61 (Activation)   (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dropout_66 (Dropout)         (None, 150)               0         \n",
            "_________________________________________________________________\n",
            "dense_45 (Dense)             (None, 1)                 151       \n",
            "_________________________________________________________________\n",
            "batch_normalization_v1_61 (B (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "activation_62 (Activation)   (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 3,132,005\n",
            "Trainable params: 3,131,103\n",
            "Non-trainable params: 902\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "F7r7BcGTDyEV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Model 3\n",
        "\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Input\n",
        "from tensorflow.keras.layers import Embedding,CuDNNLSTM, SpatialDropout1D, Reshape, Flatten\n",
        "from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
        "from tensorflow.keras.optimizers import Adam, Adagrad\n",
        "\n",
        "from tensorflow.keras import backend as K \n",
        "def custom_sigmoid(x): \n",
        "    return (K.sigmoid(x+10)) \n",
        "  \n",
        "\n",
        "words = Input(shape=(num_words,))\n",
        "df =  Embedding(input_dim = vocab_size, output_dim = embedding_size)(words)\n",
        "c1 = Conv1D(filters = 300, kernel_size = 3, padding='valid', activation='relu', strides=1)(df)\n",
        "c2 = Conv1D(filters = 300, kernel_size = 5, padding='valid', activation='relu', strides=1)(df)\n",
        "c3 = Conv1D(filters = 300, kernel_size = 8, padding='valid', activation='relu', strides=1)(df)\n",
        "\n",
        "\n",
        "g1 = GlobalMaxPooling1D()(c1)\n",
        "g2 = GlobalMaxPooling1D()(c2)\n",
        "g3 = GlobalMaxPooling1D()(c3)\n",
        "\n",
        "\n",
        "pf = Concatenate(axis=1)([g1,g2,g3])\n",
        "pf = Dropout(0.4)(pf) \n",
        "pred = Dense(1, activation = 'sigmoid')(pf)\n",
        "model = Model(inputs=words, outputs=pred)\n",
        "\n",
        "model.compile(optimizer = adam,\n",
        "                loss = 'binary_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "print(model.summary())\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "aN3ce7nAkNdh",
        "colab_type": "code",
        "outputId": "0cb70456-c0a1-46b8-d513-d569d7a07626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52154
        }
      },
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=1500,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=128, class_weight = class_weights)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 734 samples, validate on 82 samples\n",
            "Epoch 1/1500\n",
            "734/734 [==============================] - 2s 2ms/sample - loss: 0.7568 - acc: 0.5395 - val_loss: 0.6918 - val_acc: 0.5610\n",
            "Epoch 2/1500\n",
            "734/734 [==============================] - 0s 189us/sample - loss: 0.7203 - acc: 0.5872 - val_loss: 0.7002 - val_acc: 0.5122\n",
            "Epoch 3/1500\n",
            "734/734 [==============================] - 0s 185us/sample - loss: 0.6426 - acc: 0.6308 - val_loss: 0.7392 - val_acc: 0.5122\n",
            "Epoch 4/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.5715 - acc: 0.6962 - val_loss: 0.8072 - val_acc: 0.5122\n",
            "Epoch 5/1500\n",
            "734/734 [==============================] - 0s 182us/sample - loss: 0.5183 - acc: 0.7793 - val_loss: 0.8762 - val_acc: 0.5122\n",
            "Epoch 6/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.4646 - acc: 0.8406 - val_loss: 0.9492 - val_acc: 0.5122\n",
            "Epoch 7/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.4159 - acc: 0.9074 - val_loss: 1.0006 - val_acc: 0.5122\n",
            "Epoch 8/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.4044 - acc: 0.9019 - val_loss: 1.0382 - val_acc: 0.5122\n",
            "Epoch 9/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.3844 - acc: 0.9414 - val_loss: 1.0681 - val_acc: 0.5122\n",
            "Epoch 10/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.3661 - acc: 0.9659 - val_loss: 1.0929 - val_acc: 0.5122\n",
            "Epoch 11/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.3668 - acc: 0.9591 - val_loss: 1.1092 - val_acc: 0.5122\n",
            "Epoch 12/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.3515 - acc: 0.9809 - val_loss: 1.1303 - val_acc: 0.5122\n",
            "Epoch 13/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.3519 - acc: 0.9782 - val_loss: 1.1441 - val_acc: 0.5122\n",
            "Epoch 14/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.3397 - acc: 0.9891 - val_loss: 1.1566 - val_acc: 0.5122\n",
            "Epoch 15/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.3356 - acc: 0.9932 - val_loss: 1.1662 - val_acc: 0.5122\n",
            "Epoch 16/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.3329 - acc: 0.9946 - val_loss: 1.1722 - val_acc: 0.5122\n",
            "Epoch 17/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.3269 - acc: 0.9932 - val_loss: 1.1778 - val_acc: 0.5122\n",
            "Epoch 18/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.3232 - acc: 0.9959 - val_loss: 1.1807 - val_acc: 0.5122\n",
            "Epoch 19/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.3233 - acc: 0.9959 - val_loss: 1.1774 - val_acc: 0.5122\n",
            "Epoch 20/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.3163 - acc: 1.0000 - val_loss: 1.1821 - val_acc: 0.5122\n",
            "Epoch 21/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.3134 - acc: 0.9973 - val_loss: 1.1819 - val_acc: 0.5122\n",
            "Epoch 22/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.3126 - acc: 0.9973 - val_loss: 1.1847 - val_acc: 0.5122\n",
            "Epoch 23/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.3110 - acc: 0.9986 - val_loss: 1.1858 - val_acc: 0.5122\n",
            "Epoch 24/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.3064 - acc: 0.9973 - val_loss: 1.1853 - val_acc: 0.5122\n",
            "Epoch 25/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.3057 - acc: 1.0000 - val_loss: 1.1876 - val_acc: 0.5122\n",
            "Epoch 26/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.3005 - acc: 1.0000 - val_loss: 1.1845 - val_acc: 0.5122\n",
            "Epoch 27/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2981 - acc: 1.0000 - val_loss: 1.1817 - val_acc: 0.5122\n",
            "Epoch 28/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.3031 - acc: 1.0000 - val_loss: 1.1823 - val_acc: 0.5122\n",
            "Epoch 29/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.2936 - acc: 1.0000 - val_loss: 1.1794 - val_acc: 0.5122\n",
            "Epoch 30/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.2914 - acc: 1.0000 - val_loss: 1.1747 - val_acc: 0.5122\n",
            "Epoch 31/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2908 - acc: 1.0000 - val_loss: 1.1720 - val_acc: 0.5122\n",
            "Epoch 32/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2916 - acc: 1.0000 - val_loss: 1.1692 - val_acc: 0.5122\n",
            "Epoch 33/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2864 - acc: 1.0000 - val_loss: 1.1644 - val_acc: 0.5122\n",
            "Epoch 34/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2829 - acc: 1.0000 - val_loss: 1.1572 - val_acc: 0.5122\n",
            "Epoch 35/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2812 - acc: 1.0000 - val_loss: 1.1521 - val_acc: 0.5122\n",
            "Epoch 36/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.2790 - acc: 1.0000 - val_loss: 1.1492 - val_acc: 0.5122\n",
            "Epoch 37/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.2773 - acc: 1.0000 - val_loss: 1.1466 - val_acc: 0.5122\n",
            "Epoch 38/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.2747 - acc: 1.0000 - val_loss: 1.1421 - val_acc: 0.5122\n",
            "Epoch 39/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.2750 - acc: 1.0000 - val_loss: 1.1373 - val_acc: 0.5122\n",
            "Epoch 40/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2754 - acc: 1.0000 - val_loss: 1.1339 - val_acc: 0.5122\n",
            "Epoch 41/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2727 - acc: 1.0000 - val_loss: 1.1300 - val_acc: 0.5122\n",
            "Epoch 42/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2695 - acc: 1.0000 - val_loss: 1.1248 - val_acc: 0.5122\n",
            "Epoch 43/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2676 - acc: 1.0000 - val_loss: 1.1213 - val_acc: 0.5122\n",
            "Epoch 44/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2651 - acc: 1.0000 - val_loss: 1.1185 - val_acc: 0.5122\n",
            "Epoch 45/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.2656 - acc: 1.0000 - val_loss: 1.1138 - val_acc: 0.5122\n",
            "Epoch 46/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2629 - acc: 1.0000 - val_loss: 1.1100 - val_acc: 0.5122\n",
            "Epoch 47/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2627 - acc: 1.0000 - val_loss: 1.1050 - val_acc: 0.5122\n",
            "Epoch 48/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2622 - acc: 1.0000 - val_loss: 1.0994 - val_acc: 0.5122\n",
            "Epoch 49/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2579 - acc: 1.0000 - val_loss: 1.0958 - val_acc: 0.5122\n",
            "Epoch 50/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2570 - acc: 1.0000 - val_loss: 1.0902 - val_acc: 0.5122\n",
            "Epoch 51/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.2548 - acc: 1.0000 - val_loss: 1.0855 - val_acc: 0.5122\n",
            "Epoch 52/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2552 - acc: 1.0000 - val_loss: 1.0809 - val_acc: 0.5122\n",
            "Epoch 53/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2525 - acc: 1.0000 - val_loss: 1.0763 - val_acc: 0.5122\n",
            "Epoch 54/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2505 - acc: 1.0000 - val_loss: 1.0711 - val_acc: 0.5122\n",
            "Epoch 55/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2529 - acc: 1.0000 - val_loss: 1.0673 - val_acc: 0.5122\n",
            "Epoch 56/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2498 - acc: 1.0000 - val_loss: 1.0613 - val_acc: 0.5122\n",
            "Epoch 57/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.2492 - acc: 1.0000 - val_loss: 1.0561 - val_acc: 0.5122\n",
            "Epoch 58/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2486 - acc: 1.0000 - val_loss: 1.0517 - val_acc: 0.5122\n",
            "Epoch 59/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2467 - acc: 1.0000 - val_loss: 1.0488 - val_acc: 0.5122\n",
            "Epoch 60/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2467 - acc: 1.0000 - val_loss: 1.0443 - val_acc: 0.5122\n",
            "Epoch 61/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.2416 - acc: 1.0000 - val_loss: 1.0392 - val_acc: 0.5122\n",
            "Epoch 62/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2397 - acc: 1.0000 - val_loss: 1.0343 - val_acc: 0.5122\n",
            "Epoch 63/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2370 - acc: 1.0000 - val_loss: 1.0298 - val_acc: 0.5122\n",
            "Epoch 64/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2368 - acc: 1.0000 - val_loss: 1.0241 - val_acc: 0.5122\n",
            "Epoch 65/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.2378 - acc: 1.0000 - val_loss: 1.0181 - val_acc: 0.5122\n",
            "Epoch 66/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2362 - acc: 1.0000 - val_loss: 1.0128 - val_acc: 0.5122\n",
            "Epoch 67/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2334 - acc: 1.0000 - val_loss: 1.0075 - val_acc: 0.5122\n",
            "Epoch 68/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2324 - acc: 1.0000 - val_loss: 1.0033 - val_acc: 0.5122\n",
            "Epoch 69/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.2333 - acc: 1.0000 - val_loss: 0.9980 - val_acc: 0.5122\n",
            "Epoch 70/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.2318 - acc: 1.0000 - val_loss: 0.9923 - val_acc: 0.5122\n",
            "Epoch 71/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2314 - acc: 1.0000 - val_loss: 0.9881 - val_acc: 0.5122\n",
            "Epoch 72/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2308 - acc: 1.0000 - val_loss: 0.9824 - val_acc: 0.5122\n",
            "Epoch 73/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2273 - acc: 1.0000 - val_loss: 0.9782 - val_acc: 0.5122\n",
            "Epoch 74/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2258 - acc: 1.0000 - val_loss: 0.9735 - val_acc: 0.5122\n",
            "Epoch 75/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2237 - acc: 1.0000 - val_loss: 0.9692 - val_acc: 0.5122\n",
            "Epoch 76/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.2228 - acc: 1.0000 - val_loss: 0.9651 - val_acc: 0.5122\n",
            "Epoch 77/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.2216 - acc: 1.0000 - val_loss: 0.9611 - val_acc: 0.5122\n",
            "Epoch 78/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.2218 - acc: 1.0000 - val_loss: 0.9566 - val_acc: 0.5122\n",
            "Epoch 79/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2197 - acc: 1.0000 - val_loss: 0.9514 - val_acc: 0.5122\n",
            "Epoch 80/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2188 - acc: 1.0000 - val_loss: 0.9461 - val_acc: 0.5122\n",
            "Epoch 81/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2195 - acc: 1.0000 - val_loss: 0.9408 - val_acc: 0.5122\n",
            "Epoch 82/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.2185 - acc: 1.0000 - val_loss: 0.9347 - val_acc: 0.5122\n",
            "Epoch 83/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2149 - acc: 1.0000 - val_loss: 0.9308 - val_acc: 0.5122\n",
            "Epoch 84/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2134 - acc: 1.0000 - val_loss: 0.9270 - val_acc: 0.5122\n",
            "Epoch 85/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.2146 - acc: 1.0000 - val_loss: 0.9242 - val_acc: 0.5122\n",
            "Epoch 86/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.2121 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.5122\n",
            "Epoch 87/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2111 - acc: 1.0000 - val_loss: 0.9170 - val_acc: 0.5122\n",
            "Epoch 88/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2101 - acc: 1.0000 - val_loss: 0.9121 - val_acc: 0.5122\n",
            "Epoch 89/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2101 - acc: 1.0000 - val_loss: 0.9079 - val_acc: 0.5122\n",
            "Epoch 90/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2070 - acc: 1.0000 - val_loss: 0.9037 - val_acc: 0.5122\n",
            "Epoch 91/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.2079 - acc: 1.0000 - val_loss: 0.9000 - val_acc: 0.5122\n",
            "Epoch 92/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.2061 - acc: 1.0000 - val_loss: 0.8975 - val_acc: 0.5122\n",
            "Epoch 93/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.2043 - acc: 1.0000 - val_loss: 0.8946 - val_acc: 0.5122\n",
            "Epoch 94/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2029 - acc: 1.0000 - val_loss: 0.8897 - val_acc: 0.5122\n",
            "Epoch 95/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2039 - acc: 1.0000 - val_loss: 0.8859 - val_acc: 0.5122\n",
            "Epoch 96/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.2032 - acc: 1.0000 - val_loss: 0.8832 - val_acc: 0.5122\n",
            "Epoch 97/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.2019 - acc: 1.0000 - val_loss: 0.8811 - val_acc: 0.5122\n",
            "Epoch 98/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1999 - acc: 1.0000 - val_loss: 0.8775 - val_acc: 0.5122\n",
            "Epoch 99/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.2014 - acc: 1.0000 - val_loss: 0.8738 - val_acc: 0.5122\n",
            "Epoch 100/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1992 - acc: 1.0000 - val_loss: 0.8701 - val_acc: 0.5122\n",
            "Epoch 101/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1981 - acc: 1.0000 - val_loss: 0.8683 - val_acc: 0.5122\n",
            "Epoch 102/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1958 - acc: 1.0000 - val_loss: 0.8634 - val_acc: 0.5122\n",
            "Epoch 103/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1982 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.5122\n",
            "Epoch 104/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1964 - acc: 1.0000 - val_loss: 0.8580 - val_acc: 0.5122\n",
            "Epoch 105/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1928 - acc: 1.0000 - val_loss: 0.8553 - val_acc: 0.5122\n",
            "Epoch 106/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1929 - acc: 1.0000 - val_loss: 0.8537 - val_acc: 0.5122\n",
            "Epoch 107/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1929 - acc: 1.0000 - val_loss: 0.8529 - val_acc: 0.5122\n",
            "Epoch 108/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1925 - acc: 1.0000 - val_loss: 0.8496 - val_acc: 0.5122\n",
            "Epoch 109/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1898 - acc: 1.0000 - val_loss: 0.8463 - val_acc: 0.5122\n",
            "Epoch 110/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1926 - acc: 1.0000 - val_loss: 0.8446 - val_acc: 0.5122\n",
            "Epoch 111/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1886 - acc: 1.0000 - val_loss: 0.8411 - val_acc: 0.5122\n",
            "Epoch 112/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1883 - acc: 1.0000 - val_loss: 0.8377 - val_acc: 0.5122\n",
            "Epoch 113/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1874 - acc: 1.0000 - val_loss: 0.8359 - val_acc: 0.5122\n",
            "Epoch 114/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1914 - acc: 1.0000 - val_loss: 0.8302 - val_acc: 0.5122\n",
            "Epoch 115/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1842 - acc: 1.0000 - val_loss: 0.8279 - val_acc: 0.5122\n",
            "Epoch 116/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1826 - acc: 1.0000 - val_loss: 0.8254 - val_acc: 0.5122\n",
            "Epoch 117/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1866 - acc: 1.0000 - val_loss: 0.8242 - val_acc: 0.5122\n",
            "Epoch 118/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1835 - acc: 1.0000 - val_loss: 0.8233 - val_acc: 0.5122\n",
            "Epoch 119/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1803 - acc: 1.0000 - val_loss: 0.8223 - val_acc: 0.5122\n",
            "Epoch 120/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1795 - acc: 1.0000 - val_loss: 0.8208 - val_acc: 0.5122\n",
            "Epoch 121/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1785 - acc: 1.0000 - val_loss: 0.8188 - val_acc: 0.5122\n",
            "Epoch 122/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1787 - acc: 1.0000 - val_loss: 0.8158 - val_acc: 0.5122\n",
            "Epoch 123/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1797 - acc: 1.0000 - val_loss: 0.8116 - val_acc: 0.5122\n",
            "Epoch 124/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.1798 - acc: 1.0000 - val_loss: 0.8095 - val_acc: 0.5122\n",
            "Epoch 125/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1752 - acc: 1.0000 - val_loss: 0.8061 - val_acc: 0.5122\n",
            "Epoch 126/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1795 - acc: 1.0000 - val_loss: 0.8053 - val_acc: 0.5122\n",
            "Epoch 127/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1754 - acc: 1.0000 - val_loss: 0.8070 - val_acc: 0.5122\n",
            "Epoch 128/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1769 - acc: 1.0000 - val_loss: 0.8063 - val_acc: 0.5122\n",
            "Epoch 129/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1734 - acc: 1.0000 - val_loss: 0.8049 - val_acc: 0.5122\n",
            "Epoch 130/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1724 - acc: 1.0000 - val_loss: 0.8035 - val_acc: 0.5122\n",
            "Epoch 131/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1721 - acc: 1.0000 - val_loss: 0.8025 - val_acc: 0.5122\n",
            "Epoch 132/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1704 - acc: 1.0000 - val_loss: 0.8015 - val_acc: 0.5122\n",
            "Epoch 133/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1721 - acc: 1.0000 - val_loss: 0.8012 - val_acc: 0.5122\n",
            "Epoch 134/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1721 - acc: 1.0000 - val_loss: 0.8021 - val_acc: 0.5122\n",
            "Epoch 135/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1695 - acc: 1.0000 - val_loss: 0.8021 - val_acc: 0.5122\n",
            "Epoch 136/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1699 - acc: 1.0000 - val_loss: 0.7998 - val_acc: 0.5122\n",
            "Epoch 137/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1704 - acc: 1.0000 - val_loss: 0.7984 - val_acc: 0.5122\n",
            "Epoch 138/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1663 - acc: 1.0000 - val_loss: 0.7973 - val_acc: 0.5122\n",
            "Epoch 139/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1687 - acc: 1.0000 - val_loss: 0.7954 - val_acc: 0.5122\n",
            "Epoch 140/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1681 - acc: 1.0000 - val_loss: 0.7970 - val_acc: 0.5122\n",
            "Epoch 141/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1655 - acc: 1.0000 - val_loss: 0.7979 - val_acc: 0.5122\n",
            "Epoch 142/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1645 - acc: 1.0000 - val_loss: 0.7971 - val_acc: 0.5122\n",
            "Epoch 143/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1623 - acc: 1.0000 - val_loss: 0.7980 - val_acc: 0.5122\n",
            "Epoch 144/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.1625 - acc: 1.0000 - val_loss: 0.7969 - val_acc: 0.5122\n",
            "Epoch 145/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1629 - acc: 1.0000 - val_loss: 0.7965 - val_acc: 0.5122\n",
            "Epoch 146/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1608 - acc: 1.0000 - val_loss: 0.7953 - val_acc: 0.5122\n",
            "Epoch 147/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1612 - acc: 1.0000 - val_loss: 0.7938 - val_acc: 0.5122\n",
            "Epoch 148/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.1599 - acc: 1.0000 - val_loss: 0.7904 - val_acc: 0.5122\n",
            "Epoch 149/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1582 - acc: 1.0000 - val_loss: 0.7894 - val_acc: 0.5122\n",
            "Epoch 150/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1591 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.5122\n",
            "Epoch 151/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1570 - acc: 1.0000 - val_loss: 0.7879 - val_acc: 0.5122\n",
            "Epoch 152/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1561 - acc: 1.0000 - val_loss: 0.7878 - val_acc: 0.5122\n",
            "Epoch 153/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1613 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.5122\n",
            "Epoch 154/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1551 - acc: 1.0000 - val_loss: 0.7848 - val_acc: 0.5122\n",
            "Epoch 155/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.1547 - acc: 1.0000 - val_loss: 0.7834 - val_acc: 0.5122\n",
            "Epoch 156/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.1550 - acc: 1.0000 - val_loss: 0.7846 - val_acc: 0.5122\n",
            "Epoch 157/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1552 - acc: 1.0000 - val_loss: 0.7867 - val_acc: 0.5122\n",
            "Epoch 158/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1545 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.5122\n",
            "Epoch 159/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1537 - acc: 1.0000 - val_loss: 0.7870 - val_acc: 0.5122\n",
            "Epoch 160/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1533 - acc: 1.0000 - val_loss: 0.7871 - val_acc: 0.5122\n",
            "Epoch 161/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1515 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.5122\n",
            "Epoch 162/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1514 - acc: 1.0000 - val_loss: 0.7876 - val_acc: 0.5122\n",
            "Epoch 163/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.1490 - acc: 1.0000 - val_loss: 0.7895 - val_acc: 0.5122\n",
            "Epoch 164/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1488 - acc: 1.0000 - val_loss: 0.7879 - val_acc: 0.5122\n",
            "Epoch 165/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1501 - acc: 1.0000 - val_loss: 0.7872 - val_acc: 0.5122\n",
            "Epoch 166/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1529 - acc: 1.0000 - val_loss: 0.7875 - val_acc: 0.5122\n",
            "Epoch 167/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1510 - acc: 1.0000 - val_loss: 0.7873 - val_acc: 0.5122\n",
            "Epoch 168/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1507 - acc: 1.0000 - val_loss: 0.7865 - val_acc: 0.5122\n",
            "Epoch 169/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1451 - acc: 1.0000 - val_loss: 0.7867 - val_acc: 0.5122\n",
            "Epoch 170/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1469 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.5122\n",
            "Epoch 171/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.1455 - acc: 1.0000 - val_loss: 0.7868 - val_acc: 0.5122\n",
            "Epoch 172/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1467 - acc: 1.0000 - val_loss: 0.7864 - val_acc: 0.5122\n",
            "Epoch 173/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1445 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.5122\n",
            "Epoch 174/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1454 - acc: 1.0000 - val_loss: 0.7899 - val_acc: 0.5122\n",
            "Epoch 175/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1479 - acc: 1.0000 - val_loss: 0.7884 - val_acc: 0.5122\n",
            "Epoch 176/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1430 - acc: 1.0000 - val_loss: 0.7882 - val_acc: 0.5122\n",
            "Epoch 177/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1418 - acc: 1.0000 - val_loss: 0.7870 - val_acc: 0.5122\n",
            "Epoch 178/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1458 - acc: 1.0000 - val_loss: 0.7874 - val_acc: 0.5122\n",
            "Epoch 179/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1421 - acc: 1.0000 - val_loss: 0.7838 - val_acc: 0.5122\n",
            "Epoch 180/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1402 - acc: 1.0000 - val_loss: 0.7828 - val_acc: 0.5122\n",
            "Epoch 181/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1401 - acc: 1.0000 - val_loss: 0.7825 - val_acc: 0.5122\n",
            "Epoch 182/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1403 - acc: 1.0000 - val_loss: 0.7823 - val_acc: 0.5122\n",
            "Epoch 183/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1388 - acc: 1.0000 - val_loss: 0.7820 - val_acc: 0.5122\n",
            "Epoch 184/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1370 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 0.5122\n",
            "Epoch 185/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1378 - acc: 1.0000 - val_loss: 0.7804 - val_acc: 0.5122\n",
            "Epoch 186/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1400 - acc: 1.0000 - val_loss: 0.7794 - val_acc: 0.5122\n",
            "Epoch 187/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1358 - acc: 1.0000 - val_loss: 0.7815 - val_acc: 0.5122\n",
            "Epoch 188/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1374 - acc: 1.0000 - val_loss: 0.7791 - val_acc: 0.5122\n",
            "Epoch 189/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1343 - acc: 1.0000 - val_loss: 0.7801 - val_acc: 0.5122\n",
            "Epoch 190/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1376 - acc: 1.0000 - val_loss: 0.7803 - val_acc: 0.5122\n",
            "Epoch 191/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1354 - acc: 1.0000 - val_loss: 0.7806 - val_acc: 0.5122\n",
            "Epoch 192/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1330 - acc: 1.0000 - val_loss: 0.7794 - val_acc: 0.5122\n",
            "Epoch 193/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1320 - acc: 1.0000 - val_loss: 0.7776 - val_acc: 0.5122\n",
            "Epoch 194/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.1327 - acc: 1.0000 - val_loss: 0.7777 - val_acc: 0.5122\n",
            "Epoch 195/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1315 - acc: 1.0000 - val_loss: 0.7768 - val_acc: 0.5122\n",
            "Epoch 196/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1296 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.5122\n",
            "Epoch 197/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1314 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.5122\n",
            "Epoch 198/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1324 - acc: 1.0000 - val_loss: 0.7772 - val_acc: 0.5122\n",
            "Epoch 199/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1320 - acc: 1.0000 - val_loss: 0.7769 - val_acc: 0.5122\n",
            "Epoch 200/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1304 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.5122\n",
            "Epoch 201/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1287 - acc: 1.0000 - val_loss: 0.7780 - val_acc: 0.5122\n",
            "Epoch 202/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.1272 - acc: 1.0000 - val_loss: 0.7738 - val_acc: 0.5122\n",
            "Epoch 203/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1285 - acc: 1.0000 - val_loss: 0.7722 - val_acc: 0.5122\n",
            "Epoch 204/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1308 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.5122\n",
            "Epoch 205/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1271 - acc: 1.0000 - val_loss: 0.7726 - val_acc: 0.5122\n",
            "Epoch 206/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.1261 - acc: 1.0000 - val_loss: 0.7727 - val_acc: 0.5122\n",
            "Epoch 207/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1252 - acc: 1.0000 - val_loss: 0.7720 - val_acc: 0.5122\n",
            "Epoch 208/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1249 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.5122\n",
            "Epoch 209/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1252 - acc: 1.0000 - val_loss: 0.7748 - val_acc: 0.5122\n",
            "Epoch 210/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.1267 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.5122\n",
            "Epoch 211/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1230 - acc: 1.0000 - val_loss: 0.7764 - val_acc: 0.5122\n",
            "Epoch 212/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1237 - acc: 1.0000 - val_loss: 0.7760 - val_acc: 0.5122\n",
            "Epoch 213/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1253 - acc: 1.0000 - val_loss: 0.7785 - val_acc: 0.5122\n",
            "Epoch 214/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1225 - acc: 1.0000 - val_loss: 0.7759 - val_acc: 0.5122\n",
            "Epoch 215/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1219 - acc: 1.0000 - val_loss: 0.7728 - val_acc: 0.5122\n",
            "Epoch 216/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1247 - acc: 1.0000 - val_loss: 0.7714 - val_acc: 0.5122\n",
            "Epoch 217/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1237 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.5122\n",
            "Epoch 218/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.1202 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.5122\n",
            "Epoch 219/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1184 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.5122\n",
            "Epoch 220/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1220 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.5122\n",
            "Epoch 221/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1189 - acc: 1.0000 - val_loss: 0.7705 - val_acc: 0.5122\n",
            "Epoch 222/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1171 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.5122\n",
            "Epoch 223/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1180 - acc: 1.0000 - val_loss: 0.7701 - val_acc: 0.5122\n",
            "Epoch 224/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1181 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.5122\n",
            "Epoch 225/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1177 - acc: 1.0000 - val_loss: 0.7693 - val_acc: 0.5122\n",
            "Epoch 226/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1188 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.5122\n",
            "Epoch 227/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1162 - acc: 1.0000 - val_loss: 0.7686 - val_acc: 0.5122\n",
            "Epoch 228/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1195 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.5122\n",
            "Epoch 229/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1147 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.5122\n",
            "Epoch 230/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1150 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.5122\n",
            "Epoch 231/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1132 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.5122\n",
            "Epoch 232/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1134 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.5122\n",
            "Epoch 233/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1133 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.5122\n",
            "Epoch 234/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1131 - acc: 1.0000 - val_loss: 0.7698 - val_acc: 0.5122\n",
            "Epoch 235/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1115 - acc: 1.0000 - val_loss: 0.7716 - val_acc: 0.5122\n",
            "Epoch 236/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1164 - acc: 1.0000 - val_loss: 0.7716 - val_acc: 0.5122\n",
            "Epoch 237/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1108 - acc: 1.0000 - val_loss: 0.7702 - val_acc: 0.5122\n",
            "Epoch 238/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1131 - acc: 1.0000 - val_loss: 0.7695 - val_acc: 0.5122\n",
            "Epoch 239/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1116 - acc: 1.0000 - val_loss: 0.7689 - val_acc: 0.5122\n",
            "Epoch 240/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.1117 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.5122\n",
            "Epoch 241/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1094 - acc: 1.0000 - val_loss: 0.7708 - val_acc: 0.5122\n",
            "Epoch 242/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1100 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.5122\n",
            "Epoch 243/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1098 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.5122\n",
            "Epoch 244/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.1105 - acc: 1.0000 - val_loss: 0.7712 - val_acc: 0.5122\n",
            "Epoch 245/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1121 - acc: 1.0000 - val_loss: 0.7707 - val_acc: 0.5122\n",
            "Epoch 246/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1074 - acc: 1.0000 - val_loss: 0.7704 - val_acc: 0.5122\n",
            "Epoch 247/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1075 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.5122\n",
            "Epoch 248/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1078 - acc: 1.0000 - val_loss: 0.7672 - val_acc: 0.5122\n",
            "Epoch 249/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.1070 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.5122\n",
            "Epoch 250/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1071 - acc: 1.0000 - val_loss: 0.7646 - val_acc: 0.5122\n",
            "Epoch 251/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1062 - acc: 1.0000 - val_loss: 0.7646 - val_acc: 0.5122\n",
            "Epoch 252/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1055 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.5122\n",
            "Epoch 253/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1051 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.5122\n",
            "Epoch 254/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1042 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.5122\n",
            "Epoch 255/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1042 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5122\n",
            "Epoch 256/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.1064 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5122\n",
            "Epoch 257/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.1077 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5122\n",
            "Epoch 258/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1032 - acc: 1.0000 - val_loss: 0.7685 - val_acc: 0.5122\n",
            "Epoch 259/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1061 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.5122\n",
            "Epoch 260/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.1051 - acc: 1.0000 - val_loss: 0.7694 - val_acc: 0.5122\n",
            "Epoch 261/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1035 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.5122\n",
            "Epoch 262/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1033 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5244\n",
            "Epoch 263/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1032 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5244\n",
            "Epoch 264/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.1046 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.5244\n",
            "Epoch 265/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.1010 - acc: 1.0000 - val_loss: 0.7732 - val_acc: 0.5122\n",
            "Epoch 266/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1024 - acc: 1.0000 - val_loss: 0.7718 - val_acc: 0.5122\n",
            "Epoch 267/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.1008 - acc: 1.0000 - val_loss: 0.7706 - val_acc: 0.5122\n",
            "Epoch 268/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.1011 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.5122\n",
            "Epoch 269/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0990 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5122\n",
            "Epoch 270/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0987 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.5244\n",
            "Epoch 271/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0990 - acc: 1.0000 - val_loss: 0.7638 - val_acc: 0.5244\n",
            "Epoch 272/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0993 - acc: 1.0000 - val_loss: 0.7653 - val_acc: 0.5244\n",
            "Epoch 273/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0975 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.5244\n",
            "Epoch 274/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0993 - acc: 1.0000 - val_loss: 0.7644 - val_acc: 0.5244\n",
            "Epoch 275/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0975 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.5244\n",
            "Epoch 276/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0964 - acc: 1.0000 - val_loss: 0.7615 - val_acc: 0.5122\n",
            "Epoch 277/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0969 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.5244\n",
            "Epoch 278/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0965 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.5366\n",
            "Epoch 279/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0955 - acc: 1.0000 - val_loss: 0.7589 - val_acc: 0.5366\n",
            "Epoch 280/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0945 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.5366\n",
            "Epoch 281/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.1001 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.5366\n",
            "Epoch 282/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0945 - acc: 1.0000 - val_loss: 0.7581 - val_acc: 0.5366\n",
            "Epoch 283/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0957 - acc: 1.0000 - val_loss: 0.7581 - val_acc: 0.5366\n",
            "Epoch 284/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0951 - acc: 1.0000 - val_loss: 0.7596 - val_acc: 0.5244\n",
            "Epoch 285/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0942 - acc: 1.0000 - val_loss: 0.7594 - val_acc: 0.5366\n",
            "Epoch 286/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0950 - acc: 1.0000 - val_loss: 0.7587 - val_acc: 0.5366\n",
            "Epoch 287/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0936 - acc: 1.0000 - val_loss: 0.7573 - val_acc: 0.5488\n",
            "Epoch 288/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0928 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.5488\n",
            "Epoch 289/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0926 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.5488\n",
            "Epoch 290/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0935 - acc: 1.0000 - val_loss: 0.7557 - val_acc: 0.5488\n",
            "Epoch 291/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0925 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.5488\n",
            "Epoch 292/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0923 - acc: 1.0000 - val_loss: 0.7552 - val_acc: 0.5488\n",
            "Epoch 293/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0938 - acc: 1.0000 - val_loss: 0.7573 - val_acc: 0.5488\n",
            "Epoch 294/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0914 - acc: 1.0000 - val_loss: 0.7589 - val_acc: 0.5488\n",
            "Epoch 295/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0931 - acc: 1.0000 - val_loss: 0.7628 - val_acc: 0.5488\n",
            "Epoch 296/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0907 - acc: 1.0000 - val_loss: 0.7631 - val_acc: 0.5366\n",
            "Epoch 297/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0919 - acc: 1.0000 - val_loss: 0.7643 - val_acc: 0.5366\n",
            "Epoch 298/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0924 - acc: 1.0000 - val_loss: 0.7668 - val_acc: 0.5244\n",
            "Epoch 299/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0884 - acc: 1.0000 - val_loss: 0.7681 - val_acc: 0.5244\n",
            "Epoch 300/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0904 - acc: 1.0000 - val_loss: 0.7684 - val_acc: 0.5244\n",
            "Epoch 301/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0885 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.5244\n",
            "Epoch 302/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0889 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5366\n",
            "Epoch 303/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0888 - acc: 1.0000 - val_loss: 0.7669 - val_acc: 0.5366\n",
            "Epoch 304/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0866 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.5488\n",
            "Epoch 305/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0868 - acc: 1.0000 - val_loss: 0.7656 - val_acc: 0.5488\n",
            "Epoch 306/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0878 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.5488\n",
            "Epoch 307/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0867 - acc: 1.0000 - val_loss: 0.7627 - val_acc: 0.5488\n",
            "Epoch 308/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0864 - acc: 1.0000 - val_loss: 0.7636 - val_acc: 0.5488\n",
            "Epoch 309/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0869 - acc: 1.0000 - val_loss: 0.7652 - val_acc: 0.5488\n",
            "Epoch 310/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 0.5488\n",
            "Epoch 311/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0850 - acc: 1.0000 - val_loss: 0.7657 - val_acc: 0.5488\n",
            "Epoch 312/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0848 - acc: 1.0000 - val_loss: 0.7648 - val_acc: 0.5366\n",
            "Epoch 313/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0846 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.5488\n",
            "Epoch 314/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0851 - acc: 1.0000 - val_loss: 0.7652 - val_acc: 0.5488\n",
            "Epoch 315/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0865 - acc: 1.0000 - val_loss: 0.7623 - val_acc: 0.5488\n",
            "Epoch 316/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0854 - acc: 1.0000 - val_loss: 0.7618 - val_acc: 0.5488\n",
            "Epoch 317/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0849 - acc: 1.0000 - val_loss: 0.7630 - val_acc: 0.5488\n",
            "Epoch 318/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0859 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.5488\n",
            "Epoch 319/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0837 - acc: 1.0000 - val_loss: 0.7637 - val_acc: 0.5488\n",
            "Epoch 320/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0849 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.5488\n",
            "Epoch 321/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0831 - acc: 1.0000 - val_loss: 0.7639 - val_acc: 0.5488\n",
            "Epoch 322/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0840 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.5488\n",
            "Epoch 323/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0816 - acc: 1.0000 - val_loss: 0.7617 - val_acc: 0.5488\n",
            "Epoch 324/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0816 - acc: 1.0000 - val_loss: 0.7612 - val_acc: 0.5488\n",
            "Epoch 325/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0809 - acc: 1.0000 - val_loss: 0.7624 - val_acc: 0.5488\n",
            "Epoch 326/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0829 - acc: 1.0000 - val_loss: 0.7618 - val_acc: 0.5488\n",
            "Epoch 327/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0833 - acc: 1.0000 - val_loss: 0.7616 - val_acc: 0.5488\n",
            "Epoch 328/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0823 - acc: 1.0000 - val_loss: 0.7610 - val_acc: 0.5488\n",
            "Epoch 329/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0824 - acc: 1.0000 - val_loss: 0.7625 - val_acc: 0.5488\n",
            "Epoch 330/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0833 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.5488\n",
            "Epoch 331/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0801 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.5488\n",
            "Epoch 332/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0815 - acc: 1.0000 - val_loss: 0.7616 - val_acc: 0.5488\n",
            "Epoch 333/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0793 - acc: 1.0000 - val_loss: 0.7598 - val_acc: 0.5488\n",
            "Epoch 334/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.7586 - val_acc: 0.5488\n",
            "Epoch 335/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0808 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 0.5488\n",
            "Epoch 336/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0802 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.5488\n",
            "Epoch 337/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0792 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.5488\n",
            "Epoch 338/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0785 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.5488\n",
            "Epoch 339/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0775 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.5488\n",
            "Epoch 340/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0832 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.5488\n",
            "Epoch 341/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.7572 - val_acc: 0.5488\n",
            "Epoch 342/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0786 - acc: 1.0000 - val_loss: 0.7557 - val_acc: 0.5488\n",
            "Epoch 343/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0775 - acc: 1.0000 - val_loss: 0.7549 - val_acc: 0.5488\n",
            "Epoch 344/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0788 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.5488\n",
            "Epoch 345/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0776 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.5488\n",
            "Epoch 346/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0837 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 0.5488\n",
            "Epoch 347/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0796 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.5488\n",
            "Epoch 348/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0760 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.5488\n",
            "Epoch 349/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0778 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.5488\n",
            "Epoch 350/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0787 - acc: 1.0000 - val_loss: 0.7534 - val_acc: 0.5488\n",
            "Epoch 351/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0761 - acc: 1.0000 - val_loss: 0.7511 - val_acc: 0.5488\n",
            "Epoch 352/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.5488\n",
            "Epoch 353/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0746 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.5488\n",
            "Epoch 354/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0763 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.5488\n",
            "Epoch 355/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0743 - acc: 1.0000 - val_loss: 0.7528 - val_acc: 0.5488\n",
            "Epoch 356/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0742 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.5488\n",
            "Epoch 357/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0725 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.5488\n",
            "Epoch 358/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0764 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.5488\n",
            "Epoch 359/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0757 - acc: 1.0000 - val_loss: 0.7523 - val_acc: 0.5488\n",
            "Epoch 360/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.7499 - val_acc: 0.5488\n",
            "Epoch 361/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0773 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.5488\n",
            "Epoch 362/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0717 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.5488\n",
            "Epoch 363/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0721 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.5488\n",
            "Epoch 364/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0708 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 0.5488\n",
            "Epoch 365/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.7510 - val_acc: 0.5488\n",
            "Epoch 366/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0741 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 0.5488\n",
            "Epoch 367/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.7497 - val_acc: 0.5488\n",
            "Epoch 368/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0718 - acc: 1.0000 - val_loss: 0.7502 - val_acc: 0.5488\n",
            "Epoch 369/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0716 - acc: 1.0000 - val_loss: 0.7516 - val_acc: 0.5488\n",
            "Epoch 370/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0701 - acc: 1.0000 - val_loss: 0.7511 - val_acc: 0.5488\n",
            "Epoch 371/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0715 - acc: 1.0000 - val_loss: 0.7514 - val_acc: 0.5488\n",
            "Epoch 372/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0712 - acc: 1.0000 - val_loss: 0.7526 - val_acc: 0.5488\n",
            "Epoch 373/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0711 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 0.5488\n",
            "Epoch 374/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0700 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5488\n",
            "Epoch 375/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0690 - acc: 1.0000 - val_loss: 0.7575 - val_acc: 0.5488\n",
            "Epoch 376/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0689 - acc: 1.0000 - val_loss: 0.7588 - val_acc: 0.5488\n",
            "Epoch 377/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5488\n",
            "Epoch 378/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.7570 - val_acc: 0.5488\n",
            "Epoch 379/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.5488\n",
            "Epoch 380/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0672 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5488\n",
            "Epoch 381/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0724 - acc: 1.0000 - val_loss: 0.7551 - val_acc: 0.5488\n",
            "Epoch 382/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 0.5488\n",
            "Epoch 383/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0681 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.5488\n",
            "Epoch 384/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0674 - acc: 1.0000 - val_loss: 0.7532 - val_acc: 0.5488\n",
            "Epoch 385/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0686 - acc: 1.0000 - val_loss: 0.7569 - val_acc: 0.5488\n",
            "Epoch 386/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0688 - acc: 1.0000 - val_loss: 0.7595 - val_acc: 0.5488\n",
            "Epoch 387/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0660 - acc: 1.0000 - val_loss: 0.7601 - val_acc: 0.5488\n",
            "Epoch 388/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0659 - acc: 1.0000 - val_loss: 0.7598 - val_acc: 0.5488\n",
            "Epoch 389/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0663 - acc: 1.0000 - val_loss: 0.7591 - val_acc: 0.5488\n",
            "Epoch 390/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0663 - acc: 1.0000 - val_loss: 0.7559 - val_acc: 0.5488\n",
            "Epoch 391/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0657 - acc: 1.0000 - val_loss: 0.7574 - val_acc: 0.5488\n",
            "Epoch 392/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.7547 - val_acc: 0.5488\n",
            "Epoch 393/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0658 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.5488\n",
            "Epoch 394/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0649 - acc: 1.0000 - val_loss: 0.7543 - val_acc: 0.5488\n",
            "Epoch 395/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0656 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.5488\n",
            "Epoch 396/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0679 - acc: 1.0000 - val_loss: 0.7502 - val_acc: 0.5488\n",
            "Epoch 397/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0643 - acc: 1.0000 - val_loss: 0.7484 - val_acc: 0.5488\n",
            "Epoch 398/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0652 - acc: 1.0000 - val_loss: 0.7478 - val_acc: 0.5488\n",
            "Epoch 399/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0643 - acc: 1.0000 - val_loss: 0.7476 - val_acc: 0.5488\n",
            "Epoch 400/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.7509 - val_acc: 0.5488\n",
            "Epoch 401/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0635 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.5488\n",
            "Epoch 402/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0657 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5488\n",
            "Epoch 403/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.7543 - val_acc: 0.5488\n",
            "Epoch 404/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.7537 - val_acc: 0.5488\n",
            "Epoch 405/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0636 - acc: 1.0000 - val_loss: 0.7560 - val_acc: 0.5488\n",
            "Epoch 406/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0631 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5488\n",
            "Epoch 407/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0644 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.5488\n",
            "Epoch 408/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0643 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 0.5488\n",
            "Epoch 409/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0625 - acc: 1.0000 - val_loss: 0.7532 - val_acc: 0.5488\n",
            "Epoch 410/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0624 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5488\n",
            "Epoch 411/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0633 - acc: 1.0000 - val_loss: 0.7506 - val_acc: 0.5610\n",
            "Epoch 412/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0629 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5610\n",
            "Epoch 413/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0617 - acc: 1.0000 - val_loss: 0.7514 - val_acc: 0.5610\n",
            "Epoch 414/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0627 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.5610\n",
            "Epoch 415/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0625 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.5610\n",
            "Epoch 416/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0612 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.5610\n",
            "Epoch 417/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0639 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5488\n",
            "Epoch 418/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0603 - acc: 1.0000 - val_loss: 0.7513 - val_acc: 0.5488\n",
            "Epoch 419/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0621 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5488\n",
            "Epoch 420/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.5488\n",
            "Epoch 421/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0596 - acc: 1.0000 - val_loss: 0.7464 - val_acc: 0.5488\n",
            "Epoch 422/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0601 - acc: 1.0000 - val_loss: 0.7485 - val_acc: 0.5488\n",
            "Epoch 423/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0602 - acc: 1.0000 - val_loss: 0.7510 - val_acc: 0.5488\n",
            "Epoch 424/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0600 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.5488\n",
            "Epoch 425/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0587 - acc: 1.0000 - val_loss: 0.7520 - val_acc: 0.5488\n",
            "Epoch 426/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0590 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.5610\n",
            "Epoch 427/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0607 - acc: 1.0000 - val_loss: 0.7542 - val_acc: 0.5610\n",
            "Epoch 428/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0589 - acc: 1.0000 - val_loss: 0.7536 - val_acc: 0.5610\n",
            "Epoch 429/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0602 - acc: 1.0000 - val_loss: 0.7535 - val_acc: 0.5610\n",
            "Epoch 430/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0621 - acc: 1.0000 - val_loss: 0.7518 - val_acc: 0.5488\n",
            "Epoch 431/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0595 - acc: 1.0000 - val_loss: 0.7490 - val_acc: 0.5488\n",
            "Epoch 432/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.7491 - val_acc: 0.5488\n",
            "Epoch 433/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0628 - acc: 1.0000 - val_loss: 0.7508 - val_acc: 0.5488\n",
            "Epoch 434/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0562 - acc: 1.0000 - val_loss: 0.7525 - val_acc: 0.5488\n",
            "Epoch 435/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0577 - acc: 1.0000 - val_loss: 0.7539 - val_acc: 0.5488\n",
            "Epoch 436/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0573 - acc: 1.0000 - val_loss: 0.7527 - val_acc: 0.5488\n",
            "Epoch 437/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0585 - acc: 1.0000 - val_loss: 0.7526 - val_acc: 0.5488\n",
            "Epoch 438/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0560 - acc: 1.0000 - val_loss: 0.7519 - val_acc: 0.5488\n",
            "Epoch 439/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0571 - acc: 1.0000 - val_loss: 0.7556 - val_acc: 0.5488\n",
            "Epoch 440/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0559 - acc: 1.0000 - val_loss: 0.7545 - val_acc: 0.5488\n",
            "Epoch 441/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0575 - acc: 1.0000 - val_loss: 0.7585 - val_acc: 0.5488\n",
            "Epoch 442/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0564 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.5488\n",
            "Epoch 443/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0579 - acc: 1.0000 - val_loss: 0.7641 - val_acc: 0.5488\n",
            "Epoch 444/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0561 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.5488\n",
            "Epoch 445/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0570 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.5488\n",
            "Epoch 446/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.7676 - val_acc: 0.5488\n",
            "Epoch 447/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0548 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.5488\n",
            "Epoch 448/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0572 - acc: 1.0000 - val_loss: 0.7654 - val_acc: 0.5488\n",
            "Epoch 449/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0554 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.5488\n",
            "Epoch 450/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.7650 - val_acc: 0.5488\n",
            "Epoch 451/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0547 - acc: 1.0000 - val_loss: 0.7651 - val_acc: 0.5488\n",
            "Epoch 452/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.7645 - val_acc: 0.5488\n",
            "Epoch 453/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0553 - acc: 1.0000 - val_loss: 0.7678 - val_acc: 0.5488\n",
            "Epoch 454/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0544 - acc: 1.0000 - val_loss: 0.7683 - val_acc: 0.5488\n",
            "Epoch 455/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0539 - acc: 1.0000 - val_loss: 0.7666 - val_acc: 0.5488\n",
            "Epoch 456/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0545 - acc: 1.0000 - val_loss: 0.7682 - val_acc: 0.5610\n",
            "Epoch 457/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0538 - acc: 1.0000 - val_loss: 0.7671 - val_acc: 0.5610\n",
            "Epoch 458/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0540 - acc: 1.0000 - val_loss: 0.7667 - val_acc: 0.5610\n",
            "Epoch 459/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0558 - acc: 1.0000 - val_loss: 0.7698 - val_acc: 0.5610\n",
            "Epoch 460/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0526 - acc: 1.0000 - val_loss: 0.7685 - val_acc: 0.5610\n",
            "Epoch 461/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0524 - acc: 1.0000 - val_loss: 0.7691 - val_acc: 0.5610\n",
            "Epoch 462/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.7687 - val_acc: 0.5610\n",
            "Epoch 463/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0535 - acc: 1.0000 - val_loss: 0.7658 - val_acc: 0.5488\n",
            "Epoch 464/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.7640 - val_acc: 0.5488\n",
            "Epoch 465/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.7608 - val_acc: 0.5610\n",
            "Epoch 466/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.7579 - val_acc: 0.5610\n",
            "Epoch 467/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0517 - acc: 1.0000 - val_loss: 0.7591 - val_acc: 0.5610\n",
            "Epoch 468/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0545 - acc: 1.0000 - val_loss: 0.7571 - val_acc: 0.5610\n",
            "Epoch 469/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0508 - acc: 1.0000 - val_loss: 0.7548 - val_acc: 0.5610\n",
            "Epoch 470/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.5610\n",
            "Epoch 471/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0520 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.5610\n",
            "Epoch 472/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0518 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.5610\n",
            "Epoch 473/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0509 - acc: 1.0000 - val_loss: 0.7538 - val_acc: 0.5610\n",
            "Epoch 474/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0521 - acc: 1.0000 - val_loss: 0.7554 - val_acc: 0.5610\n",
            "Epoch 475/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5610\n",
            "Epoch 476/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0501 - acc: 1.0000 - val_loss: 0.7572 - val_acc: 0.5610\n",
            "Epoch 477/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0504 - acc: 1.0000 - val_loss: 0.7559 - val_acc: 0.5610\n",
            "Epoch 478/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0525 - acc: 1.0000 - val_loss: 0.7565 - val_acc: 0.5610\n",
            "Epoch 479/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0499 - acc: 1.0000 - val_loss: 0.7579 - val_acc: 0.5610\n",
            "Epoch 480/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.7597 - val_acc: 0.5610\n",
            "Epoch 481/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0494 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5610\n",
            "Epoch 482/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0506 - acc: 1.0000 - val_loss: 0.7546 - val_acc: 0.5610\n",
            "Epoch 483/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0491 - acc: 1.0000 - val_loss: 0.7498 - val_acc: 0.5610\n",
            "Epoch 484/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.7485 - val_acc: 0.5610\n",
            "Epoch 485/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0483 - acc: 1.0000 - val_loss: 0.7470 - val_acc: 0.5610\n",
            "Epoch 486/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0523 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.5610\n",
            "Epoch 487/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0488 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.5610\n",
            "Epoch 488/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.7412 - val_acc: 0.5610\n",
            "Epoch 489/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0497 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.5610\n",
            "Epoch 490/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.5610\n",
            "Epoch 491/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0503 - acc: 1.0000 - val_loss: 0.7401 - val_acc: 0.5610\n",
            "Epoch 492/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0474 - acc: 1.0000 - val_loss: 0.7407 - val_acc: 0.5610\n",
            "Epoch 493/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0512 - acc: 1.0000 - val_loss: 0.7413 - val_acc: 0.5610\n",
            "Epoch 494/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0478 - acc: 1.0000 - val_loss: 0.7395 - val_acc: 0.5610\n",
            "Epoch 495/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0477 - acc: 1.0000 - val_loss: 0.7403 - val_acc: 0.5610\n",
            "Epoch 496/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0482 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.5610\n",
            "Epoch 497/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0475 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.5610\n",
            "Epoch 498/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.5610\n",
            "Epoch 499/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0483 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.5610\n",
            "Epoch 500/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0487 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.5610\n",
            "Epoch 501/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0475 - acc: 1.0000 - val_loss: 0.7342 - val_acc: 0.5610\n",
            "Epoch 502/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.7376 - val_acc: 0.5610\n",
            "Epoch 503/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0466 - acc: 1.0000 - val_loss: 0.7402 - val_acc: 0.5610\n",
            "Epoch 504/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.7420 - val_acc: 0.5610\n",
            "Epoch 505/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0468 - acc: 1.0000 - val_loss: 0.7443 - val_acc: 0.5610\n",
            "Epoch 506/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0467 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.5610\n",
            "Epoch 507/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0470 - acc: 1.0000 - val_loss: 0.7460 - val_acc: 0.5610\n",
            "Epoch 508/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.7457 - val_acc: 0.5610\n",
            "Epoch 509/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0454 - acc: 1.0000 - val_loss: 0.7438 - val_acc: 0.5610\n",
            "Epoch 510/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0465 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.5610\n",
            "Epoch 511/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.5610\n",
            "Epoch 512/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0448 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.5610\n",
            "Epoch 513/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0450 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.5610\n",
            "Epoch 514/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.7473 - val_acc: 0.5610\n",
            "Epoch 515/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0460 - acc: 1.0000 - val_loss: 0.7500 - val_acc: 0.5610\n",
            "Epoch 516/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0456 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.5610\n",
            "Epoch 517/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0446 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.5610\n",
            "Epoch 518/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0452 - acc: 1.0000 - val_loss: 0.7523 - val_acc: 0.5610\n",
            "Epoch 519/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0492 - acc: 1.0000 - val_loss: 0.7535 - val_acc: 0.5610\n",
            "Epoch 520/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0447 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5610\n",
            "Epoch 521/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0432 - acc: 1.0000 - val_loss: 0.7541 - val_acc: 0.5610\n",
            "Epoch 522/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0463 - acc: 1.0000 - val_loss: 0.7544 - val_acc: 0.5610\n",
            "Epoch 523/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0461 - acc: 1.0000 - val_loss: 0.7530 - val_acc: 0.5610\n",
            "Epoch 524/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0436 - acc: 1.0000 - val_loss: 0.7504 - val_acc: 0.5610\n",
            "Epoch 525/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0464 - acc: 1.0000 - val_loss: 0.7503 - val_acc: 0.5610\n",
            "Epoch 526/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0442 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 0.5610\n",
            "Epoch 527/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0438 - acc: 1.0000 - val_loss: 0.7491 - val_acc: 0.5610\n",
            "Epoch 528/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0443 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.5610\n",
            "Epoch 529/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.7414 - val_acc: 0.5610\n",
            "Epoch 530/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0426 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.5610\n",
            "Epoch 531/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0453 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.5610\n",
            "Epoch 532/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0455 - acc: 1.0000 - val_loss: 0.7386 - val_acc: 0.5610\n",
            "Epoch 533/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.7386 - val_acc: 0.5610\n",
            "Epoch 534/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0435 - acc: 1.0000 - val_loss: 0.7366 - val_acc: 0.5610\n",
            "Epoch 535/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0434 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.5610\n",
            "Epoch 536/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0433 - acc: 1.0000 - val_loss: 0.7353 - val_acc: 0.5610\n",
            "Epoch 537/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.5610\n",
            "Epoch 538/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0425 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.5610\n",
            "Epoch 539/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.5732\n",
            "Epoch 540/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0424 - acc: 1.0000 - val_loss: 0.7346 - val_acc: 0.5732\n",
            "Epoch 541/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0437 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.5732\n",
            "Epoch 542/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0422 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 0.5732\n",
            "Epoch 543/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0417 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.5610\n",
            "Epoch 544/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 0.5610\n",
            "Epoch 545/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0429 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.5610\n",
            "Epoch 546/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0411 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.5610\n",
            "Epoch 547/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0415 - acc: 1.0000 - val_loss: 0.7297 - val_acc: 0.5610\n",
            "Epoch 548/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.5610\n",
            "Epoch 549/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0407 - acc: 1.0000 - val_loss: 0.7320 - val_acc: 0.5610\n",
            "Epoch 550/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.5610\n",
            "Epoch 551/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0404 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.5610\n",
            "Epoch 552/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0421 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.5610\n",
            "Epoch 553/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0402 - acc: 1.0000 - val_loss: 0.7396 - val_acc: 0.5610\n",
            "Epoch 554/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0412 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.5610\n",
            "Epoch 555/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0411 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.5610\n",
            "Epoch 556/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0393 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.5610\n",
            "Epoch 557/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0399 - acc: 1.0000 - val_loss: 0.7362 - val_acc: 0.5610\n",
            "Epoch 558/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0403 - acc: 1.0000 - val_loss: 0.7392 - val_acc: 0.5610\n",
            "Epoch 559/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.7417 - val_acc: 0.5610\n",
            "Epoch 560/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.7411 - val_acc: 0.5610\n",
            "Epoch 561/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.7363 - val_acc: 0.5610\n",
            "Epoch 562/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0384 - acc: 1.0000 - val_loss: 0.7344 - val_acc: 0.5610\n",
            "Epoch 563/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0383 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.5610\n",
            "Epoch 564/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0406 - acc: 1.0000 - val_loss: 0.7385 - val_acc: 0.5610\n",
            "Epoch 565/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0398 - acc: 1.0000 - val_loss: 0.7427 - val_acc: 0.5610\n",
            "Epoch 566/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0386 - acc: 1.0000 - val_loss: 0.7398 - val_acc: 0.5610\n",
            "Epoch 567/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.7399 - val_acc: 0.5610\n",
            "Epoch 568/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0394 - acc: 1.0000 - val_loss: 0.7375 - val_acc: 0.5610\n",
            "Epoch 569/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.7393 - val_acc: 0.5610\n",
            "Epoch 570/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0400 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.5610\n",
            "Epoch 571/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0388 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.5610\n",
            "Epoch 572/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0397 - acc: 1.0000 - val_loss: 0.7428 - val_acc: 0.5610\n",
            "Epoch 573/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0392 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.5610\n",
            "Epoch 574/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0387 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.5610\n",
            "Epoch 575/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.5610\n",
            "Epoch 576/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0385 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.5610\n",
            "Epoch 577/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 0.7400 - val_acc: 0.5610\n",
            "Epoch 578/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0395 - acc: 1.0000 - val_loss: 0.7433 - val_acc: 0.5610\n",
            "Epoch 579/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 0.7443 - val_acc: 0.5610\n",
            "Epoch 580/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0378 - acc: 1.0000 - val_loss: 0.7467 - val_acc: 0.5610\n",
            "Epoch 581/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0363 - acc: 1.0000 - val_loss: 0.7466 - val_acc: 0.5610\n",
            "Epoch 582/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.7465 - val_acc: 0.5610\n",
            "Epoch 583/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5610\n",
            "Epoch 584/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.7454 - val_acc: 0.5610\n",
            "Epoch 585/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.7471 - val_acc: 0.5610\n",
            "Epoch 586/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0376 - acc: 1.0000 - val_loss: 0.7436 - val_acc: 0.5610\n",
            "Epoch 587/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.5610\n",
            "Epoch 588/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0377 - acc: 1.0000 - val_loss: 0.7334 - val_acc: 0.5610\n",
            "Epoch 589/1500\n",
            "734/734 [==============================] - 0s 187us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.7328 - val_acc: 0.5610\n",
            "Epoch 590/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.7381 - val_acc: 0.5610\n",
            "Epoch 591/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0373 - acc: 1.0000 - val_loss: 0.7404 - val_acc: 0.5610\n",
            "Epoch 592/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0358 - acc: 1.0000 - val_loss: 0.7374 - val_acc: 0.5610\n",
            "Epoch 593/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.7352 - val_acc: 0.5610\n",
            "Epoch 594/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0359 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.5610\n",
            "Epoch 595/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.7341 - val_acc: 0.5610\n",
            "Epoch 596/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.7354 - val_acc: 0.5610\n",
            "Epoch 597/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.7361 - val_acc: 0.5610\n",
            "Epoch 598/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0367 - acc: 1.0000 - val_loss: 0.7365 - val_acc: 0.5610\n",
            "Epoch 599/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0389 - acc: 1.0000 - val_loss: 0.7336 - val_acc: 0.5610\n",
            "Epoch 600/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0353 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.5610\n",
            "Epoch 601/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0344 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.5610\n",
            "Epoch 602/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0364 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.5610\n",
            "Epoch 603/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0361 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.5610\n",
            "Epoch 604/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0355 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.5610\n",
            "Epoch 605/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0341 - acc: 1.0000 - val_loss: 0.7331 - val_acc: 0.5610\n",
            "Epoch 606/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0346 - acc: 1.0000 - val_loss: 0.7313 - val_acc: 0.5610\n",
            "Epoch 607/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0352 - acc: 1.0000 - val_loss: 0.7304 - val_acc: 0.5610\n",
            "Epoch 608/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0371 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 0.5610\n",
            "Epoch 609/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0339 - acc: 1.0000 - val_loss: 0.7293 - val_acc: 0.5610\n",
            "Epoch 610/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.5610\n",
            "Epoch 611/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0345 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.5610\n",
            "Epoch 612/1500\n",
            "734/734 [==============================] - 0s 187us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7305 - val_acc: 0.5610\n",
            "Epoch 613/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7318 - val_acc: 0.5610\n",
            "Epoch 614/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0356 - acc: 1.0000 - val_loss: 0.7305 - val_acc: 0.5610\n",
            "Epoch 615/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.7284 - val_acc: 0.5610\n",
            "Epoch 616/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0333 - acc: 1.0000 - val_loss: 0.7288 - val_acc: 0.5610\n",
            "Epoch 617/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.7280 - val_acc: 0.5610\n",
            "Epoch 618/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7256 - val_acc: 0.5610\n",
            "Epoch 619/1500\n",
            "734/734 [==============================] - 0s 181us/sample - loss: 0.0328 - acc: 1.0000 - val_loss: 0.7298 - val_acc: 0.5610\n",
            "Epoch 620/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0333 - acc: 1.0000 - val_loss: 0.7263 - val_acc: 0.5610\n",
            "Epoch 621/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0366 - acc: 1.0000 - val_loss: 0.7234 - val_acc: 0.5610\n",
            "Epoch 622/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.7215 - val_acc: 0.5610\n",
            "Epoch 623/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7224 - val_acc: 0.5610\n",
            "Epoch 624/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.7227 - val_acc: 0.5610\n",
            "Epoch 625/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.7253 - val_acc: 0.5610\n",
            "Epoch 626/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0325 - acc: 1.0000 - val_loss: 0.7239 - val_acc: 0.5732\n",
            "Epoch 627/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7272 - val_acc: 0.5732\n",
            "Epoch 628/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.5732\n",
            "Epoch 629/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0323 - acc: 1.0000 - val_loss: 0.7330 - val_acc: 0.5610\n",
            "Epoch 630/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0354 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.5610\n",
            "Epoch 631/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0324 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.5610\n",
            "Epoch 632/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0340 - acc: 1.0000 - val_loss: 0.7291 - val_acc: 0.5610\n",
            "Epoch 633/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7301 - val_acc: 0.5610\n",
            "Epoch 634/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.5610\n",
            "Epoch 635/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0326 - acc: 1.0000 - val_loss: 0.7269 - val_acc: 0.5732\n",
            "Epoch 636/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.5732\n",
            "Epoch 637/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0311 - acc: 1.0000 - val_loss: 0.7283 - val_acc: 0.5732\n",
            "Epoch 638/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0316 - acc: 1.0000 - val_loss: 0.7300 - val_acc: 0.5732\n",
            "Epoch 639/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.5732\n",
            "Epoch 640/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.7412 - val_acc: 0.5732\n",
            "Epoch 641/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5732\n",
            "Epoch 642/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0322 - acc: 1.0000 - val_loss: 0.7428 - val_acc: 0.5732\n",
            "Epoch 643/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0318 - acc: 1.0000 - val_loss: 0.7451 - val_acc: 0.5610\n",
            "Epoch 644/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0331 - acc: 1.0000 - val_loss: 0.7444 - val_acc: 0.5610\n",
            "Epoch 645/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.7447 - val_acc: 0.5610\n",
            "Epoch 646/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0309 - acc: 1.0000 - val_loss: 0.7456 - val_acc: 0.5610\n",
            "Epoch 647/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0334 - acc: 1.0000 - val_loss: 0.7475 - val_acc: 0.5610\n",
            "Epoch 648/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0314 - acc: 1.0000 - val_loss: 0.7478 - val_acc: 0.5610\n",
            "Epoch 649/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0304 - acc: 1.0000 - val_loss: 0.7472 - val_acc: 0.5610\n",
            "Epoch 650/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0305 - acc: 1.0000 - val_loss: 0.7496 - val_acc: 0.5610\n",
            "Epoch 651/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.7533 - val_acc: 0.5610\n",
            "Epoch 652/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0335 - acc: 1.0000 - val_loss: 0.7509 - val_acc: 0.5610\n",
            "Epoch 653/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.7505 - val_acc: 0.5610\n",
            "Epoch 654/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0330 - acc: 1.0000 - val_loss: 0.7455 - val_acc: 0.5610\n",
            "Epoch 655/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0310 - acc: 1.0000 - val_loss: 0.7487 - val_acc: 0.5610\n",
            "Epoch 656/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0320 - acc: 1.0000 - val_loss: 0.7495 - val_acc: 0.5610\n",
            "Epoch 657/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7507 - val_acc: 0.5732\n",
            "Epoch 658/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0293 - acc: 1.0000 - val_loss: 0.7500 - val_acc: 0.5732\n",
            "Epoch 659/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.7500 - val_acc: 0.5732\n",
            "Epoch 660/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0296 - acc: 1.0000 - val_loss: 0.7515 - val_acc: 0.5854\n",
            "Epoch 661/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0319 - acc: 1.0000 - val_loss: 0.7483 - val_acc: 0.5854\n",
            "Epoch 662/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.5854\n",
            "Epoch 663/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7458 - val_acc: 0.5854\n",
            "Epoch 664/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7479 - val_acc: 0.5732\n",
            "Epoch 665/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.5732\n",
            "Epoch 666/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.5732\n",
            "Epoch 667/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0308 - acc: 1.0000 - val_loss: 0.7453 - val_acc: 0.5732\n",
            "Epoch 668/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7425 - val_acc: 0.5732\n",
            "Epoch 669/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0285 - acc: 1.0000 - val_loss: 0.7430 - val_acc: 0.5732\n",
            "Epoch 670/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0290 - acc: 1.0000 - val_loss: 0.7442 - val_acc: 0.5732\n",
            "Epoch 671/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0287 - acc: 1.0000 - val_loss: 0.7459 - val_acc: 0.5732\n",
            "Epoch 672/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0292 - acc: 1.0000 - val_loss: 0.7468 - val_acc: 0.5732\n",
            "Epoch 673/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.7489 - val_acc: 0.5732\n",
            "Epoch 674/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0298 - acc: 1.0000 - val_loss: 0.7522 - val_acc: 0.5732\n",
            "Epoch 675/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.7567 - val_acc: 0.5732\n",
            "Epoch 676/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0284 - acc: 1.0000 - val_loss: 0.7569 - val_acc: 0.5610\n",
            "Epoch 677/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.7568 - val_acc: 0.5610\n",
            "Epoch 678/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0299 - acc: 1.0000 - val_loss: 0.7662 - val_acc: 0.5610\n",
            "Epoch 679/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0291 - acc: 1.0000 - val_loss: 0.7680 - val_acc: 0.5610\n",
            "Epoch 680/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.7676 - val_acc: 0.5610\n",
            "Epoch 681/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0271 - acc: 1.0000 - val_loss: 0.7692 - val_acc: 0.5610\n",
            "Epoch 682/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0289 - acc: 1.0000 - val_loss: 0.7655 - val_acc: 0.5610\n",
            "Epoch 683/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0283 - acc: 1.0000 - val_loss: 0.7614 - val_acc: 0.5610\n",
            "Epoch 684/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.7619 - val_acc: 0.5610\n",
            "Epoch 685/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0279 - acc: 1.0000 - val_loss: 0.7584 - val_acc: 0.5610\n",
            "Epoch 686/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.7582 - val_acc: 0.5610\n",
            "Epoch 687/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0269 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.5610\n",
            "Epoch 688/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0282 - acc: 1.0000 - val_loss: 0.7480 - val_acc: 0.5610\n",
            "Epoch 689/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0277 - acc: 1.0000 - val_loss: 0.7465 - val_acc: 0.5610\n",
            "Epoch 690/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.7375 - val_acc: 0.5610\n",
            "Epoch 691/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.7340 - val_acc: 0.5610\n",
            "Epoch 692/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0276 - acc: 1.0000 - val_loss: 0.7285 - val_acc: 0.5732\n",
            "Epoch 693/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0281 - acc: 1.0000 - val_loss: 0.7264 - val_acc: 0.5854\n",
            "Epoch 694/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0288 - acc: 1.0000 - val_loss: 0.7287 - val_acc: 0.5854\n",
            "Epoch 695/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.7303 - val_acc: 0.5610\n",
            "Epoch 696/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0286 - acc: 1.0000 - val_loss: 0.7337 - val_acc: 0.5610\n",
            "Epoch 697/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.7322 - val_acc: 0.5610\n",
            "Epoch 698/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.5610\n",
            "Epoch 699/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.5610\n",
            "Epoch 700/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0270 - acc: 1.0000 - val_loss: 0.7309 - val_acc: 0.5610\n",
            "Epoch 701/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0273 - acc: 1.0000 - val_loss: 0.7332 - val_acc: 0.5610\n",
            "Epoch 702/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0272 - acc: 1.0000 - val_loss: 0.7359 - val_acc: 0.5610\n",
            "Epoch 703/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0307 - acc: 1.0000 - val_loss: 0.7370 - val_acc: 0.5610\n",
            "Epoch 704/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0261 - acc: 1.0000 - val_loss: 0.7343 - val_acc: 0.5610\n",
            "Epoch 705/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0278 - acc: 1.0000 - val_loss: 0.7373 - val_acc: 0.5610\n",
            "Epoch 706/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.7352 - val_acc: 0.5610\n",
            "Epoch 707/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.7357 - val_acc: 0.5610\n",
            "Epoch 708/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.7341 - val_acc: 0.5610\n",
            "Epoch 709/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0262 - acc: 1.0000 - val_loss: 0.7348 - val_acc: 0.5610\n",
            "Epoch 710/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0268 - acc: 1.0000 - val_loss: 0.7377 - val_acc: 0.5732\n",
            "Epoch 711/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.7360 - val_acc: 0.5732\n",
            "Epoch 712/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.7335 - val_acc: 0.5854\n",
            "Epoch 713/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0253 - acc: 1.0000 - val_loss: 0.7292 - val_acc: 0.5854\n",
            "Epoch 714/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.7271 - val_acc: 0.5854\n",
            "Epoch 715/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.7249 - val_acc: 0.5854\n",
            "Epoch 716/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0256 - acc: 1.0000 - val_loss: 0.7252 - val_acc: 0.5976\n",
            "Epoch 717/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0260 - acc: 1.0000 - val_loss: 0.7220 - val_acc: 0.5976\n",
            "Epoch 718/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0255 - acc: 1.0000 - val_loss: 0.7217 - val_acc: 0.5854\n",
            "Epoch 719/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.7201 - val_acc: 0.5976\n",
            "Epoch 720/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.7187 - val_acc: 0.6098\n",
            "Epoch 721/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.7158 - val_acc: 0.6098\n",
            "Epoch 722/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0266 - acc: 1.0000 - val_loss: 0.7106 - val_acc: 0.6098\n",
            "Epoch 723/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.7072 - val_acc: 0.6098\n",
            "Epoch 724/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0248 - acc: 1.0000 - val_loss: 0.7082 - val_acc: 0.5976\n",
            "Epoch 725/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.7145 - val_acc: 0.5976\n",
            "Epoch 726/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.7125 - val_acc: 0.5976\n",
            "Epoch 727/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0263 - acc: 1.0000 - val_loss: 0.7064 - val_acc: 0.6098\n",
            "Epoch 728/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0257 - acc: 1.0000 - val_loss: 0.7016 - val_acc: 0.6220\n",
            "Epoch 729/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0247 - acc: 1.0000 - val_loss: 0.6989 - val_acc: 0.6220\n",
            "Epoch 730/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0264 - acc: 1.0000 - val_loss: 0.6958 - val_acc: 0.6220\n",
            "Epoch 731/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.6970 - val_acc: 0.6098\n",
            "Epoch 732/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0251 - acc: 1.0000 - val_loss: 0.6948 - val_acc: 0.6220\n",
            "Epoch 733/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6942 - val_acc: 0.6220\n",
            "Epoch 734/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6931 - val_acc: 0.6220\n",
            "Epoch 735/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0258 - acc: 1.0000 - val_loss: 0.6945 - val_acc: 0.6220\n",
            "Epoch 736/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0246 - acc: 1.0000 - val_loss: 0.6980 - val_acc: 0.6220\n",
            "Epoch 737/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0250 - acc: 1.0000 - val_loss: 0.7031 - val_acc: 0.6098\n",
            "Epoch 738/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0239 - acc: 1.0000 - val_loss: 0.7007 - val_acc: 0.6220\n",
            "Epoch 739/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0249 - acc: 1.0000 - val_loss: 0.6964 - val_acc: 0.6220\n",
            "Epoch 740/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6963 - val_acc: 0.6220\n",
            "Epoch 741/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6951 - val_acc: 0.6098\n",
            "Epoch 742/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0241 - acc: 1.0000 - val_loss: 0.6951 - val_acc: 0.5976\n",
            "Epoch 743/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0240 - acc: 1.0000 - val_loss: 0.6926 - val_acc: 0.6098\n",
            "Epoch 744/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6866 - val_acc: 0.6220\n",
            "Epoch 745/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.6832 - val_acc: 0.6220\n",
            "Epoch 746/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6789 - val_acc: 0.6463\n",
            "Epoch 747/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0252 - acc: 1.0000 - val_loss: 0.6746 - val_acc: 0.6463\n",
            "Epoch 748/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.6772 - val_acc: 0.6463\n",
            "Epoch 749/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0232 - acc: 1.0000 - val_loss: 0.6766 - val_acc: 0.6341\n",
            "Epoch 750/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0245 - acc: 1.0000 - val_loss: 0.6793 - val_acc: 0.6220\n",
            "Epoch 751/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0233 - acc: 1.0000 - val_loss: 0.6872 - val_acc: 0.6098\n",
            "Epoch 752/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0242 - acc: 1.0000 - val_loss: 0.6877 - val_acc: 0.6098\n",
            "Epoch 753/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0238 - acc: 1.0000 - val_loss: 0.6829 - val_acc: 0.6098\n",
            "Epoch 754/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0230 - acc: 1.0000 - val_loss: 0.6804 - val_acc: 0.6098\n",
            "Epoch 755/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6815 - val_acc: 0.6098\n",
            "Epoch 756/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6797 - val_acc: 0.6220\n",
            "Epoch 757/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6826 - val_acc: 0.6220\n",
            "Epoch 758/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.6831 - val_acc: 0.6220\n",
            "Epoch 759/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0237 - acc: 1.0000 - val_loss: 0.6810 - val_acc: 0.6220\n",
            "Epoch 760/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6807 - val_acc: 0.6220\n",
            "Epoch 761/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0243 - acc: 1.0000 - val_loss: 0.6822 - val_acc: 0.6220\n",
            "Epoch 762/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.6845 - val_acc: 0.6220\n",
            "Epoch 763/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0235 - acc: 1.0000 - val_loss: 0.6844 - val_acc: 0.6341\n",
            "Epoch 764/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6786 - val_acc: 0.6341\n",
            "Epoch 765/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.6806 - val_acc: 0.6341\n",
            "Epoch 766/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6797 - val_acc: 0.6463\n",
            "Epoch 767/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.6463\n",
            "Epoch 768/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6778 - val_acc: 0.6463\n",
            "Epoch 769/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0227 - acc: 1.0000 - val_loss: 0.6762 - val_acc: 0.6463\n",
            "Epoch 770/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0231 - acc: 1.0000 - val_loss: 0.6744 - val_acc: 0.6463\n",
            "Epoch 771/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0229 - acc: 1.0000 - val_loss: 0.6752 - val_acc: 0.6463\n",
            "Epoch 772/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6755 - val_acc: 0.6463\n",
            "Epoch 773/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0226 - acc: 1.0000 - val_loss: 0.6757 - val_acc: 0.6463\n",
            "Epoch 774/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0228 - acc: 1.0000 - val_loss: 0.6794 - val_acc: 0.6463\n",
            "Epoch 775/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0236 - acc: 1.0000 - val_loss: 0.6768 - val_acc: 0.6341\n",
            "Epoch 776/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0220 - acc: 1.0000 - val_loss: 0.6785 - val_acc: 0.6341\n",
            "Epoch 777/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0215 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.6341\n",
            "Epoch 778/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6754 - val_acc: 0.6341\n",
            "Epoch 779/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0222 - acc: 1.0000 - val_loss: 0.6708 - val_acc: 0.6463\n",
            "Epoch 780/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0234 - acc: 1.0000 - val_loss: 0.6712 - val_acc: 0.6463\n",
            "Epoch 781/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0216 - acc: 1.0000 - val_loss: 0.6760 - val_acc: 0.6463\n",
            "Epoch 782/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6761 - val_acc: 0.6463\n",
            "Epoch 783/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6775 - val_acc: 0.6585\n",
            "Epoch 784/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6743 - val_acc: 0.6585\n",
            "Epoch 785/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6733 - val_acc: 0.6463\n",
            "Epoch 786/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6736 - val_acc: 0.6585\n",
            "Epoch 787/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6727 - val_acc: 0.6585\n",
            "Epoch 788/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6729 - val_acc: 0.6585\n",
            "Epoch 789/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6696 - val_acc: 0.6463\n",
            "Epoch 790/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0221 - acc: 1.0000 - val_loss: 0.6676 - val_acc: 0.6463\n",
            "Epoch 791/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6666 - val_acc: 0.6463\n",
            "Epoch 792/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6639 - val_acc: 0.6707\n",
            "Epoch 793/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6669 - val_acc: 0.6585\n",
            "Epoch 794/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0204 - acc: 1.0000 - val_loss: 0.6661 - val_acc: 0.6585\n",
            "Epoch 795/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0213 - acc: 1.0000 - val_loss: 0.6606 - val_acc: 0.6585\n",
            "Epoch 796/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6583 - val_acc: 0.6707\n",
            "Epoch 797/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0224 - acc: 1.0000 - val_loss: 0.6620 - val_acc: 0.6707\n",
            "Epoch 798/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6621 - val_acc: 0.6707\n",
            "Epoch 799/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6625 - val_acc: 0.6707\n",
            "Epoch 800/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6626 - val_acc: 0.6707\n",
            "Epoch 801/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6642 - val_acc: 0.6707\n",
            "Epoch 802/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6651 - val_acc: 0.6585\n",
            "Epoch 803/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6604 - val_acc: 0.6707\n",
            "Epoch 804/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6613 - val_acc: 0.6585\n",
            "Epoch 805/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0207 - acc: 1.0000 - val_loss: 0.6605 - val_acc: 0.6707\n",
            "Epoch 806/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.6585\n",
            "Epoch 807/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.6585\n",
            "Epoch 808/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.6600 - val_acc: 0.6585\n",
            "Epoch 809/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6597 - val_acc: 0.6707\n",
            "Epoch 810/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.6707\n",
            "Epoch 811/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0199 - acc: 1.0000 - val_loss: 0.6509 - val_acc: 0.6829\n",
            "Epoch 812/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.6829\n",
            "Epoch 813/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0202 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.6829\n",
            "Epoch 814/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0206 - acc: 1.0000 - val_loss: 0.6545 - val_acc: 0.6707\n",
            "Epoch 815/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0200 - acc: 1.0000 - val_loss: 0.6528 - val_acc: 0.6707\n",
            "Epoch 816/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0191 - acc: 1.0000 - val_loss: 0.6515 - val_acc: 0.6707\n",
            "Epoch 817/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0208 - acc: 1.0000 - val_loss: 0.6524 - val_acc: 0.6707\n",
            "Epoch 818/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.6829\n",
            "Epoch 819/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0197 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.6829\n",
            "Epoch 820/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0210 - acc: 1.0000 - val_loss: 0.6569 - val_acc: 0.6829\n",
            "Epoch 821/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0211 - acc: 1.0000 - val_loss: 0.6565 - val_acc: 0.6829\n",
            "Epoch 822/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0195 - acc: 1.0000 - val_loss: 0.6550 - val_acc: 0.6707\n",
            "Epoch 823/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6540 - val_acc: 0.6707\n",
            "Epoch 824/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6572 - val_acc: 0.6707\n",
            "Epoch 825/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6569 - val_acc: 0.6585\n",
            "Epoch 826/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0193 - acc: 1.0000 - val_loss: 0.6582 - val_acc: 0.6585\n",
            "Epoch 827/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6564 - val_acc: 0.6585\n",
            "Epoch 828/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6571 - val_acc: 0.6585\n",
            "Epoch 829/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.6585\n",
            "Epoch 830/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0218 - acc: 1.0000 - val_loss: 0.6577 - val_acc: 0.6585\n",
            "Epoch 831/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0214 - acc: 1.0000 - val_loss: 0.6593 - val_acc: 0.6585\n",
            "Epoch 832/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0212 - acc: 1.0000 - val_loss: 0.6549 - val_acc: 0.6585\n",
            "Epoch 833/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0182 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.6585\n",
            "Epoch 834/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0192 - acc: 1.0000 - val_loss: 0.6532 - val_acc: 0.6585\n",
            "Epoch 835/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6523 - val_acc: 0.6585\n",
            "Epoch 836/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 0.6585\n",
            "Epoch 837/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0196 - acc: 1.0000 - val_loss: 0.6511 - val_acc: 0.6585\n",
            "Epoch 838/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6568 - val_acc: 0.6585\n",
            "Epoch 839/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0186 - acc: 1.0000 - val_loss: 0.6619 - val_acc: 0.6585\n",
            "Epoch 840/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6623 - val_acc: 0.6585\n",
            "Epoch 841/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6578 - val_acc: 0.6585\n",
            "Epoch 842/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0178 - acc: 1.0000 - val_loss: 0.6563 - val_acc: 0.6585\n",
            "Epoch 843/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6538 - val_acc: 0.6585\n",
            "Epoch 844/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.6707\n",
            "Epoch 845/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6543 - val_acc: 0.6707\n",
            "Epoch 846/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6537 - val_acc: 0.6829\n",
            "Epoch 847/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6555 - val_acc: 0.6585\n",
            "Epoch 848/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6520 - val_acc: 0.6707\n",
            "Epoch 849/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6529 - val_acc: 0.6707\n",
            "Epoch 850/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0188 - acc: 1.0000 - val_loss: 0.6560 - val_acc: 0.6829\n",
            "Epoch 851/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0194 - acc: 1.0000 - val_loss: 0.6494 - val_acc: 0.6829\n",
            "Epoch 852/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0183 - acc: 1.0000 - val_loss: 0.6436 - val_acc: 0.6951\n",
            "Epoch 853/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0176 - acc: 1.0000 - val_loss: 0.6475 - val_acc: 0.6829\n",
            "Epoch 854/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0180 - acc: 1.0000 - val_loss: 0.6452 - val_acc: 0.6951\n",
            "Epoch 855/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6450 - val_acc: 0.6951\n",
            "Epoch 856/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0177 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.6951\n",
            "Epoch 857/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0190 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.6951\n",
            "Epoch 858/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6434 - val_acc: 0.6951\n",
            "Epoch 859/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6451 - val_acc: 0.6829\n",
            "Epoch 860/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0172 - acc: 1.0000 - val_loss: 0.6472 - val_acc: 0.6829\n",
            "Epoch 861/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0189 - acc: 1.0000 - val_loss: 0.6470 - val_acc: 0.6829\n",
            "Epoch 862/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0171 - acc: 1.0000 - val_loss: 0.6501 - val_acc: 0.6829\n",
            "Epoch 863/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6498 - val_acc: 0.6829\n",
            "Epoch 864/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6482 - val_acc: 0.6829\n",
            "Epoch 865/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6533 - val_acc: 0.6829\n",
            "Epoch 866/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6526 - val_acc: 0.6829\n",
            "Epoch 867/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6478 - val_acc: 0.6829\n",
            "Epoch 868/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6429 - val_acc: 0.6829\n",
            "Epoch 869/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0187 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.6951\n",
            "Epoch 870/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6438 - val_acc: 0.6951\n",
            "Epoch 871/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6429 - val_acc: 0.6951\n",
            "Epoch 872/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6416 - val_acc: 0.6951\n",
            "Epoch 873/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.6951\n",
            "Epoch 874/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6338 - val_acc: 0.6951\n",
            "Epoch 875/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0175 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.6951\n",
            "Epoch 876/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0170 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.6951\n",
            "Epoch 877/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 0.6951\n",
            "Epoch 878/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6259 - val_acc: 0.6951\n",
            "Epoch 879/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0185 - acc: 1.0000 - val_loss: 0.6285 - val_acc: 0.6951\n",
            "Epoch 880/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6286 - val_acc: 0.6951\n",
            "Epoch 881/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0174 - acc: 1.0000 - val_loss: 0.6327 - val_acc: 0.7073\n",
            "Epoch 882/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6298 - val_acc: 0.7073\n",
            "Epoch 883/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.6951\n",
            "Epoch 884/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6376 - val_acc: 0.6951\n",
            "Epoch 885/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6403 - val_acc: 0.6951\n",
            "Epoch 886/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6346 - val_acc: 0.6951\n",
            "Epoch 887/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6366 - val_acc: 0.6951\n",
            "Epoch 888/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0184 - acc: 1.0000 - val_loss: 0.6362 - val_acc: 0.6951\n",
            "Epoch 889/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0165 - acc: 1.0000 - val_loss: 0.6357 - val_acc: 0.6951\n",
            "Epoch 890/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6384 - val_acc: 0.6951\n",
            "Epoch 891/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6337 - val_acc: 0.7073\n",
            "Epoch 892/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6319 - val_acc: 0.7073\n",
            "Epoch 893/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6296 - val_acc: 0.7073\n",
            "Epoch 894/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6304 - val_acc: 0.7073\n",
            "Epoch 895/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6315 - val_acc: 0.7073\n",
            "Epoch 896/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6342 - val_acc: 0.7073\n",
            "Epoch 897/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0163 - acc: 1.0000 - val_loss: 0.6315 - val_acc: 0.7073\n",
            "Epoch 898/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6263 - val_acc: 0.7073\n",
            "Epoch 899/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0159 - acc: 1.0000 - val_loss: 0.6244 - val_acc: 0.7073\n",
            "Epoch 900/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0153 - acc: 1.0000 - val_loss: 0.6294 - val_acc: 0.7073\n",
            "Epoch 901/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0156 - acc: 1.0000 - val_loss: 0.6350 - val_acc: 0.7073\n",
            "Epoch 902/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6351 - val_acc: 0.7073\n",
            "Epoch 903/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6292 - val_acc: 0.7073\n",
            "Epoch 904/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.6313 - val_acc: 0.7073\n",
            "Epoch 905/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6316 - val_acc: 0.7073\n",
            "Epoch 906/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0160 - acc: 1.0000 - val_loss: 0.6354 - val_acc: 0.7073\n",
            "Epoch 907/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.6391 - val_acc: 0.7073\n",
            "Epoch 908/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.6413 - val_acc: 0.7073\n",
            "Epoch 909/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6397 - val_acc: 0.7073\n",
            "Epoch 910/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6406 - val_acc: 0.7073\n",
            "Epoch 911/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0167 - acc: 1.0000 - val_loss: 0.6381 - val_acc: 0.6951\n",
            "Epoch 912/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0164 - acc: 1.0000 - val_loss: 0.6390 - val_acc: 0.6951\n",
            "Epoch 913/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.6334 - val_acc: 0.6951\n",
            "Epoch 914/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0158 - acc: 1.0000 - val_loss: 0.6340 - val_acc: 0.6951\n",
            "Epoch 915/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0173 - acc: 1.0000 - val_loss: 0.6290 - val_acc: 0.6951\n",
            "Epoch 916/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.6271 - val_acc: 0.6951\n",
            "Epoch 917/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6262 - val_acc: 0.6951\n",
            "Epoch 918/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.6246 - val_acc: 0.6951\n",
            "Epoch 919/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.6224 - val_acc: 0.6951\n",
            "Epoch 920/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0169 - acc: 1.0000 - val_loss: 0.6183 - val_acc: 0.6951\n",
            "Epoch 921/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.6089 - val_acc: 0.6951\n",
            "Epoch 922/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.6031 - val_acc: 0.7195\n",
            "Epoch 923/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6015 - val_acc: 0.7195\n",
            "Epoch 924/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0157 - acc: 1.0000 - val_loss: 0.6033 - val_acc: 0.7195\n",
            "Epoch 925/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6069 - val_acc: 0.7195\n",
            "Epoch 926/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.6046 - val_acc: 0.7195\n",
            "Epoch 927/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0150 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7195\n",
            "Epoch 928/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0155 - acc: 1.0000 - val_loss: 0.6044 - val_acc: 0.7195\n",
            "Epoch 929/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0168 - acc: 1.0000 - val_loss: 0.6011 - val_acc: 0.7195\n",
            "Epoch 930/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0166 - acc: 1.0000 - val_loss: 0.5953 - val_acc: 0.7317\n",
            "Epoch 931/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.5925 - val_acc: 0.7439\n",
            "Epoch 932/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0162 - acc: 1.0000 - val_loss: 0.5908 - val_acc: 0.7561\n",
            "Epoch 933/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.5892 - val_acc: 0.7439\n",
            "Epoch 934/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0144 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.7683\n",
            "Epoch 935/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0152 - acc: 1.0000 - val_loss: 0.5826 - val_acc: 0.7683\n",
            "Epoch 936/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.5804 - val_acc: 0.7561\n",
            "Epoch 937/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5800 - val_acc: 0.7561\n",
            "Epoch 938/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5803 - val_acc: 0.7561\n",
            "Epoch 939/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0148 - acc: 1.0000 - val_loss: 0.5788 - val_acc: 0.7561\n",
            "Epoch 940/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.5832 - val_acc: 0.7683\n",
            "Epoch 941/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0151 - acc: 1.0000 - val_loss: 0.5834 - val_acc: 0.7683\n",
            "Epoch 942/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.7683\n",
            "Epoch 943/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.7683\n",
            "Epoch 944/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0133 - acc: 1.0000 - val_loss: 0.5791 - val_acc: 0.7683\n",
            "Epoch 945/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.7683\n",
            "Epoch 946/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.5864 - val_acc: 0.7683\n",
            "Epoch 947/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.5869 - val_acc: 0.7561\n",
            "Epoch 948/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0149 - acc: 1.0000 - val_loss: 0.5846 - val_acc: 0.7561\n",
            "Epoch 949/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5840 - val_acc: 0.7561\n",
            "Epoch 950/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5824 - val_acc: 0.7561\n",
            "Epoch 951/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.7561\n",
            "Epoch 952/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.5808 - val_acc: 0.7561\n",
            "Epoch 953/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0138 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.7561\n",
            "Epoch 954/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5812 - val_acc: 0.7561\n",
            "Epoch 955/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5817 - val_acc: 0.7561\n",
            "Epoch 956/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.7561\n",
            "Epoch 957/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5831 - val_acc: 0.7683\n",
            "Epoch 958/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0154 - acc: 1.0000 - val_loss: 0.5806 - val_acc: 0.7683\n",
            "Epoch 959/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0141 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.7683\n",
            "Epoch 960/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0132 - acc: 1.0000 - val_loss: 0.5781 - val_acc: 0.7683\n",
            "Epoch 961/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5792 - val_acc: 0.7683\n",
            "Epoch 962/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.7683\n",
            "Epoch 963/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0140 - acc: 1.0000 - val_loss: 0.5879 - val_acc: 0.7683\n",
            "Epoch 964/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.5873 - val_acc: 0.7683\n",
            "Epoch 965/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0145 - acc: 1.0000 - val_loss: 0.5880 - val_acc: 0.7683\n",
            "Epoch 966/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5950 - val_acc: 0.7683\n",
            "Epoch 967/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.5936 - val_acc: 0.7683\n",
            "Epoch 968/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.5956 - val_acc: 0.7683\n",
            "Epoch 969/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0139 - acc: 1.0000 - val_loss: 0.5980 - val_acc: 0.7683\n",
            "Epoch 970/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.6026 - val_acc: 0.7439\n",
            "Epoch 971/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5998 - val_acc: 0.7561\n",
            "Epoch 972/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.6014 - val_acc: 0.7317\n",
            "Epoch 973/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.6060 - val_acc: 0.7195\n",
            "Epoch 974/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0135 - acc: 1.0000 - val_loss: 0.6066 - val_acc: 0.7195\n",
            "Epoch 975/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.6036 - val_acc: 0.7195\n",
            "Epoch 976/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5991 - val_acc: 0.7317\n",
            "Epoch 977/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.5969 - val_acc: 0.7439\n",
            "Epoch 978/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5981 - val_acc: 0.7317\n",
            "Epoch 979/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.5979 - val_acc: 0.7683\n",
            "Epoch 980/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.5937 - val_acc: 0.7561\n",
            "Epoch 981/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0128 - acc: 1.0000 - val_loss: 0.5901 - val_acc: 0.7561\n",
            "Epoch 982/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5888 - val_acc: 0.7561\n",
            "Epoch 983/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0147 - acc: 1.0000 - val_loss: 0.5848 - val_acc: 0.7561\n",
            "Epoch 984/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0137 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.7561\n",
            "Epoch 985/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0146 - acc: 1.0000 - val_loss: 0.5806 - val_acc: 0.7561\n",
            "Epoch 986/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0143 - acc: 1.0000 - val_loss: 0.5755 - val_acc: 0.7561\n",
            "Epoch 987/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0131 - acc: 1.0000 - val_loss: 0.5758 - val_acc: 0.7439\n",
            "Epoch 988/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.7683\n",
            "Epoch 989/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5672 - val_acc: 0.7683\n",
            "Epoch 990/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0134 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.7561\n",
            "Epoch 991/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5652 - val_acc: 0.7683\n",
            "Epoch 992/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.7683\n",
            "Epoch 993/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.5636 - val_acc: 0.7683\n",
            "Epoch 994/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.7683\n",
            "Epoch 995/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5629 - val_acc: 0.7683\n",
            "Epoch 996/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.7561\n",
            "Epoch 997/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0130 - acc: 1.0000 - val_loss: 0.5647 - val_acc: 0.7683\n",
            "Epoch 998/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0125 - acc: 1.0000 - val_loss: 0.5669 - val_acc: 0.7805\n",
            "Epoch 999/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5693 - val_acc: 0.7561\n",
            "Epoch 1000/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.7561\n",
            "Epoch 1001/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0127 - acc: 1.0000 - val_loss: 0.5776 - val_acc: 0.7439\n",
            "Epoch 1002/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.7439\n",
            "Epoch 1003/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0119 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.7439\n",
            "Epoch 1004/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.7439\n",
            "Epoch 1005/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5829 - val_acc: 0.7317\n",
            "Epoch 1006/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0118 - acc: 1.0000 - val_loss: 0.5827 - val_acc: 0.7317\n",
            "Epoch 1007/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5807 - val_acc: 0.7317\n",
            "Epoch 1008/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0121 - acc: 1.0000 - val_loss: 0.5859 - val_acc: 0.7317\n",
            "Epoch 1009/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5902 - val_acc: 0.7195\n",
            "Epoch 1010/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5867 - val_acc: 0.7195\n",
            "Epoch 1011/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5865 - val_acc: 0.7195\n",
            "Epoch 1012/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5868 - val_acc: 0.7317\n",
            "Epoch 1013/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5846 - val_acc: 0.7317\n",
            "Epoch 1014/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5865 - val_acc: 0.7317\n",
            "Epoch 1015/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5849 - val_acc: 0.7317\n",
            "Epoch 1016/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0136 - acc: 1.0000 - val_loss: 0.5793 - val_acc: 0.7317\n",
            "Epoch 1017/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.7317\n",
            "Epoch 1018/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.7317\n",
            "Epoch 1019/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0124 - acc: 1.0000 - val_loss: 0.5775 - val_acc: 0.7317\n",
            "Epoch 1020/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5785 - val_acc: 0.7317\n",
            "Epoch 1021/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0129 - acc: 1.0000 - val_loss: 0.5722 - val_acc: 0.7439\n",
            "Epoch 1022/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5749 - val_acc: 0.7439\n",
            "Epoch 1023/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0123 - acc: 1.0000 - val_loss: 0.5724 - val_acc: 0.7439\n",
            "Epoch 1024/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5748 - val_acc: 0.7439\n",
            "Epoch 1025/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.5770 - val_acc: 0.7439\n",
            "Epoch 1026/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5779 - val_acc: 0.7439\n",
            "Epoch 1027/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.7439\n",
            "Epoch 1028/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5799 - val_acc: 0.7317\n",
            "Epoch 1029/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5802 - val_acc: 0.7195\n",
            "Epoch 1030/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5815 - val_acc: 0.7195\n",
            "Epoch 1031/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5782 - val_acc: 0.7195\n",
            "Epoch 1032/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0120 - acc: 1.0000 - val_loss: 0.5813 - val_acc: 0.7195\n",
            "Epoch 1033/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.5819 - val_acc: 0.7195\n",
            "Epoch 1034/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.7195\n",
            "Epoch 1035/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0122 - acc: 1.0000 - val_loss: 0.5797 - val_acc: 0.7195\n",
            "Epoch 1036/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0113 - acc: 1.0000 - val_loss: 0.5783 - val_acc: 0.7195\n",
            "Epoch 1037/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5777 - val_acc: 0.7195\n",
            "Epoch 1038/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5707 - val_acc: 0.7439\n",
            "Epoch 1039/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5690 - val_acc: 0.7439\n",
            "Epoch 1040/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0112 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.7439\n",
            "Epoch 1041/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0126 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.7683\n",
            "Epoch 1042/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.5630 - val_acc: 0.7683\n",
            "Epoch 1043/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0110 - acc: 1.0000 - val_loss: 0.5632 - val_acc: 0.7561\n",
            "Epoch 1044/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.7439\n",
            "Epoch 1045/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5738 - val_acc: 0.7317\n",
            "Epoch 1046/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5757 - val_acc: 0.7317\n",
            "Epoch 1047/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5735 - val_acc: 0.7317\n",
            "Epoch 1048/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5752 - val_acc: 0.7317\n",
            "Epoch 1049/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5764 - val_acc: 0.7317\n",
            "Epoch 1050/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5772 - val_acc: 0.7317\n",
            "Epoch 1051/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5767 - val_acc: 0.7317\n",
            "Epoch 1052/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0117 - acc: 1.0000 - val_loss: 0.5774 - val_acc: 0.7317\n",
            "Epoch 1053/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.5796 - val_acc: 0.7195\n",
            "Epoch 1054/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.7317\n",
            "Epoch 1055/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.5809 - val_acc: 0.7195\n",
            "Epoch 1056/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5773 - val_acc: 0.7317\n",
            "Epoch 1057/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0115 - acc: 1.0000 - val_loss: 0.5729 - val_acc: 0.7439\n",
            "Epoch 1058/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5703 - val_acc: 0.7439\n",
            "Epoch 1059/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0107 - acc: 1.0000 - val_loss: 0.5667 - val_acc: 0.7439\n",
            "Epoch 1060/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.7439\n",
            "Epoch 1061/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0104 - acc: 1.0000 - val_loss: 0.5614 - val_acc: 0.7439\n",
            "Epoch 1062/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.7561\n",
            "Epoch 1063/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0111 - acc: 1.0000 - val_loss: 0.5550 - val_acc: 0.7561\n",
            "Epoch 1064/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5478 - val_acc: 0.7561\n",
            "Epoch 1065/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.7561\n",
            "Epoch 1066/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.7561\n",
            "Epoch 1067/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.7561\n",
            "Epoch 1068/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.7561\n",
            "Epoch 1069/1500\n",
            "734/734 [==============================] - 0s 163us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.7561\n",
            "Epoch 1070/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5549 - val_acc: 0.7561\n",
            "Epoch 1071/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0116 - acc: 1.0000 - val_loss: 0.5556 - val_acc: 0.7561\n",
            "Epoch 1072/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5567 - val_acc: 0.7561\n",
            "Epoch 1073/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5553 - val_acc: 0.7561\n",
            "Epoch 1074/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5551 - val_acc: 0.7561\n",
            "Epoch 1075/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.7561\n",
            "Epoch 1076/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.7561\n",
            "Epoch 1077/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5533 - val_acc: 0.7561\n",
            "Epoch 1078/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0106 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.7561\n",
            "Epoch 1079/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0103 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.7561\n",
            "Epoch 1080/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5511 - val_acc: 0.7561\n",
            "Epoch 1081/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0105 - acc: 1.0000 - val_loss: 0.5559 - val_acc: 0.7439\n",
            "Epoch 1082/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0101 - acc: 1.0000 - val_loss: 0.5525 - val_acc: 0.7439\n",
            "Epoch 1083/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.7561\n",
            "Epoch 1084/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.7561\n",
            "Epoch 1085/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5545 - val_acc: 0.7561\n",
            "Epoch 1086/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5546 - val_acc: 0.7561\n",
            "Epoch 1087/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5549 - val_acc: 0.7561\n",
            "Epoch 1088/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.7561\n",
            "Epoch 1089/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.7561\n",
            "Epoch 1090/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.7561\n",
            "Epoch 1091/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.7561\n",
            "Epoch 1092/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0109 - acc: 1.0000 - val_loss: 0.5587 - val_acc: 0.7439\n",
            "Epoch 1093/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5651 - val_acc: 0.7561\n",
            "Epoch 1094/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.7561\n",
            "Epoch 1095/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.7561\n",
            "Epoch 1096/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5583 - val_acc: 0.7561\n",
            "Epoch 1097/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5571 - val_acc: 0.7561\n",
            "Epoch 1098/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5570 - val_acc: 0.7561\n",
            "Epoch 1099/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5576 - val_acc: 0.7683\n",
            "Epoch 1100/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5619 - val_acc: 0.7683\n",
            "Epoch 1101/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5614 - val_acc: 0.7683\n",
            "Epoch 1102/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.7683\n",
            "Epoch 1103/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5642 - val_acc: 0.7683\n",
            "Epoch 1104/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0093 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.7683\n",
            "Epoch 1105/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0102 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.7683\n",
            "Epoch 1106/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0114 - acc: 1.0000 - val_loss: 0.5643 - val_acc: 0.7561\n",
            "Epoch 1107/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5668 - val_acc: 0.7561\n",
            "Epoch 1108/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5645 - val_acc: 0.7683\n",
            "Epoch 1109/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5609 - val_acc: 0.7683\n",
            "Epoch 1110/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5591 - val_acc: 0.7683\n",
            "Epoch 1111/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5565 - val_acc: 0.7561\n",
            "Epoch 1112/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.7683\n",
            "Epoch 1113/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5569 - val_acc: 0.7561\n",
            "Epoch 1114/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5542 - val_acc: 0.7561\n",
            "Epoch 1115/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0099 - acc: 1.0000 - val_loss: 0.5528 - val_acc: 0.7561\n",
            "Epoch 1116/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.7561\n",
            "Epoch 1117/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.7561\n",
            "Epoch 1118/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5495 - val_acc: 0.7683\n",
            "Epoch 1119/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.7561\n",
            "Epoch 1120/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0094 - acc: 1.0000 - val_loss: 0.5527 - val_acc: 0.7683\n",
            "Epoch 1121/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.7683\n",
            "Epoch 1122/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.7805\n",
            "Epoch 1123/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0095 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.7805\n",
            "Epoch 1124/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.7683\n",
            "Epoch 1125/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.7683\n",
            "Epoch 1126/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5542 - val_acc: 0.7683\n",
            "Epoch 1127/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5577 - val_acc: 0.7683\n",
            "Epoch 1128/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5585 - val_acc: 0.7805\n",
            "Epoch 1129/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0098 - acc: 1.0000 - val_loss: 0.5605 - val_acc: 0.7805\n",
            "Epoch 1130/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5637 - val_acc: 0.7683\n",
            "Epoch 1131/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5664 - val_acc: 0.7683\n",
            "Epoch 1132/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0100 - acc: 1.0000 - val_loss: 0.5670 - val_acc: 0.7683\n",
            "Epoch 1133/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.7805\n",
            "Epoch 1134/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5630 - val_acc: 0.7805\n",
            "Epoch 1135/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5649 - val_acc: 0.7927\n",
            "Epoch 1136/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5652 - val_acc: 0.7683\n",
            "Epoch 1137/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0091 - acc: 1.0000 - val_loss: 0.5679 - val_acc: 0.7561\n",
            "Epoch 1138/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0087 - acc: 1.0000 - val_loss: 0.5715 - val_acc: 0.7561\n",
            "Epoch 1139/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5699 - val_acc: 0.7561\n",
            "Epoch 1140/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0097 - acc: 1.0000 - val_loss: 0.5670 - val_acc: 0.7561\n",
            "Epoch 1141/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0096 - acc: 1.0000 - val_loss: 0.5680 - val_acc: 0.7683\n",
            "Epoch 1142/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5633 - val_acc: 0.7561\n",
            "Epoch 1143/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5624 - val_acc: 0.7561\n",
            "Epoch 1144/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0092 - acc: 1.0000 - val_loss: 0.5652 - val_acc: 0.7683\n",
            "Epoch 1145/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5671 - val_acc: 0.7561\n",
            "Epoch 1146/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5724 - val_acc: 0.7683\n",
            "Epoch 1147/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5753 - val_acc: 0.7683\n",
            "Epoch 1148/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5712 - val_acc: 0.7683\n",
            "Epoch 1149/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5734 - val_acc: 0.7683\n",
            "Epoch 1150/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0090 - acc: 1.0000 - val_loss: 0.5729 - val_acc: 0.7683\n",
            "Epoch 1151/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0089 - acc: 1.0000 - val_loss: 0.5747 - val_acc: 0.7683\n",
            "Epoch 1152/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5681 - val_acc: 0.7805\n",
            "Epoch 1153/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.7561\n",
            "Epoch 1154/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5689 - val_acc: 0.7561\n",
            "Epoch 1155/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.7561\n",
            "Epoch 1156/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5642 - val_acc: 0.7561\n",
            "Epoch 1157/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5644 - val_acc: 0.7561\n",
            "Epoch 1158/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0088 - acc: 1.0000 - val_loss: 0.5679 - val_acc: 0.7561\n",
            "Epoch 1159/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5714 - val_acc: 0.7439\n",
            "Epoch 1160/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.7561\n",
            "Epoch 1161/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5692 - val_acc: 0.7561\n",
            "Epoch 1162/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5660 - val_acc: 0.7561\n",
            "Epoch 1163/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.7561\n",
            "Epoch 1164/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5673 - val_acc: 0.7561\n",
            "Epoch 1165/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5669 - val_acc: 0.7561\n",
            "Epoch 1166/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5695 - val_acc: 0.7561\n",
            "Epoch 1167/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5706 - val_acc: 0.7561\n",
            "Epoch 1168/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5696 - val_acc: 0.7561\n",
            "Epoch 1169/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5682 - val_acc: 0.7439\n",
            "Epoch 1170/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5668 - val_acc: 0.7439\n",
            "Epoch 1171/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.7561\n",
            "Epoch 1172/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5689 - val_acc: 0.7561\n",
            "Epoch 1173/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.7561\n",
            "Epoch 1174/1500\n",
            "734/734 [==============================] - 0s 183us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5718 - val_acc: 0.7561\n",
            "Epoch 1175/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0084 - acc: 1.0000 - val_loss: 0.5683 - val_acc: 0.7317\n",
            "Epoch 1176/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0086 - acc: 1.0000 - val_loss: 0.5664 - val_acc: 0.7317\n",
            "Epoch 1177/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5742 - val_acc: 0.7561\n",
            "Epoch 1178/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5772 - val_acc: 0.7561\n",
            "Epoch 1179/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5736 - val_acc: 0.7317\n",
            "Epoch 1180/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0078 - acc: 1.0000 - val_loss: 0.5731 - val_acc: 0.7439\n",
            "Epoch 1181/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5737 - val_acc: 0.7439\n",
            "Epoch 1182/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5732 - val_acc: 0.7439\n",
            "Epoch 1183/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0085 - acc: 1.0000 - val_loss: 0.5733 - val_acc: 0.7317\n",
            "Epoch 1184/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5768 - val_acc: 0.7317\n",
            "Epoch 1185/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5816 - val_acc: 0.7439\n",
            "Epoch 1186/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5786 - val_acc: 0.7561\n",
            "Epoch 1187/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5805 - val_acc: 0.7683\n",
            "Epoch 1188/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5811 - val_acc: 0.7561\n",
            "Epoch 1189/1500\n",
            "734/734 [==============================] - 0s 181us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5839 - val_acc: 0.7439\n",
            "Epoch 1190/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5851 - val_acc: 0.7195\n",
            "Epoch 1191/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0082 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.7195\n",
            "Epoch 1192/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5830 - val_acc: 0.7317\n",
            "Epoch 1193/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5823 - val_acc: 0.7317\n",
            "Epoch 1194/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5794 - val_acc: 0.7317\n",
            "Epoch 1195/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5857 - val_acc: 0.7439\n",
            "Epoch 1196/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5919 - val_acc: 0.7561\n",
            "Epoch 1197/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5928 - val_acc: 0.7561\n",
            "Epoch 1198/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5920 - val_acc: 0.7561\n",
            "Epoch 1199/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5862 - val_acc: 0.7561\n",
            "Epoch 1200/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5853 - val_acc: 0.7683\n",
            "Epoch 1201/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0076 - acc: 1.0000 - val_loss: 0.5835 - val_acc: 0.7683\n",
            "Epoch 1202/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5818 - val_acc: 0.7561\n",
            "Epoch 1203/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0081 - acc: 1.0000 - val_loss: 0.5780 - val_acc: 0.7439\n",
            "Epoch 1204/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0080 - acc: 1.0000 - val_loss: 0.5783 - val_acc: 0.7439\n",
            "Epoch 1205/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5708 - val_acc: 0.7561\n",
            "Epoch 1206/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5659 - val_acc: 0.7561\n",
            "Epoch 1207/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5646 - val_acc: 0.7561\n",
            "Epoch 1208/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5587 - val_acc: 0.7561\n",
            "Epoch 1209/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.7439\n",
            "Epoch 1210/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.7439\n",
            "Epoch 1211/1500\n",
            "734/734 [==============================] - 0s 179us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5601 - val_acc: 0.7439\n",
            "Epoch 1212/1500\n",
            "734/734 [==============================] - 0s 184us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.7439\n",
            "Epoch 1213/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5646 - val_acc: 0.7439\n",
            "Epoch 1214/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0079 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.7439\n",
            "Epoch 1215/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5588 - val_acc: 0.7439\n",
            "Epoch 1216/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5607 - val_acc: 0.7439\n",
            "Epoch 1217/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5601 - val_acc: 0.7561\n",
            "Epoch 1218/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5608 - val_acc: 0.7561\n",
            "Epoch 1219/1500\n",
            "734/734 [==============================] - 0s 185us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5634 - val_acc: 0.7561\n",
            "Epoch 1220/1500\n",
            "734/734 [==============================] - 0s 178us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5644 - val_acc: 0.7561\n",
            "Epoch 1221/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.7317\n",
            "Epoch 1222/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0077 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.7317\n",
            "Epoch 1223/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5626 - val_acc: 0.7317\n",
            "Epoch 1224/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5632 - val_acc: 0.7317\n",
            "Epoch 1225/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5614 - val_acc: 0.7317\n",
            "Epoch 1226/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0071 - acc: 1.0000 - val_loss: 0.5657 - val_acc: 0.7317\n",
            "Epoch 1227/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5648 - val_acc: 0.7317\n",
            "Epoch 1228/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5653 - val_acc: 0.7439\n",
            "Epoch 1229/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5660 - val_acc: 0.7561\n",
            "Epoch 1230/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5637 - val_acc: 0.7561\n",
            "Epoch 1231/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5618 - val_acc: 0.7439\n",
            "Epoch 1232/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5611 - val_acc: 0.7439\n",
            "Epoch 1233/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5625 - val_acc: 0.7561\n",
            "Epoch 1234/1500\n",
            "734/734 [==============================] - 0s 182us/sample - loss: 0.0083 - acc: 1.0000 - val_loss: 0.5632 - val_acc: 0.7439\n",
            "Epoch 1235/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.0074 - acc: 1.0000 - val_loss: 0.5610 - val_acc: 0.7439\n",
            "Epoch 1236/1500\n",
            "734/734 [==============================] - 0s 180us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5585 - val_acc: 0.7439\n",
            "Epoch 1237/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0070 - acc: 1.0000 - val_loss: 0.5575 - val_acc: 0.7439\n",
            "Epoch 1238/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5561 - val_acc: 0.7439\n",
            "Epoch 1239/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5579 - val_acc: 0.7439\n",
            "Epoch 1240/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0068 - acc: 1.0000 - val_loss: 0.5570 - val_acc: 0.7439\n",
            "Epoch 1241/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5529 - val_acc: 0.7439\n",
            "Epoch 1242/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0075 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.7439\n",
            "Epoch 1243/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.7439\n",
            "Epoch 1244/1500\n",
            "734/734 [==============================] - 0s 183us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5570 - val_acc: 0.7439\n",
            "Epoch 1245/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5599 - val_acc: 0.7439\n",
            "Epoch 1246/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5588 - val_acc: 0.7317\n",
            "Epoch 1247/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5535 - val_acc: 0.7317\n",
            "Epoch 1248/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5529 - val_acc: 0.7317\n",
            "Epoch 1249/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.7317\n",
            "Epoch 1250/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.7317\n",
            "Epoch 1251/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5502 - val_acc: 0.7195\n",
            "Epoch 1252/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.7195\n",
            "Epoch 1253/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5548 - val_acc: 0.7317\n",
            "Epoch 1254/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0069 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.7317\n",
            "Epoch 1255/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0073 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.7439\n",
            "Epoch 1256/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5566 - val_acc: 0.7439\n",
            "Epoch 1257/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5620 - val_acc: 0.7439\n",
            "Epoch 1258/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5623 - val_acc: 0.7439\n",
            "Epoch 1259/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5557 - val_acc: 0.7561\n",
            "Epoch 1260/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0072 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.7561\n",
            "Epoch 1261/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5540 - val_acc: 0.7439\n",
            "Epoch 1262/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0065 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.7439\n",
            "Epoch 1263/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5555 - val_acc: 0.7561\n",
            "Epoch 1264/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.7561\n",
            "Epoch 1265/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5468 - val_acc: 0.7561\n",
            "Epoch 1266/1500\n",
            "734/734 [==============================] - 0s 182us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5423 - val_acc: 0.7561\n",
            "Epoch 1267/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0067 - acc: 1.0000 - val_loss: 0.5430 - val_acc: 0.7561\n",
            "Epoch 1268/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5454 - val_acc: 0.7805\n",
            "Epoch 1269/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5435 - val_acc: 0.7805\n",
            "Epoch 1270/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5417 - val_acc: 0.7805\n",
            "Epoch 1271/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5425 - val_acc: 0.7805\n",
            "Epoch 1272/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.7805\n",
            "Epoch 1273/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5445 - val_acc: 0.7805\n",
            "Epoch 1274/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5429 - val_acc: 0.7683\n",
            "Epoch 1275/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5408 - val_acc: 0.7683\n",
            "Epoch 1276/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5418 - val_acc: 0.7683\n",
            "Epoch 1277/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5453 - val_acc: 0.7561\n",
            "Epoch 1278/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.7439\n",
            "Epoch 1279/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0064 - acc: 1.0000 - val_loss: 0.5492 - val_acc: 0.7439\n",
            "Epoch 1280/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0066 - acc: 1.0000 - val_loss: 0.5475 - val_acc: 0.7439\n",
            "Epoch 1281/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5494 - val_acc: 0.7439\n",
            "Epoch 1282/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5451 - val_acc: 0.7561\n",
            "Epoch 1283/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5437 - val_acc: 0.7561\n",
            "Epoch 1284/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5452 - val_acc: 0.7561\n",
            "Epoch 1285/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5430 - val_acc: 0.7561\n",
            "Epoch 1286/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5397 - val_acc: 0.7561\n",
            "Epoch 1287/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.7683\n",
            "Epoch 1288/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5360 - val_acc: 0.7805\n",
            "Epoch 1289/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5348 - val_acc: 0.7805\n",
            "Epoch 1290/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5361 - val_acc: 0.7805\n",
            "Epoch 1291/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5350 - val_acc: 0.7805\n",
            "Epoch 1292/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5353 - val_acc: 0.7805\n",
            "Epoch 1293/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5375 - val_acc: 0.7683\n",
            "Epoch 1294/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.7683\n",
            "Epoch 1295/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.7683\n",
            "Epoch 1296/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5384 - val_acc: 0.7683\n",
            "Epoch 1297/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5379 - val_acc: 0.7683\n",
            "Epoch 1298/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5413 - val_acc: 0.7683\n",
            "Epoch 1299/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5450 - val_acc: 0.7805\n",
            "Epoch 1300/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5468 - val_acc: 0.7805\n",
            "Epoch 1301/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5448 - val_acc: 0.7805\n",
            "Epoch 1302/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5488 - val_acc: 0.7805\n",
            "Epoch 1303/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5453 - val_acc: 0.7683\n",
            "Epoch 1304/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5410 - val_acc: 0.7683\n",
            "Epoch 1305/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5425 - val_acc: 0.7683\n",
            "Epoch 1306/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5481 - val_acc: 0.7805\n",
            "Epoch 1307/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.7805\n",
            "Epoch 1308/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.7683\n",
            "Epoch 1309/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.7683\n",
            "Epoch 1310/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5488 - val_acc: 0.7683\n",
            "Epoch 1311/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0062 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.7683\n",
            "Epoch 1312/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5434 - val_acc: 0.7683\n",
            "Epoch 1313/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5401 - val_acc: 0.7561\n",
            "Epoch 1314/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5396 - val_acc: 0.7683\n",
            "Epoch 1315/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0061 - acc: 1.0000 - val_loss: 0.5435 - val_acc: 0.7683\n",
            "Epoch 1316/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.7805\n",
            "Epoch 1317/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5448 - val_acc: 0.7683\n",
            "Epoch 1318/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.7561\n",
            "Epoch 1319/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5405 - val_acc: 0.7561\n",
            "Epoch 1320/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5363 - val_acc: 0.7561\n",
            "Epoch 1321/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5382 - val_acc: 0.7683\n",
            "Epoch 1322/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5414 - val_acc: 0.7683\n",
            "Epoch 1323/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5392 - val_acc: 0.7439\n",
            "Epoch 1324/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5377 - val_acc: 0.7439\n",
            "Epoch 1325/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5407 - val_acc: 0.7561\n",
            "Epoch 1326/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5425 - val_acc: 0.7561\n",
            "Epoch 1327/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0059 - acc: 1.0000 - val_loss: 0.5393 - val_acc: 0.7561\n",
            "Epoch 1328/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0058 - acc: 1.0000 - val_loss: 0.5402 - val_acc: 0.7561\n",
            "Epoch 1329/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5408 - val_acc: 0.7561\n",
            "Epoch 1330/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5414 - val_acc: 0.7561\n",
            "Epoch 1331/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0060 - acc: 1.0000 - val_loss: 0.5429 - val_acc: 0.7439\n",
            "Epoch 1332/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5481 - val_acc: 0.7439\n",
            "Epoch 1333/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.7439\n",
            "Epoch 1334/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5495 - val_acc: 0.7439\n",
            "Epoch 1335/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.7439\n",
            "Epoch 1336/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5491 - val_acc: 0.7439\n",
            "Epoch 1337/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5523 - val_acc: 0.7317\n",
            "Epoch 1338/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5534 - val_acc: 0.7317\n",
            "Epoch 1339/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.7317\n",
            "Epoch 1340/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5517 - val_acc: 0.7317\n",
            "Epoch 1341/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5543 - val_acc: 0.7317\n",
            "Epoch 1342/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.7439\n",
            "Epoch 1343/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.7439\n",
            "Epoch 1344/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5573 - val_acc: 0.7439\n",
            "Epoch 1345/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5567 - val_acc: 0.7317\n",
            "Epoch 1346/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5542 - val_acc: 0.7439\n",
            "Epoch 1347/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5514 - val_acc: 0.7561\n",
            "Epoch 1348/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5502 - val_acc: 0.7561\n",
            "Epoch 1349/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5518 - val_acc: 0.7561\n",
            "Epoch 1350/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5497 - val_acc: 0.7561\n",
            "Epoch 1351/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5507 - val_acc: 0.7439\n",
            "Epoch 1352/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5552 - val_acc: 0.7561\n",
            "Epoch 1353/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5544 - val_acc: 0.7561\n",
            "Epoch 1354/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5556 - val_acc: 0.7561\n",
            "Epoch 1355/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.7561\n",
            "Epoch 1356/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0057 - acc: 1.0000 - val_loss: 0.5502 - val_acc: 0.7439\n",
            "Epoch 1357/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5529 - val_acc: 0.7561\n",
            "Epoch 1358/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5510 - val_acc: 0.7317\n",
            "Epoch 1359/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5489 - val_acc: 0.7439\n",
            "Epoch 1360/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5473 - val_acc: 0.7439\n",
            "Epoch 1361/1500\n",
            "734/734 [==============================] - 0s 177us/sample - loss: 0.0063 - acc: 1.0000 - val_loss: 0.5447 - val_acc: 0.7439\n",
            "Epoch 1362/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0052 - acc: 1.0000 - val_loss: 0.5421 - val_acc: 0.7439\n",
            "Epoch 1363/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5397 - val_acc: 0.7439\n",
            "Epoch 1364/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5399 - val_acc: 0.7439\n",
            "Epoch 1365/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0056 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.7439\n",
            "Epoch 1366/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.7439\n",
            "Epoch 1367/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5532 - val_acc: 0.7439\n",
            "Epoch 1368/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5536 - val_acc: 0.7439\n",
            "Epoch 1369/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5556 - val_acc: 0.7439\n",
            "Epoch 1370/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5539 - val_acc: 0.7439\n",
            "Epoch 1371/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.7439\n",
            "Epoch 1372/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5508 - val_acc: 0.7439\n",
            "Epoch 1373/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.7561\n",
            "Epoch 1374/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5519 - val_acc: 0.7439\n",
            "Epoch 1375/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5477 - val_acc: 0.7439\n",
            "Epoch 1376/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5476 - val_acc: 0.7439\n",
            "Epoch 1377/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.7439\n",
            "Epoch 1378/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5458 - val_acc: 0.7439\n",
            "Epoch 1379/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5423 - val_acc: 0.7439\n",
            "Epoch 1380/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5403 - val_acc: 0.7439\n",
            "Epoch 1381/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5389 - val_acc: 0.7561\n",
            "Epoch 1382/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5356 - val_acc: 0.7561\n",
            "Epoch 1383/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5359 - val_acc: 0.7561\n",
            "Epoch 1384/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0054 - acc: 1.0000 - val_loss: 0.5359 - val_acc: 0.7561\n",
            "Epoch 1385/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5377 - val_acc: 0.7561\n",
            "Epoch 1386/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5415 - val_acc: 0.7561\n",
            "Epoch 1387/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0051 - acc: 1.0000 - val_loss: 0.5420 - val_acc: 0.7561\n",
            "Epoch 1388/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5416 - val_acc: 0.7439\n",
            "Epoch 1389/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5384 - val_acc: 0.7439\n",
            "Epoch 1390/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0055 - acc: 1.0000 - val_loss: 0.5376 - val_acc: 0.7439\n",
            "Epoch 1391/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5405 - val_acc: 0.7561\n",
            "Epoch 1392/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5421 - val_acc: 0.7561\n",
            "Epoch 1393/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5389 - val_acc: 0.7561\n",
            "Epoch 1394/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5390 - val_acc: 0.7683\n",
            "Epoch 1395/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5435 - val_acc: 0.7683\n",
            "Epoch 1396/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5485 - val_acc: 0.7561\n",
            "Epoch 1397/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5473 - val_acc: 0.7683\n",
            "Epoch 1398/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.7683\n",
            "Epoch 1399/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5475 - val_acc: 0.7683\n",
            "Epoch 1400/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5450 - val_acc: 0.7683\n",
            "Epoch 1401/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5432 - val_acc: 0.7683\n",
            "Epoch 1402/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5415 - val_acc: 0.7683\n",
            "Epoch 1403/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5412 - val_acc: 0.7683\n",
            "Epoch 1404/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0049 - acc: 1.0000 - val_loss: 0.5380 - val_acc: 0.7683\n",
            "Epoch 1405/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5370 - val_acc: 0.7683\n",
            "Epoch 1406/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5389 - val_acc: 0.7683\n",
            "Epoch 1407/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0050 - acc: 1.0000 - val_loss: 0.5408 - val_acc: 0.7683\n",
            "Epoch 1408/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5409 - val_acc: 0.7683\n",
            "Epoch 1409/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0047 - acc: 1.0000 - val_loss: 0.5392 - val_acc: 0.7683\n",
            "Epoch 1410/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5394 - val_acc: 0.7683\n",
            "Epoch 1411/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5400 - val_acc: 0.7683\n",
            "Epoch 1412/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.7683\n",
            "Epoch 1413/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5396 - val_acc: 0.7683\n",
            "Epoch 1414/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5427 - val_acc: 0.7683\n",
            "Epoch 1415/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0053 - acc: 1.0000 - val_loss: 0.5439 - val_acc: 0.7683\n",
            "Epoch 1416/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.7683\n",
            "Epoch 1417/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5474 - val_acc: 0.7683\n",
            "Epoch 1418/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.7561\n",
            "Epoch 1419/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.7561\n",
            "Epoch 1420/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.7683\n",
            "Epoch 1421/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5471 - val_acc: 0.7683\n",
            "Epoch 1422/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5476 - val_acc: 0.7683\n",
            "Epoch 1423/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5484 - val_acc: 0.7683\n",
            "Epoch 1424/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5460 - val_acc: 0.7683\n",
            "Epoch 1425/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5447 - val_acc: 0.7683\n",
            "Epoch 1426/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5426 - val_acc: 0.7683\n",
            "Epoch 1427/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5412 - val_acc: 0.7683\n",
            "Epoch 1428/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5403 - val_acc: 0.7683\n",
            "Epoch 1429/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.7683\n",
            "Epoch 1430/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5388 - val_acc: 0.7683\n",
            "Epoch 1431/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0048 - acc: 1.0000 - val_loss: 0.5385 - val_acc: 0.7683\n",
            "Epoch 1432/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5398 - val_acc: 0.7683\n",
            "Epoch 1433/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5395 - val_acc: 0.7683\n",
            "Epoch 1434/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0046 - acc: 1.0000 - val_loss: 0.5426 - val_acc: 0.7683\n",
            "Epoch 1435/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5480 - val_acc: 0.7683\n",
            "Epoch 1436/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5483 - val_acc: 0.7683\n",
            "Epoch 1437/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.7683\n",
            "Epoch 1438/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5498 - val_acc: 0.7561\n",
            "Epoch 1439/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.7561\n",
            "Epoch 1440/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5509 - val_acc: 0.7561\n",
            "Epoch 1441/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5516 - val_acc: 0.7561\n",
            "Epoch 1442/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5475 - val_acc: 0.7683\n",
            "Epoch 1443/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5512 - val_acc: 0.7439\n",
            "Epoch 1444/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5537 - val_acc: 0.7439\n",
            "Epoch 1445/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5514 - val_acc: 0.7683\n",
            "Epoch 1446/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5490 - val_acc: 0.7683\n",
            "Epoch 1447/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5493 - val_acc: 0.7683\n",
            "Epoch 1448/1500\n",
            "734/734 [==============================] - 0s 176us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5487 - val_acc: 0.7683\n",
            "Epoch 1449/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5467 - val_acc: 0.7683\n",
            "Epoch 1450/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5482 - val_acc: 0.7683\n",
            "Epoch 1451/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.7683\n",
            "Epoch 1452/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5436 - val_acc: 0.7683\n",
            "Epoch 1453/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0043 - acc: 1.0000 - val_loss: 0.5441 - val_acc: 0.7683\n",
            "Epoch 1454/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5502 - val_acc: 0.7561\n",
            "Epoch 1455/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5541 - val_acc: 0.7561\n",
            "Epoch 1456/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5520 - val_acc: 0.7561\n",
            "Epoch 1457/1500\n",
            "734/734 [==============================] - 0s 172us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5500 - val_acc: 0.7683\n",
            "Epoch 1458/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5486 - val_acc: 0.7683\n",
            "Epoch 1459/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5496 - val_acc: 0.7561\n",
            "Epoch 1460/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5530 - val_acc: 0.7439\n",
            "Epoch 1461/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5531 - val_acc: 0.7561\n",
            "Epoch 1462/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.7561\n",
            "Epoch 1463/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.7561\n",
            "Epoch 1464/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5582 - val_acc: 0.7439\n",
            "Epoch 1465/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5596 - val_acc: 0.7561\n",
            "Epoch 1466/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5594 - val_acc: 0.7561\n",
            "Epoch 1467/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0041 - acc: 1.0000 - val_loss: 0.5569 - val_acc: 0.7561\n",
            "Epoch 1468/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0042 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.7561\n",
            "Epoch 1469/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5546 - val_acc: 0.7561\n",
            "Epoch 1470/1500\n",
            "734/734 [==============================] - 0s 165us/sample - loss: 0.0045 - acc: 1.0000 - val_loss: 0.5527 - val_acc: 0.7561\n",
            "Epoch 1471/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5521 - val_acc: 0.7561\n",
            "Epoch 1472/1500\n",
            "734/734 [==============================] - 0s 174us/sample - loss: 0.0040 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.7561\n",
            "Epoch 1473/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5539 - val_acc: 0.7561\n",
            "Epoch 1474/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5536 - val_acc: 0.7561\n",
            "Epoch 1475/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5560 - val_acc: 0.7561\n",
            "Epoch 1476/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.7683\n",
            "Epoch 1477/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5547 - val_acc: 0.7683\n",
            "Epoch 1478/1500\n",
            "734/734 [==============================] - 0s 175us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5554 - val_acc: 0.7683\n",
            "Epoch 1479/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5559 - val_acc: 0.7683\n",
            "Epoch 1480/1500\n",
            "734/734 [==============================] - 0s 173us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5526 - val_acc: 0.7683\n",
            "Epoch 1481/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0039 - acc: 1.0000 - val_loss: 0.5517 - val_acc: 0.7683\n",
            "Epoch 1482/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5515 - val_acc: 0.7683\n",
            "Epoch 1483/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5522 - val_acc: 0.7683\n",
            "Epoch 1484/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5503 - val_acc: 0.7683\n",
            "Epoch 1485/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5452 - val_acc: 0.7683\n",
            "Epoch 1486/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5446 - val_acc: 0.7683\n",
            "Epoch 1487/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0037 - acc: 1.0000 - val_loss: 0.5464 - val_acc: 0.7683\n",
            "Epoch 1488/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5501 - val_acc: 0.7683\n",
            "Epoch 1489/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0038 - acc: 1.0000 - val_loss: 0.5568 - val_acc: 0.7683\n",
            "Epoch 1490/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5622 - val_acc: 0.7683\n",
            "Epoch 1491/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0044 - acc: 1.0000 - val_loss: 0.5666 - val_acc: 0.7683\n",
            "Epoch 1492/1500\n",
            "734/734 [==============================] - 0s 167us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5658 - val_acc: 0.7683\n",
            "Epoch 1493/1500\n",
            "734/734 [==============================] - 0s 168us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5683 - val_acc: 0.7683\n",
            "Epoch 1494/1500\n",
            "734/734 [==============================] - 0s 164us/sample - loss: 0.0033 - acc: 1.0000 - val_loss: 0.5675 - val_acc: 0.7683\n",
            "Epoch 1495/1500\n",
            "734/734 [==============================] - 0s 169us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5673 - val_acc: 0.7805\n",
            "Epoch 1496/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5667 - val_acc: 0.7683\n",
            "Epoch 1497/1500\n",
            "734/734 [==============================] - 0s 170us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5687 - val_acc: 0.7805\n",
            "Epoch 1498/1500\n",
            "734/734 [==============================] - 0s 171us/sample - loss: 0.0035 - acc: 1.0000 - val_loss: 0.5723 - val_acc: 0.7805\n",
            "Epoch 1499/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0034 - acc: 1.0000 - val_loss: 0.5679 - val_acc: 0.7683\n",
            "Epoch 1500/1500\n",
            "734/734 [==============================] - 0s 166us/sample - loss: 0.0036 - acc: 1.0000 - val_loss: 0.5630 - val_acc: 0.7683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "E32LWBFAkrSq",
        "colab_type": "code",
        "outputId": "773fb6a1-6c8c-4ff5-99d9-6284ee60eac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    \n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFACAYAAAC/abrtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "metadata": {
        "id": "0-L6gkT1k1yQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict_classes(X_test)\n",
        "y_score = model.predict(X_test)\n",
        "#y_pred= model.predict_classes(X_neutral)\n",
        "#y_test = y_netural\n",
        "\n",
        "for idx,p in enumerate(y_score):\n",
        "    if p >= 0.50:\n",
        "        y_pred[idx] = 1\n",
        "    else:\n",
        "        y_pred[idx] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7JLI_WVJkwcP",
        "colab_type": "code",
        "outputId": "16f7443a-96f9-497c-bd86-193cdd80d056",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred)))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"Kappa: {:.4f}\".format(cohen_kappa_score(y_test, y_pred)))\n",
        "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"F1: {:.4f}\".format(f1_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"Auc: {:.4f}\".format(roc_auc_score(y_test, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "[[37  5]\n",
            " [14 26]]\n",
            "Accuracy: 0.7683\n",
            "Kappa: 0.5338\n",
            "Precision: 0.8387\n",
            "Recall: 0.6500\n",
            "F1: 0.7324\n",
            "Auc: 0.7655\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WJ1mQbvOJaQl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save('nice_movie' + '_model2.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Nvz8Z9-J-TRJ",
        "colab_type": "code",
        "outputId": "5912d229-bd1d-465e-e618-efad668ff9a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install tmdbsimple\n",
        "\n",
        "import tmdbsimple as tmdb\n",
        "\n",
        "tmdb.API_KEY = '38dd5c6c01713ef99903275d51e2fd68'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tmdbsimple in /usr/local/lib/python3.6/dist-packages (2.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from tmdbsimple) (2.18.4)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbsimple) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbsimple) (1.22)\n",
            "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbsimple) (2.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->tmdbsimple) (2019.3.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "s-kzUQdq863L",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_likeness(film):\n",
        "  \n",
        "  search = tmdb.Search()\n",
        "  response = search.movie(query=film,language='es-ES')\n",
        "  \n",
        "  print(response)\n",
        "  \n",
        "\n",
        "  if len(response['results']) >= 1:\n",
        "    over = response['results'][0]['overview']\n",
        "    score = response['results'][0]['vote_average']\n",
        "    \n",
        "    id_movie = response['results'][0]['id']\n",
        "    \n",
        "    movie = tmdb.Movies(id_movie)\n",
        "    \n",
        "    actors = get_actors(movie.credits()['cast'])\n",
        "    director = get_director(movie.credits()['crew'])\n",
        "    \n",
        "    over = clean_overview(str(over))\n",
        "    over = delete_stop_words(over)\n",
        "\n",
        "    over = actors + ' ' + over\n",
        "    over = director + over\n",
        "    \n",
        "    print(over)\n",
        "    \n",
        "    X_over = tokenizer.texts_to_sequences(np.array([over]))\n",
        "    X_over = pad_sequences(X_over, padding='post', maxlen=maxlen)\n",
        "\n",
        "    probability = model.predict(X_over)\n",
        "    print(probability)\n",
        "    probability = probability[0][0] * 0.75 + (score/10)*0.25\n",
        "    \n",
        "    if (probability >= 0.5):\n",
        "        pred = 1\n",
        "        print(probability)\n",
        "        if (probability < 0.5):\n",
        "          probability = 0.5\n",
        "        \n",
        "    else:\n",
        "        pred = 0\n",
        "    \n",
        "    return (str(pred) , str(probability), score/10)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    return 'No existe la peli'\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "BRvFNL5nBlPU",
        "colab_type": "code",
        "outputId": "8c23ff4e-fdc5-485a-fa61-324e0bc4965b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "movie = tmdb.Movies(64)\n",
        "    \n",
        "get_director(movie.credits()['crew'])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'pedro_almodovar'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "metadata": {
        "id": "zYO4-m5wL3Ll",
        "colab_type": "code",
        "outputId": "8bb71c55-88a0-499d-fa1e-eb87971f4d1b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "cell_type": "code",
      "source": [
        "get_likeness(\"la boda de mi mejor amiga\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'page': 1, 'total_results': 1, 'total_pages': 1, 'results': [{'vote_count': 2682, 'id': 55721, 'video': False, 'vote_average': 6.5, 'title': 'La boda de mi mejor amiga', 'popularity': 13.59, 'poster_path': '/f5qGgjJYoG81SYAKF0VamjGrwd2.jpg', 'original_language': 'en', 'original_title': 'Bridesmaids', 'genre_ids': [35, 10749], 'backdrop_path': '/yMqCfrfz3QXGiurmXXP3pJIwKOR.jpg', 'adult': False, 'overview': 'Annie (Kristen Wiig) es una treintañera soltera del Medio Oeste, con una vida sentimental más bien precaria, a la que Lilliam, su mejor amiga (Maya Rudolph), le pide que sea su dama de honor. Sin embargo, aunque nunca ha ejercido esa función, la pobre se esfuerza por dárselas de snob en la fiesta anterior a la boda. Mientras tanto, otra amiga de Lillian (Rose Byrne) hará todo lo posible por arrebatarle el papel a la inexperta Annie', 'release_date': '2011-05-13'}]}\n",
            "paul_feig kristen_wiig maya_rudolph rose_byrne annie kristen wiig treintañera soltera oeste vida sentimental precaria lilliam amiga maya rudolph pide dama honor ejercido funcion pobre esfuerza darselas snob fiesta boda amiga lillian rose byrne hara arrebatarle papel inexperta annie\n",
            "[[0.00496199]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('0', '0.16622149306349457', 0.65)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 316
        }
      ]
    },
    {
      "metadata": {
        "id": "fuJocWX_CC8r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "word_embds = model.layers[1].get_weights()[0]\n",
        "word_list = []\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    word_list.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rvDRkNV0CFrm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "X_embedded = TSNE(n_components=2).fit_transform(word_embds)\n",
        "number_of_words = 1000\n",
        "trace = go.Scatter(\n",
        "    x = X_embedded[0:number_of_words,0], \n",
        "    y = X_embedded[0:number_of_words, 1],\n",
        "    mode = 'markers',\n",
        "    text= word_list[0:number_of_words]\n",
        ")\n",
        "layout = dict(title= 't-SNE 1 vs t-SNE 2 for sirst 1000 words ',\n",
        "              yaxis = dict(title='t-SNE 2'),\n",
        "              xaxis = dict(title='t-SNE 1'),\n",
        "              hovermode= 'closest')\n",
        "fig = dict(data = [trace], layout= layout)\n",
        "py.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fnSAd3BxBzGF",
        "colab_type": "code",
        "outputId": "6659672d-a142-4bab-f508-9c71f06a9e1d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        }
      },
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "#model = xgb.XGBClassifier(max_depth=10,n_estimators=150,silent=False,objective='binary:logistic')\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
              "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
              "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
              "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
              "       silent=True, subsample=1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 56
        }
      ]
    },
    {
      "metadata": {
        "id": "mR7WdupnB7pd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_score = model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FcrD_SolC9Qt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!pip install finetune"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFzRg88aDFdv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from finetune import Classifier\n",
        "\n",
        "model = Classifier()               # Load base model\n",
        "model.fit(X_train, y_train)          # Finetune base model on custom data\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}