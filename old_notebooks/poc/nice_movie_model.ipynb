{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nice-movie-model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "X4FsDixDIzQ9",
        "colab_type": "code",
        "outputId": "18821449-35c7-4b5e-9abe-9e4a1b6703fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPXkey0S6MsO",
        "colab_type": "code",
        "outputId": "e1e9c4e6-82bd-42b1-ecf1-885bcd94de21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Nov 18 19:48:08 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_eSPvzmPSA_J",
        "colab_type": "code",
        "outputId": "17e5b842-dba7-4dcb-eedf-0d62bedc6cbc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "%pip install nlpaug"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting nlpaug\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/45/ce353d60920cabe773de35ee8dac0989659c055540fa50eb0f6ac774e6f0/nlpaug-0.0.10-py3-none-any.whl (83kB)\n",
            "\r\u001b[K     |████                            | 10kB 17.5MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 20kB 2.2MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 30kB 3.2MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 40kB 2.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 51kB 2.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 61kB 3.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 71kB 3.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 81kB 4.0MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 92kB 3.4MB/s \n",
            "\u001b[?25hInstalling collected packages: nlpaug\n",
            "Successfully installed nlpaug-0.0.10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tMkEUmLmByo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%pip install torch>=1.2.0 transformers>=2.0.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rl4LFkMQoya5",
        "colab_type": "code",
        "outputId": "c34daaee-c0f1-47fd-f2f9-b00c9c174c21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 851
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import pandas as pd\n",
        "import time\n",
        "\n",
        "import numpy as np\n",
        "from numpy.random import seed\n",
        "seed(9)\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import set_random_seed\n",
        "set_random_seed(9)\n",
        "\n",
        "import json\n",
        "import nltk\n",
        "from nltk.tokenize import WordPunctTokenizer\n",
        "import keras\n",
        "import re\n",
        "\n",
        "nltk.download(\"popular\")\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading collection 'popular'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/cmudict.zip.\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gazetteers.zip.\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/genesis.zip.\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/inaugural.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/omw.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection popular\n",
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1urQMU5YkEC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataover = pd.read_csv(\"gdrive/My Drive/TFG/tmdb_spanish_def.csv\", sep='#',encoding='utf-8', lineterminator='\\n')\n",
        "taste = pd.read_csv(\"gdrive/My Drive/TFG/tmdb_spanish_Jaime_def.csv\", sep='#', encoding='utf-8')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZKXfq0GiJq6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "taste = taste[~taste['id'].str.contains('/')]\n",
        "taste['id'] = taste['id'].astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4mTpGIoaAq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Merge taste and credits\n",
        "\n",
        "data = taste.merge(dataover[['id','title','overview','genres','crew','cast']], left_on='id', right_on='id')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dWHa6AEIrQl",
        "colab_type": "code",
        "outputId": "85f85523-bc8c-4d52-dd02-9f88de86b6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 771
        }
      },
      "source": [
        "data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>like</th>\n",
              "      <th>title</th>\n",
              "      <th>overview</th>\n",
              "      <th>genres</th>\n",
              "      <th>crew</th>\n",
              "      <th>cast</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Four Rooms</td>\n",
              "      <td>Durante una Nochevieja, en un hotel de Los Áng...</td>\n",
              "      <td>[{'id': 80, 'name': 'Crimen'}, {'id': 35, 'nam...</td>\n",
              "      <td>[{'credit_id': '52fe420dc3a36847f800011b', 'de...</td>\n",
              "      <td>[{'cast_id': 42, 'character': 'Ted the Bellhop...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>11</td>\n",
              "      <td>1.0</td>\n",
              "      <td>La guerra de las galaxias. Episodio IV: Una nu...</td>\n",
              "      <td>La princesa Leia, líder del movimiento rebelde...</td>\n",
              "      <td>[{'id': 12, 'name': 'Aventura'}, {'id': 28, 'n...</td>\n",
              "      <td>[{'credit_id': '52fe420dc3a36847f8000437', 'de...</td>\n",
              "      <td>[{'cast_id': 3, 'character': 'Luke Skywalker',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Buscando a Nemo</td>\n",
              "      <td>Nemo, un pececillo, hijo único muy querido y p...</td>\n",
              "      <td>[{'id': 16, 'name': 'Animación'}, {'id': 10751...</td>\n",
              "      <td>[{'credit_id': '52fe420ec3a36847f8000653', 'de...</td>\n",
              "      <td>[{'cast_id': 8, 'character': 'Marlin (voice)',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>13</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Forrest Gump</td>\n",
              "      <td>Forrest Gump es un chico con deficiencias ment...</td>\n",
              "      <td>[{'id': 35, 'name': 'Comedia'}, {'id': 18, 'na...</td>\n",
              "      <td>[{'credit_id': '52fe420ec3a36847f800072d', 'de...</td>\n",
              "      <td>[{'cast_id': 7, 'character': 'Forrest Gump', '...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>14</td>\n",
              "      <td>NaN</td>\n",
              "      <td>American Beauty</td>\n",
              "      <td>Divertida, inquietante y sorprendente incursió...</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
              "      <td>[{'credit_id': '52fe420ec3a36847f80007c5', 'de...</td>\n",
              "      <td>[{'cast_id': 6, 'character': 'Lester Burnham',...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11549</th>\n",
              "      <td>397511</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Misfortune</td>\n",
              "      <td>Boyd, un mecánico desempleado, deberá buscar l...</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}, {'id': 80, 'name...</td>\n",
              "      <td>[{'credit_id': '57376693c3a36823b40038ad', 'de...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Boyd', 'credit_i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11550</th>\n",
              "      <td>348413</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Tango argentino</td>\n",
              "      <td>La profesora de tango argentina Valentina Mart...</td>\n",
              "      <td>[{'id': 18, 'name': 'Drama'}]</td>\n",
              "      <td>[{'credit_id': '55a26d71925141296e003744', 'de...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'Valentina Martin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11551</th>\n",
              "      <td>461264</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Ya no siento nada</td>\n",
              "      <td>Él es un mago. Ella es una bombera. Aislándose...</td>\n",
              "      <td>[{'id': 16, 'name': 'Animación'}]</td>\n",
              "      <td>[{'credit_id': '593b31ee925141059b0024b3', 'de...</td>\n",
              "      <td>[]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11552</th>\n",
              "      <td>429691</td>\n",
              "      <td>NaN</td>\n",
              "      <td>El proyecto supermente</td>\n",
              "      <td>En Los Ángeles, la tierra se estremece,  la ge...</td>\n",
              "      <td>[{'id': 28, 'name': 'Acción'}, {'id': 53, 'nam...</td>\n",
              "      <td>[{'credit_id': '584c723b9251411e35002a5b', 'de...</td>\n",
              "      <td>[{'cast_id': 1, 'character': 'General White', ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11553</th>\n",
              "      <td>420472</td>\n",
              "      <td>NaN</td>\n",
              "      <td>El complot</td>\n",
              "      <td>Cameron pensaba que tenía una vida perfecta co...</td>\n",
              "      <td>[{'id': 53, 'name': 'Suspense'}]</td>\n",
              "      <td>[{'credit_id': '5891d85d9251412dcb006cf9', 'de...</td>\n",
              "      <td>[{'cast_id': 8, 'character': 'Cameron', 'credi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>11554 rows × 7 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  ...                                               cast\n",
              "0           5  ...  [{'cast_id': 42, 'character': 'Ted the Bellhop...\n",
              "1          11  ...  [{'cast_id': 3, 'character': 'Luke Skywalker',...\n",
              "2          12  ...  [{'cast_id': 8, 'character': 'Marlin (voice)',...\n",
              "3          13  ...  [{'cast_id': 7, 'character': 'Forrest Gump', '...\n",
              "4          14  ...  [{'cast_id': 6, 'character': 'Lester Burnham',...\n",
              "...       ...  ...                                                ...\n",
              "11549  397511  ...  [{'cast_id': 1, 'character': 'Boyd', 'credit_i...\n",
              "11550  348413  ...  [{'cast_id': 1, 'character': 'Valentina Martin...\n",
              "11551  461264  ...                                                 []\n",
              "11552  429691  ...  [{'cast_id': 1, 'character': 'General White', ...\n",
              "11553  420472  ...  [{'cast_id': 8, 'character': 'Cameron', 'credi...\n",
              "\n",
              "[11554 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 162
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lhpyV6W4gXPh",
        "colab_type": "code",
        "outputId": "7775e8f4-e8e4-4949-d411-465c6863bbcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = data[~pd.isna(data.overview)]\n",
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11166"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 163
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zId8PUhkQX0",
        "colab_type": "code",
        "outputId": "d437d260-8dcb-4ec7-afbc-3374f230207d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "data = data.dropna(subset=['like'])\n",
        "data['like'] = data['like'].astype(int)\n",
        "data.reset_index(inplace=True,drop=True)\n",
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1109"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-l7_kcrl_Iv4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Clean overviews ver que ocurre con deadpool y deadpool 2 \n",
        "\n",
        "import string\n",
        "\n",
        "stop_words = pd.read_csv(\"gdrive/My Drive/TFG/stopwords-es.txt\",header=None)\n",
        "stop_words = stop_words[0].tolist() + ['secuela']\n",
        "\n",
        "def normalize(s):\n",
        "  s = s.lower()\n",
        "  replacements = (\n",
        "      (\"á\", \"a\"),\n",
        "      (\"é\", \"e\"),\n",
        "      (\"í\", \"i\"),\n",
        "      (\"ó\", \"o\"),\n",
        "      (\"ú\", \"u\"),\n",
        "      (\"ñ\", \"n\")\n",
        "  )\n",
        "  for a, b in replacements:\n",
        "      s = s.replace(a, b).replace(a.upper(), b.upper())\n",
        "  return s\n",
        "\n",
        "def split_punt(x):\n",
        "  words = WordPunctTokenizer().tokenize(x)\n",
        "  x = str(' '.join(words))\n",
        "  x = re.sub(' +', ' ', x)\n",
        "  return x\n",
        "\n",
        "def delete_stop_words(x):\n",
        "  x = x.translate(str.maketrans('','',string.punctuation))\n",
        "  x = x.translate(str.maketrans('','','1234567890ªº¡¿'))\n",
        "  words = x.split(' ')\n",
        "  words = [word for word in words if word not in stop_words]\n",
        "  x = str(' '.join(words))\n",
        "  return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJnmSCnwYzYd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data['overview']= data['overview'].apply(lambda x: split_punt(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSEAKnpeVyfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Steaming overview\n",
        "\n",
        "from nltk import word_tokenize\n",
        "from nltk.stem import SnowballStemmer\n",
        "\n",
        "stemmer = SnowballStemmer(\"spanish\", ignore_stopwords=True)\n",
        "\n",
        "def stem_sentence(sentence):\n",
        "  stemmed_text = [stemmer.stem(word) for word in word_tokenize(sentence)]\n",
        "  return \" \".join(stemmed_text)\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_hs9fQ23G_TW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import nlpaug.augmenter.char as nac\n",
        "import nlpaug.augmenter.word as naw\n",
        "import nlpaug.augmenter.sentence as nas\n",
        "import nlpaug.flow as naf\n",
        "\n",
        "from nlpaug.util import Action\n",
        "\n",
        "aug = naf.Sequential([\n",
        "    naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-cased', action=\"insert\", aug_p=0.1),\n",
        "    naw.ContextualWordEmbsAug(model_path='bert-base-multilingual-cased', action=\"substitute\", aug_p=0.9),\n",
        "    naw.RandomWordAug(action=\"delete\", aug_p=0.1)\n",
        "])\n",
        "\n",
        "def augment(x):\n",
        "  try:\n",
        "    return aug.augment(x)\n",
        "  except:\n",
        "    return None\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3D5xiv1eRzQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get staff and paste to overview\n",
        "\n",
        "def eval_cell(cell):\n",
        "  \n",
        "  try:\n",
        "    \n",
        "    cell_array = eval(cell)\n",
        "  \n",
        "  except:\n",
        "    \n",
        "    cell_array = []\n",
        "  \n",
        "  return cell_array\n",
        "\n",
        "def get_actors(cast):\n",
        "  \n",
        "  eval_cast = eval_cell(cast)\n",
        "  \n",
        "  if len(eval_cast) > 2:\n",
        "    up = 3\n",
        "  else:\n",
        "    up = len(eval_cast)\n",
        "\n",
        "  actors = ''\n",
        "  \n",
        "  for i in range(0,up):\n",
        "    actor = eval_cast[i]['name']\n",
        "    actor = normalize(actor.replace(' ','_').lower())\n",
        "  \n",
        "    actors = actors + ' ' + actor\n",
        "  \n",
        "  return actors\n",
        "\n",
        "def get_director(crew):\n",
        "  \n",
        "  eval_crew = eval_cell(crew)\n",
        "  \n",
        "  directors = [member['name'] for member in eval_crew if member['job'] == 'Director']\n",
        "  directors = [normalize(director.replace(' ','_').lower()) for director in directors]\n",
        "  directors = str(' '.join(directors))\n",
        "  \n",
        "  return directors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwp9UDLvh5Kw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = data[['overview','cast','crew','like']]\n",
        "\n",
        "train, test = train_test_split(df, test_size=0.15, stratify=df['like'], random_state=1996)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RmaaVM10hEqE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate training data\n",
        "\n",
        "train_aug_1 = train.copy()\n",
        "train_aug_1['overview'] = train_aug_1['overview'].apply(lambda x: augment(x))\n",
        "train_aug_1 = train_aug_1.dropna(subset=['overview'])\n",
        "\n",
        "train_aug_2 = train_aug_1.copy()\n",
        "train_aug_2['overview'] = train_aug_2['overview'].apply(lambda x: augment(x))\n",
        "train_aug_2 = train_aug_2.dropna(subset=['overview'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaefzNhLIcWf",
        "colab_type": "code",
        "outputId": "022f56ca-7c2f-4ff2-c3db-b50c9f878c33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train.iloc[0].overview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La supervivencia de la humanidad pende de un hilo , pero Beck , un héroe mortal , está decidido a salvar el mundo y a rescatar a su verdadero amor . Para conseguirlo busca la ayuda del poderoso dios Horus , con el que establecerá una alianza contra Set , el despiadado dios de la oscuridad que ha usurpado el trono de Egipto , sumiendo al país en el caos . Para ganar la batalla contra Set y sus secuaces tendrán que someterse a terribles pruebas de valentía y sacrificio .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xh40Fzlt-gvV",
        "colab_type": "code",
        "outputId": "241934ed-b1a7-4b68-ab81-7834d4a9f9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_aug_1.iloc[0].overview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La de su humanidad pende de nuevo hilo , pero Beck , un héroe solitario , a no salvar el y a rescatar a su verdadero amor . Para conseguirlo la ayuda técnica del poderoso Horus , con el que establecerá una alianza contra Set , es el despiadado y dios la oscuridad que ha usurpado definitivamente el dominio original de Egipto , sumiendo al país en el caos . terminar la batalla contra Set y sus secuaces tendrán que someterse a terribles pruebas y valentía y de sacrificio .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 176
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs4bZ2Rg-fbP",
        "colab_type": "code",
        "outputId": "a5f45509-e602-4f3f-bb0e-0faf99684177",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "train_aug_2.iloc[0].overview"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'La de su humanidad pende al nuevo hilo , pero Beck , un héroe virtual solitario , puede no salvar el tiempo a rescatar a su verdadero mundo . Para conseguirlo ayuda y técnica del prominente príncipe Horus , con el objetivo se establecerá una alianza contra Set , es el despiadado y dios la oscuridad que ha usurpado definitivamente su dominio ( original ) de , sumiendo al país por caos . terminar la batalla contra Set sus secuaces tendrán que someterse o moral de y de sacrificio .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 177
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcwVa4a1ilhu",
        "colab_type": "code",
        "outputId": "1719b1e5-53b1-4bc8-f053-789ea5d590d3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        }
      },
      "source": [
        "train_new = train.append(train_aug_1).append(train_aug_2)\n",
        "\n",
        "def transform_over(df):\n",
        "  df['overview'] = df['overview'].apply(lambda x: normalize(x))\n",
        "  df['overview'] = df['overview'].apply(lambda x: delete_stop_words(x))\n",
        "  df['overview'] = df['overview'].apply(lambda x: stem_sentence(x))\n",
        "  df['overview'] = df.apply(lambda x: get_actors(x['cast']) + ' ' + x['overview'] , axis=1)\n",
        "  df['overview'] = df.apply(lambda x: get_director(x['crew']) + x['overview'] , axis=1)\n",
        "  df['overview'] = df['overview'].apply(lambda x: normalize(x))\n",
        "  df['overview'] = df['overview'].apply(lambda x: delete_stop_words(x))\n",
        "\n",
        "  return df\n",
        "\n",
        "train_new = transform_over(train_new).reset_index()\n",
        "test_new = transform_over(test).reset_index()\n",
        "\n",
        "X_train = train_new.overview.values\n",
        "y_train = train_new.like.values\n",
        "X_test = test_new.overview.values\n",
        "y_test = test_new.like.values"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  import sys\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j5pooRddATyH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "columns_train = {'overview': X_train, 'like': y_train}\n",
        "train_df = pd.DataFrame(data=columns_train)\n",
        "train_df.to_csv('gdrive/My Drive/TFG/train' + '.csv', sep=';', encoding='utf-8', index=False)\n",
        "\n",
        "columns_test = {'overview': X_test, 'like': y_test}\n",
        "test_df = pd.DataFrame(data=columns_test)\n",
        "test_df.to_csv('gdrive/My Drive/TFG/test' + '.csv', sep=';', encoding='utf-8', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgMdTSe4Af9c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = pd.read_csv('gdrive/My Drive/TFG/train.csv', sep=';', encoding='utf-8')\n",
        "test_df = pd.read_csv('gdrive/My Drive/TFG/test.csv', sep=';', encoding='utf-8')\n",
        "\n",
        "X_train = train_df.overview.values\n",
        "y_train = train_df.like.values\n",
        "X_test = test_df.overview.values\n",
        "y_test = test_df.like.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytxLvkJL_F_s",
        "colab_type": "code",
        "outputId": "06fb8cf6-2c9c-403d-8d78-8105ad8d9105",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 459
        }
      },
      "source": [
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "\n",
        "over_lenghts = train_df.overview.str.split().apply(len)\n",
        "print(over_lenghts.describe())\n",
        "\n",
        "sns.distplot(over_lenghts)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "count    2788.000000\n",
            "mean       41.519727\n",
            "std        15.836761\n",
            "min         8.000000\n",
            "25%        30.000000\n",
            "50%        40.000000\n",
            "75%        52.000000\n",
            "max        91.000000\n",
            "Name: overview, dtype: float64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fef605c7080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEMCAYAAADAqxFbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n2hFIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKNbtClGH2BX",
        "colab_type": "code",
        "outputId": "6fb3dc84-e049-4dc1-f5d8-306e281c1722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "X_test[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'gasparnoe nathanielbrown pazdelahuerta cyrilroy oscar herman lind viv toky sobreviv trafic drog stripp club nocturn forceje polici oscar cae her dispar agoniz espiritu fiel promes abandon herman rechaz abandon mund viv espiritu vag ciud vision caotic filmaffinity'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1APEOOWyi-gO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Embedding\n",
        "num_words = 8000\n",
        "maxlen = 80"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lBLAw0i0i5j3",
        "colab_type": "code",
        "outputId": "3c748b9a-8b94-4eef-9465-898c8d3d0b21",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "tokenizer = Tokenizer() \n",
        "tokenizer.fit_on_texts(X_train)\n",
        "print(X_train[2]) \n",
        "\n",
        "X_train = tokenizer.texts_to_sequences(X_train) \n",
        "X_test = tokenizer.texts_to_sequences(X_test)\n",
        "\n",
        "vocab_size = len(tokenizer.word_index) + 1 # Adding 1 because of reserved 0 index\n",
        "\n",
        "print(X_train[2]) \n",
        "print(vocab_size)\n",
        "\n",
        "# Max length vector\n",
        "len(max(X_train, key=len))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "davidayer willsmith margotrobbie joelkinnaman gobiern ee uu respond visit alienigen tierr intencion malign amand mur wall lid agenci secret ofrec curios solucion reclut villan cruel habil letal magic trabaj demasi opcion negat supervillan peligr mund acced colabor ejecut peligr mision secret suic logr limpi expedient\n",
            "[2414, 585, 1570, 1916, 465, 998, 1399, 1186, 138, 159, 21, 353, 342, 907, 1703, 1296, 274, 406, 24, 335, 1571, 405, 296, 106, 734, 244, 508, 197, 235, 2281, 908, 1704, 1806, 20, 2, 1474, 466, 1187, 20, 33, 24, 1917, 108, 909, 948]\n",
            "10162\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "91"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7gUTUeS7CN_X",
        "colab_type": "code",
        "outputId": "a1434545-1514-497d-a4ef-98aebef43529",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max([max(i) for i in X_train])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10161"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQ_2DQpPJzlp",
        "colab_type": "code",
        "outputId": "0c75662f-143f-413b-b846-fe61f3c63cc2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "tokenizer.word_index"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'vid': 1,\n",
              " 'mund': 2,\n",
              " 'jov': 3,\n",
              " 'anos': 4,\n",
              " 'cas': 5,\n",
              " 'amig': 6,\n",
              " 'hij': 7,\n",
              " 'viv': 8,\n",
              " 'padr': 9,\n",
              " 'descubr': 10,\n",
              " 'human': 11,\n",
              " 'llam': 12,\n",
              " 'famili': 13,\n",
              " 'ayud': 14,\n",
              " 'conoc': 15,\n",
              " 'enfrent': 16,\n",
              " 'histori': 17,\n",
              " 'decid': 18,\n",
              " 'misteri': 19,\n",
              " 'peligr': 20,\n",
              " 'tierr': 21,\n",
              " 'lleg': 22,\n",
              " 'pequen': 23,\n",
              " 'secret': 24,\n",
              " 'busc': 25,\n",
              " 'hombr': 26,\n",
              " 'agent': 27,\n",
              " 'unic': 28,\n",
              " 'salv': 29,\n",
              " 'grup': 30,\n",
              " 'form': 31,\n",
              " 'luch': 32,\n",
              " 'mision': 33,\n",
              " 'viaj': 34,\n",
              " 'ciud': 35,\n",
              " 'encontr': 36,\n",
              " 'nin': 37,\n",
              " 'pas': 38,\n",
              " 'equip': 39,\n",
              " 'acab': 40,\n",
              " 'unk': 41,\n",
              " 'muert': 42,\n",
              " 'herman': 43,\n",
              " 'muj': 44,\n",
              " 'antigu': 45,\n",
              " 'tendr': 46,\n",
              " 'cre': 47,\n",
              " 'chic': 48,\n",
              " 'fuerz': 49,\n",
              " 'aventur': 50,\n",
              " 'planet': 51,\n",
              " 'dej': 52,\n",
              " 'cambi': 53,\n",
              " 'futur': 54,\n",
              " 'vuelv': 55,\n",
              " 'guerr': 56,\n",
              " 'madr': 57,\n",
              " 'pelicul': 58,\n",
              " 'convert': 59,\n",
              " 'seri': 60,\n",
              " 'polici': 61,\n",
              " 'deber': 62,\n",
              " 'qued': 63,\n",
              " 'joven': 64,\n",
              " 'asesin': 65,\n",
              " 'tom': 66,\n",
              " 'especial': 67,\n",
              " 'amenaz': 68,\n",
              " 'llev': 69,\n",
              " 'regres': 70,\n",
              " 'objet': 71,\n",
              " 'rein': 72,\n",
              " 'jam': 73,\n",
              " '́': 74,\n",
              " 'plan': 75,\n",
              " 'esper': 76,\n",
              " 'john': 77,\n",
              " 'entreg': 78,\n",
              " 'person': 79,\n",
              " 'amor': 80,\n",
              " 'perd': 81,\n",
              " 'enemig': 82,\n",
              " 'adolescent': 83,\n",
              " 'relacion': 84,\n",
              " 'junt': 85,\n",
              " 'comienz': 86,\n",
              " 'ultim': 87,\n",
              " 'estudi': 88,\n",
              " 'suen': 89,\n",
              " 'famos': 90,\n",
              " 'oscur': 91,\n",
              " 'univers': 92,\n",
              " 'man': 93,\n",
              " 'problem': 94,\n",
              " 'ano': 95,\n",
              " 'jef': 96,\n",
              " 'band': 97,\n",
              " 'bas': 98,\n",
              " 'dirig': 99,\n",
              " 'investig': 100,\n",
              " 'carrer': 101,\n",
              " 'viej': 102,\n",
              " 'empiez': 103,\n",
              " 'noch': 104,\n",
              " 'realid': 105,\n",
              " 'villan': 106,\n",
              " 'jueg': 107,\n",
              " 'logr': 108,\n",
              " 'camin': 109,\n",
              " 'pon': 110,\n",
              " 'complet': 111,\n",
              " 've': 112,\n",
              " 'gan': 113,\n",
              " 'volv': 114,\n",
              " 'destin': 115,\n",
              " 'libr': 116,\n",
              " 'unid': 117,\n",
              " 'mil': 118,\n",
              " 'profesor': 119,\n",
              " 'personaj': 120,\n",
              " 'intent': 121,\n",
              " 'puebl': 122,\n",
              " 'sag': 123,\n",
              " 'punt': 124,\n",
              " 'oblig': 125,\n",
              " 'encuentr': 126,\n",
              " 'ali': 127,\n",
              " 'segur': 128,\n",
              " 'extran': 129,\n",
              " 'real': 130,\n",
              " 'orden': 131,\n",
              " 'personal': 132,\n",
              " 'evit': 133,\n",
              " 'rey': 134,\n",
              " 'recuper': 135,\n",
              " 'criatur': 136,\n",
              " 'malv': 137,\n",
              " 'visit': 138,\n",
              " 'criminal': 139,\n",
              " 'entren': 140,\n",
              " 'trat': 141,\n",
              " 'destru': 142,\n",
              " 'dese': 143,\n",
              " 'conviert': 144,\n",
              " 'proteg': 145,\n",
              " 'envi': 146,\n",
              " 'novi': 147,\n",
              " 'cuy': 148,\n",
              " 'aparent': 149,\n",
              " 'companer': 150,\n",
              " 'cientif': 151,\n",
              " 'prueb': 152,\n",
              " 'ejercit': 153,\n",
              " 'recib': 154,\n",
              " 'rescat': 155,\n",
              " 'capit': 156,\n",
              " 'sobreviv': 157,\n",
              " 'terribl': 158,\n",
              " 'alienigen': 159,\n",
              " 'result': 160,\n",
              " 'negr': 161,\n",
              " 'original': 162,\n",
              " 'exit': 163,\n",
              " 'cab': 164,\n",
              " 'cuerp': 165,\n",
              " 'batall': 166,\n",
              " 'blanc': 167,\n",
              " 'mundial': 168,\n",
              " 'escap': 169,\n",
              " 'termin': 170,\n",
              " 'michael': 171,\n",
              " 'asesinat': 172,\n",
              " 'control': 173,\n",
              " 'terror': 174,\n",
              " 'pet': 175,\n",
              " 'bond': 176,\n",
              " 'trav': 177,\n",
              " 'hac': 178,\n",
              " 'combat': 179,\n",
              " 'bell': 180,\n",
              " 'inesper': 181,\n",
              " 'adaptacion': 182,\n",
              " 'york': 183,\n",
              " 'situacion': 184,\n",
              " 'parej': 185,\n",
              " 'accion': 186,\n",
              " 'espos': 187,\n",
              " 'guerrer': 188,\n",
              " 'enorm': 189,\n",
              " 'com': 190,\n",
              " 'princes': 191,\n",
              " 'mat': 192,\n",
              " 'nuev': 193,\n",
              " 'centr': 194,\n",
              " 'nombr': 195,\n",
              " 'popul': 196,\n",
              " 'magic': 197,\n",
              " 'continu': 198,\n",
              " 'utiliz': 199,\n",
              " 'import': 200,\n",
              " 'nav': 201,\n",
              " 'isla': 202,\n",
              " 'estrell': 203,\n",
              " 'reun': 204,\n",
              " 'espacial': 205,\n",
              " 'program': 206,\n",
              " 'dur': 207,\n",
              " 'venganz': 208,\n",
              " 'the': 209,\n",
              " 'acerc': 210,\n",
              " 'protagon': 211,\n",
              " 'inici': 212,\n",
              " 'hog': 213,\n",
              " 'monstru': 214,\n",
              " 'mar': 215,\n",
              " 'acompan': 216,\n",
              " 'lider': 217,\n",
              " 'principal': 218,\n",
              " 'hero': 219,\n",
              " 'aparec': 220,\n",
              " 'realment': 221,\n",
              " 'inteligent': 222,\n",
              " 'rest': 223,\n",
              " 'habit': 224,\n",
              " 'escond': 225,\n",
              " 'cin': 226,\n",
              " 'vist': 227,\n",
              " 'rob': 228,\n",
              " 'jack': 229,\n",
              " 'sold': 230,\n",
              " 'vigil': 231,\n",
              " 'raz': 232,\n",
              " 'enamor': 233,\n",
              " 'mortal': 234,\n",
              " 'trabaj': 235,\n",
              " 'her': 236,\n",
              " 'comun': 237,\n",
              " 'narr': 238,\n",
              " 'ide': 239,\n",
              " 'public': 240,\n",
              " 'doctor': 241,\n",
              " 'cumpl': 242,\n",
              " 'oficial': 243,\n",
              " 'habil': 244,\n",
              " 'destruccion': 245,\n",
              " 'existent': 246,\n",
              " 'detectiv': 247,\n",
              " 'ocurr': 248,\n",
              " 'miembr': 249,\n",
              " 'britan': 250,\n",
              " 'abandon': 251,\n",
              " 'dav': 252,\n",
              " 'atac': 253,\n",
              " 'secuestr': 254,\n",
              " 'complic': 255,\n",
              " 'milit': 256,\n",
              " 'mutant': 257,\n",
              " 'captur': 258,\n",
              " 'atrap': 259,\n",
              " 'rapid': 260,\n",
              " '«': 261,\n",
              " 'animal': 262,\n",
              " 'enter': 263,\n",
              " 'deten': 264,\n",
              " 'ric': 265,\n",
              " 'ataqu': 266,\n",
              " 'alici': 267,\n",
              " 'sup': 268,\n",
              " 'experiment': 269,\n",
              " 'internacional': 270,\n",
              " 'millon': 271,\n",
              " 'fiest': 272,\n",
              " 'espectacul': 273,\n",
              " 'lid': 274,\n",
              " 'med': 275,\n",
              " 'will': 276,\n",
              " 'ocasion': 277,\n",
              " 'jon': 278,\n",
              " 'super': 279,\n",
              " 'ident': 280,\n",
              " 'har': 281,\n",
              " 'luz': 282,\n",
              " 'clas': 283,\n",
              " 'busqued': 284,\n",
              " 'diner': 285,\n",
              " 'desarroll': 286,\n",
              " 'estadounidens': 287,\n",
              " 'encarg': 288,\n",
              " 'transform': 289,\n",
              " 'bruj': 290,\n",
              " 'desaparec': 291,\n",
              " 'corazon': 292,\n",
              " 'caus': 293,\n",
              " 'accident': 294,\n",
              " 'vengador': 295,\n",
              " 'reclut': 296,\n",
              " 'tem': 297,\n",
              " 'especi': 298,\n",
              " 'senor': 299,\n",
              " 'muer': 300,\n",
              " 'profund': 301,\n",
              " 'llen': 302,\n",
              " 'extraterrestr': 303,\n",
              " 'maquin': 304,\n",
              " 'desesper': 305,\n",
              " 'oportun': 306,\n",
              " 'practic': 307,\n",
              " 'ocult': 308,\n",
              " 'frank': 309,\n",
              " 'music': 310,\n",
              " 'angel': 311,\n",
              " 'vampir': 312,\n",
              " 'dios': 313,\n",
              " 'legendari': 314,\n",
              " 'ray': 315,\n",
              " 'puest': 316,\n",
              " 'comic': 317,\n",
              " 'supervivient': 318,\n",
              " 'manten': 319,\n",
              " 'resolv': 320,\n",
              " 'divert': 321,\n",
              " 'respons': 322,\n",
              " 'perr': 323,\n",
              " 'cont': 324,\n",
              " 'clasic': 325,\n",
              " 'infiltr': 326,\n",
              " 'modern': 327,\n",
              " 'facil': 328,\n",
              " 'sombr': 329,\n",
              " 'american': 330,\n",
              " 'normal': 331,\n",
              " 'par': 332,\n",
              " 'parec': 333,\n",
              " 'fantasm': 334,\n",
              " 'ofrec': 335,\n",
              " 'desafi': 336,\n",
              " '”': 337,\n",
              " 'ensen': 338,\n",
              " 'don': 339,\n",
              " 'comenz': 340,\n",
              " 'period': 341,\n",
              " 'malign': 342,\n",
              " 'frent': 343,\n",
              " 'empres': 344,\n",
              " 'present': 345,\n",
              " 'lord': 346,\n",
              " 'necesit': 347,\n",
              " 'robert': 348,\n",
              " 'desconoc': 349,\n",
              " 'jason': 350,\n",
              " 'dificil': 351,\n",
              " 'despiad': 352,\n",
              " 'intencion': 353,\n",
              " 'director': 354,\n",
              " 'prepar': 355,\n",
              " 'cuid': 356,\n",
              " 'mit': 357,\n",
              " 'ambient': 358,\n",
              " 'graci': 359,\n",
              " 'dem': 360,\n",
              " 'vecin': 361,\n",
              " 'supervivent': 362,\n",
              " 'acontec': 363,\n",
              " 'siniestr': 364,\n",
              " 'lanz': 365,\n",
              " 'civil': 366,\n",
              " 'aprend': 367,\n",
              " 'medi': 368,\n",
              " 'universitari': 369,\n",
              " 'prision': 370,\n",
              " 'eleg': 371,\n",
              " 'crim': 372,\n",
              " 'carg': 373,\n",
              " 'musical': 374,\n",
              " 'solter': 375,\n",
              " 'pose': 376,\n",
              " 'conflict': 377,\n",
              " 'permit': 378,\n",
              " 'salvaj': 379,\n",
              " 'retir': 380,\n",
              " 'emocion': 381,\n",
              " 'brutal': 382,\n",
              " 'conquist': 383,\n",
              " 'numer': 384,\n",
              " 'park': 385,\n",
              " 'espiritu': 386,\n",
              " 'tim': 387,\n",
              " 'sistem': 388,\n",
              " 'avanz': 389,\n",
              " 'compani': 390,\n",
              " 'cart': 391,\n",
              " 'espaci': 392,\n",
              " 'increibl': 393,\n",
              " 'premi': 394,\n",
              " 'embarc': 395,\n",
              " 'loc': 396,\n",
              " 'mujer': 397,\n",
              " 'dispuest': 398,\n",
              " 'remot': 399,\n",
              " 'rap': 400,\n",
              " 'institut': 401,\n",
              " 'local': 402,\n",
              " 'golp': 403,\n",
              " 'fuert': 404,\n",
              " 'solucion': 405,\n",
              " 'agenci': 406,\n",
              " 'propon': 407,\n",
              " 'marvel': 408,\n",
              " 'armas': 409,\n",
              " 'tecnologi': 410,\n",
              " 'amist': 411,\n",
              " 'filmaffinity': 412,\n",
              " 'recient': 413,\n",
              " 'conden': 414,\n",
              " 'caz': 415,\n",
              " 'produc': 416,\n",
              " 'servici': 417,\n",
              " 'ocup': 418,\n",
              " 'convirt': 419,\n",
              " 'investigacion': 420,\n",
              " 'consider': 421,\n",
              " 'cia': 422,\n",
              " 'pist': 423,\n",
              " 'sam': 424,\n",
              " 'disfrut': 425,\n",
              " 'impos': 426,\n",
              " 'tranquil': 427,\n",
              " 'ven': 428,\n",
              " 'abuel': 429,\n",
              " '»': 430,\n",
              " '“': 431,\n",
              " 'emprend': 432,\n",
              " 'dec': 433,\n",
              " 'veng': 434,\n",
              " 'algui': 435,\n",
              " 'provoc': 436,\n",
              " 'expert': 437,\n",
              " 'novel': 438,\n",
              " 'sufr': 439,\n",
              " 'harry': 440,\n",
              " 'olvid': 441,\n",
              " 'anna': 442,\n",
              " 'car': 443,\n",
              " 'rebeld': 444,\n",
              " 'direct': 445,\n",
              " 'camp': 446,\n",
              " 'convenc': 447,\n",
              " 'revel': 448,\n",
              " 'recurs': 449,\n",
              " 'sospech': 450,\n",
              " 'nick': 451,\n",
              " 'chris': 452,\n",
              " 'organiz': 453,\n",
              " 'capac': 454,\n",
              " 'christi': 455,\n",
              " 'rus': 456,\n",
              " 'sigl': 457,\n",
              " 'marc': 458,\n",
              " 'lee': 459,\n",
              " 'polit': 460,\n",
              " 'call': 461,\n",
              " 'posibl': 462,\n",
              " 'doc': 463,\n",
              " 'constant': 464,\n",
              " 'gobiern': 465,\n",
              " 'colabor': 466,\n",
              " 'pondr': 467,\n",
              " 'despiert': 468,\n",
              " 'londr': 469,\n",
              " 'cuent': 470,\n",
              " 'limit': 471,\n",
              " 'oper': 472,\n",
              " 'entrar': 473,\n",
              " 'temibl': 474,\n",
              " 'veran': 475,\n",
              " 'cazador': 476,\n",
              " 'montan': 477,\n",
              " 'distint': 478,\n",
              " 'tecnic': 479,\n",
              " 'stev': 480,\n",
              " 'juli': 481,\n",
              " 'alex': 482,\n",
              " 'definit': 483,\n",
              " 'diez': 484,\n",
              " 'comedi': 485,\n",
              " 'mari': 486,\n",
              " 'rod': 487,\n",
              " 'grand': 488,\n",
              " 'perfect': 489,\n",
              " 'social': 490,\n",
              " 'gat': 491,\n",
              " 'franc': 492,\n",
              " 'dedic': 493,\n",
              " 'convertir': 494,\n",
              " 'valient': 495,\n",
              " 'organizacion': 496,\n",
              " 'devast': 497,\n",
              " 'johnnydepp': 498,\n",
              " 'inocent': 499,\n",
              " 'acept': 500,\n",
              " 'beb': 501,\n",
              " 'part': 502,\n",
              " 'vacacion': 503,\n",
              " 'motiv': 504,\n",
              " 'superhero': 505,\n",
              " 'princip': 506,\n",
              " 'just': 507,\n",
              " 'letal': 508,\n",
              " 'encabez': 509,\n",
              " 'mor': 510,\n",
              " 'matrimoni': 511,\n",
              " 'entra': 512,\n",
              " 'dian': 513,\n",
              " 'vuelt': 514,\n",
              " 'orig': 515,\n",
              " 'lob': 516,\n",
              " 'persegu': 517,\n",
              " 'escuel': 518,\n",
              " 'alcanz': 519,\n",
              " 'dragon': 520,\n",
              " 'red': 521,\n",
              " 'amer': 522,\n",
              " 'inclu': 523,\n",
              " 'plen': 524,\n",
              " 'version': 525,\n",
              " 'siente': 526,\n",
              " 'azul': 527,\n",
              " 'medic': 528,\n",
              " 'extraordinari': 529,\n",
              " 'chin': 530,\n",
              " 'recuerd': 531,\n",
              " 'sorpres': 532,\n",
              " 'cercan': 533,\n",
              " 'veteran': 534,\n",
              " 'norteamerican': 535,\n",
              " 'sobrenatural': 536,\n",
              " 'venc': 537,\n",
              " 'brillant': 538,\n",
              " 'cuart': 539,\n",
              " 'transport': 540,\n",
              " 'william': 541,\n",
              " 'johnny': 542,\n",
              " 'cruz': 543,\n",
              " 'contrat': 544,\n",
              " 'charl': 545,\n",
              " 'negoci': 546,\n",
              " 'quer': 547,\n",
              " 'interpret': 548,\n",
              " 'nacional': 549,\n",
              " 'galaxi': 550,\n",
              " 'ryan': 551,\n",
              " 'curs': 552,\n",
              " 'socied': 553,\n",
              " 'bail': 554,\n",
              " 'alter': 555,\n",
              " 'consecuent': 556,\n",
              " 'capaz': 557,\n",
              " 'ley': 558,\n",
              " 'bruc': 559,\n",
              " 'solitari': 560,\n",
              " 'ador': 561,\n",
              " 'consegu': 562,\n",
              " 'caos': 563,\n",
              " 'president': 564,\n",
              " 'concurs': 565,\n",
              " 'demostr': 566,\n",
              " 'explor': 567,\n",
              " 'gent': 568,\n",
              " 'hall': 569,\n",
              " 'mag': 570,\n",
              " 'asegur': 571,\n",
              " 'tio': 572,\n",
              " 'videojueg': 573,\n",
              " 'celebr': 574,\n",
              " 'domin': 575,\n",
              " 'mental': 576,\n",
              " 'quier': 577,\n",
              " 'bob': 578,\n",
              " 'mied': 579,\n",
              " 'mes': 580,\n",
              " 'billy': 581,\n",
              " 'sac': 582,\n",
              " 'segu': 583,\n",
              " 'tiburon': 584,\n",
              " 'willsmith': 585,\n",
              " 'coch': 586,\n",
              " 'met': 587,\n",
              " 'violent': 588,\n",
              " 'recorr': 589,\n",
              " 'victim': 590,\n",
              " 'prep': 591,\n",
              " 'black': 592,\n",
              " 'mercenari': 593,\n",
              " 'principi': 594,\n",
              " 'harrisonford': 595,\n",
              " 'fech': 596,\n",
              " 'contact': 597,\n",
              " 'hotel': 598,\n",
              " 'traicion': 599,\n",
              " 'escrit': 600,\n",
              " 'actual': 601,\n",
              " 'ingles': 602,\n",
              " 'alta': 603,\n",
              " 'maestr': 604,\n",
              " 'dr': 605,\n",
              " 'voz': 606,\n",
              " 'stevenspielberg': 607,\n",
              " 'deadpool': 608,\n",
              " 'adopt': 609,\n",
              " 'preci': 610,\n",
              " 'artist': 611,\n",
              " 'campament': 612,\n",
              " 'fracas': 613,\n",
              " 'fisic': 614,\n",
              " 'lejan': 615,\n",
              " 'unirs': 616,\n",
              " 'liber': 617,\n",
              " 'bosqu': 618,\n",
              " 'acud': 619,\n",
              " 'veg': 620,\n",
              " 'decision': 621,\n",
              " 'aprovech': 622,\n",
              " 'paz': 623,\n",
              " 'represent': 624,\n",
              " 'edward': 625,\n",
              " 'suced': 626,\n",
              " 'somet': 627,\n",
              " 'asalt': 628,\n",
              " 'invasor': 629,\n",
              " 'atract': 630,\n",
              " 'enmascar': 631,\n",
              " 'defend': 632,\n",
              " 'comet': 633,\n",
              " 'pregunt': 634,\n",
              " 'anill': 635,\n",
              " 'mud': 636,\n",
              " 'titul': 637,\n",
              " 'sofistic': 638,\n",
              " 'cost': 639,\n",
              " 'zon': 640,\n",
              " 'posterior': 641,\n",
              " 'podr': 642,\n",
              " 'mont': 643,\n",
              " 'besti': 644,\n",
              " 'suficient': 645,\n",
              " 'dinosauri': 646,\n",
              " 'alianz': 647,\n",
              " 'derrot': 648,\n",
              " 'kirk': 649,\n",
              " 'nac': 650,\n",
              " 'memori': 651,\n",
              " 'neces': 652,\n",
              " 'annehathaway': 653,\n",
              " 'puert': 654,\n",
              " 'paranormal': 655,\n",
              " 'operacion': 656,\n",
              " 'alto': 657,\n",
              " 'empez': 658,\n",
              " 'men': 659,\n",
              " 'arriesg': 660,\n",
              " 'paul': 661,\n",
              " 'piens': 662,\n",
              " 'spid': 663,\n",
              " 'lun': 664,\n",
              " 'dwaynejohnson': 665,\n",
              " 'documental': 666,\n",
              " 'duen': 667,\n",
              " 'surg': 668,\n",
              " 'tesor': 669,\n",
              " 'ben': 670,\n",
              " 'traslad': 671,\n",
              " 'pres': 672,\n",
              " 'presenci': 673,\n",
              " 'romp': 674,\n",
              " 'diari': 675,\n",
              " 'pesadill': 676,\n",
              " 'favorit': 677,\n",
              " 'unen': 678,\n",
              " 'feliz': 679,\n",
              " 'libert': 680,\n",
              " 'inmediat': 681,\n",
              " 'judi': 682,\n",
              " 'cinematograf': 683,\n",
              " 'kevin': 684,\n",
              " 'adam': 685,\n",
              " 'implac': 686,\n",
              " 'desastr': 687,\n",
              " 'roj': 688,\n",
              " 'aisl': 689,\n",
              " 'acech': 690,\n",
              " 'paris': 691,\n",
              " 'experient': 692,\n",
              " 'particip': 693,\n",
              " 'obsesion': 694,\n",
              " 'charli': 695,\n",
              " 'europ': 696,\n",
              " 'not': 697,\n",
              " 'sangr': 698,\n",
              " 'sir': 699,\n",
              " 'simon': 700,\n",
              " 'disen': 701,\n",
              " 'smith': 702,\n",
              " 'pokemon': 703,\n",
              " 'teni': 704,\n",
              " 'bord': 705,\n",
              " 'bod': 706,\n",
              " 'fbi': 707,\n",
              " 'gary': 708,\n",
              " 'elit': 709,\n",
              " 'parodi': 710,\n",
              " 'jak': 711,\n",
              " 'crisis': 712,\n",
              " 'justici': 713,\n",
              " 'habl': 714,\n",
              " 'andy': 715,\n",
              " 'torment': 716,\n",
              " 'ment': 717,\n",
              " 'seman': 718,\n",
              " 'connor': 719,\n",
              " 'city': 720,\n",
              " 'drog': 721,\n",
              " 'jigsaw': 722,\n",
              " 'rio': 723,\n",
              " 'invasion': 724,\n",
              " 'confi': 725,\n",
              " 'munec': 726,\n",
              " 'virus': 727,\n",
              " 'imagin': 728,\n",
              " 'futbol': 729,\n",
              " 'superher': 730,\n",
              " 'reci': 731,\n",
              " 'espi': 732,\n",
              " 'cam': 733,\n",
              " 'cruel': 734,\n",
              " 'talent': 735,\n",
              " 'nacion': 736,\n",
              " 'gigantesc': 737,\n",
              " 'interior': 738,\n",
              " 'epic': 739,\n",
              " 'grav': 740,\n",
              " 'pacif': 741,\n",
              " 'unir': 742,\n",
              " 'steph': 743,\n",
              " 'une': 744,\n",
              " 'emper': 745,\n",
              " 'baj': 746,\n",
              " 'color': 747,\n",
              " 'sorprend': 748,\n",
              " 'desencaden': 749,\n",
              " 'chrisevans': 750,\n",
              " 'realiz': 751,\n",
              " 'anim': 752,\n",
              " 'navid': 753,\n",
              " 'carcel': 754,\n",
              " 'leon': 755,\n",
              " 'jenniferlawrence': 756,\n",
              " 'television': 757,\n",
              " 'rival': 758,\n",
              " 'barri': 759,\n",
              " 'armad': 760,\n",
              " 'toc': 761,\n",
              " 'sant': 762,\n",
              " 'fantast': 763,\n",
              " 'colegi': 764,\n",
              " 'robot': 765,\n",
              " 'corr': 766,\n",
              " 'tradicional': 767,\n",
              " 'autent': 768,\n",
              " 'descubrir': 769,\n",
              " 'juguet': 770,\n",
              " 'nicolascage': 771,\n",
              " 'jug': 772,\n",
              " 'naturalez': 773,\n",
              " 'millonari': 774,\n",
              " 'cri': 775,\n",
              " 'jean': 776,\n",
              " 'carl': 777,\n",
              " 'of': 778,\n",
              " 'danny': 779,\n",
              " 'internet': 780,\n",
              " 'encant': 781,\n",
              " 'obra': 782,\n",
              " 'trop': 783,\n",
              " 'jennif': 784,\n",
              " 'invad': 785,\n",
              " 'magi': 786,\n",
              " 'mary': 787,\n",
              " 'tip': 788,\n",
              " 'separ': 789,\n",
              " 'tripulacion': 790,\n",
              " 'diabol': 791,\n",
              " 'ciudadan': 792,\n",
              " 'hannah': 793,\n",
              " 'agu': 794,\n",
              " 'legion': 795,\n",
              " 'fabric': 796,\n",
              " 'promet': 797,\n",
              " 'robertdowneyjr': 798,\n",
              " 'restaur': 799,\n",
              " 'coronel': 800,\n",
              " 'tram': 801,\n",
              " 'habi': 802,\n",
              " 'activ': 803,\n",
              " 'cobr': 804,\n",
              " 'localiz': 805,\n",
              " 'sent': 806,\n",
              " 'respuest': 807,\n",
              " 'esfuerz': 808,\n",
              " 'maxim': 809,\n",
              " 'alic': 810,\n",
              " 'caid': 811,\n",
              " 'divorci': 812,\n",
              " 'avion': 813,\n",
              " 'cit': 814,\n",
              " 'infinit': 815,\n",
              " 'metal': 816,\n",
              " 'gru': 817,\n",
              " 'gigant': 818,\n",
              " 'intern': 819,\n",
              " 'natural': 820,\n",
              " 'secuac': 821,\n",
              " 'matthewlillard': 822,\n",
              " 'adamsandler': 823,\n",
              " 'campeon': 824,\n",
              " 'liamhemsworth': 825,\n",
              " 'mexic': 826,\n",
              " 'cos': 827,\n",
              " 'cabez': 828,\n",
              " 'compromis': 829,\n",
              " 'atencion': 830,\n",
              " 'event': 831,\n",
              " 'tortug': 832,\n",
              " 'mantien': 833,\n",
              " 'air': 834,\n",
              " 'sentido': 835,\n",
              " 'autor': 836,\n",
              " 'estall': 837,\n",
              " 'homonim': 838,\n",
              " 'genet': 839,\n",
              " 'pretend': 840,\n",
              " 'arqueolog': 841,\n",
              " 'remedi': 842,\n",
              " 'crec': 843,\n",
              " 'californi': 844,\n",
              " 'laboratori': 845,\n",
              " 'batm': 846,\n",
              " 'remak': 847,\n",
              " 'desiert': 848,\n",
              " 'mascot': 849,\n",
              " 'constru': 850,\n",
              " 'nazis': 851,\n",
              " 'espanol': 852,\n",
              " 'escen': 853,\n",
              " 'jan': 854,\n",
              " 'nucl': 855,\n",
              " 'protagoniz': 856,\n",
              " 'terrorif': 857,\n",
              " 'hel': 858,\n",
              " 'arrastr': 859,\n",
              " 'conduc': 860,\n",
              " 'michaelfassbender': 861,\n",
              " 'brucewillis': 862,\n",
              " 'acus': 863,\n",
              " 'aterroriz': 864,\n",
              " 'cody': 865,\n",
              " 'thor': 866,\n",
              " 'central': 867,\n",
              " 'georg': 868,\n",
              " 'relat': 869,\n",
              " 'jungl': 870,\n",
              " 'warr': 871,\n",
              " 'pandill': 872,\n",
              " 'invent': 873,\n",
              " 'fox': 874,\n",
              " 'descubiert': 875,\n",
              " 'shredd': 876,\n",
              " 'prestigi': 877,\n",
              " 'tomcruise': 878,\n",
              " 'grey': 879,\n",
              " 'wad': 880,\n",
              " 'trafic': 881,\n",
              " 'fenomen': 882,\n",
              " 'hughjackman': 883,\n",
              " 'dot': 884,\n",
              " 'refugi': 885,\n",
              " 'tir': 886,\n",
              " 'aterr': 887,\n",
              " 'etern': 888,\n",
              " 'elizabeth': 889,\n",
              " 'sex': 890,\n",
              " 'sexual': 891,\n",
              " 'leyend': 892,\n",
              " 'tra': 893,\n",
              " 'bellez': 894,\n",
              " 'ira': 895,\n",
              " 'ancian': 896,\n",
              " 'peculi': 897,\n",
              " 'zombi': 898,\n",
              " 'testig': 899,\n",
              " 'inspir': 900,\n",
              " 'kat': 901,\n",
              " 'edad': 902,\n",
              " 'falt': 903,\n",
              " 'inicial': 904,\n",
              " 'pens': 905,\n",
              " 'bailarin': 906,\n",
              " 'amand': 907,\n",
              " 'opcion': 908,\n",
              " 'limpi': 909,\n",
              " 'razon': 910,\n",
              " 'emple': 911,\n",
              " 'aventurer': 912,\n",
              " 'mark': 913,\n",
              " 'monton': 914,\n",
              " 'washington': 915,\n",
              " 'comprend': 916,\n",
              " 'mezcl': 917,\n",
              " 'prim': 918,\n",
              " 'masc': 919,\n",
              " 'actu': 920,\n",
              " 'lar': 921,\n",
              " 'nort': 922,\n",
              " 'aparicion': 923,\n",
              " 'imperial': 924,\n",
              " 'bomb': 925,\n",
              " 'alegri': 926,\n",
              " 'max': 927,\n",
              " 'jim': 928,\n",
              " 'distrit': 929,\n",
              " 'may': 930,\n",
              " 'desaparicion': 931,\n",
              " 'des': 932,\n",
              " 'forz': 933,\n",
              " 'determin': 934,\n",
              " 'cae': 935,\n",
              " 'invit': 936,\n",
              " 'larg': 937,\n",
              " 'fion': 938,\n",
              " 'aterriz': 939,\n",
              " 'probabl': 940,\n",
              " 'terc': 941,\n",
              " 'ningun': 942,\n",
              " 'expedicion': 943,\n",
              " 'menor': 944,\n",
              " 'delincuent': 945,\n",
              " 'sethrogen': 946,\n",
              " 'ret': 947,\n",
              " 'expedient': 948,\n",
              " 'jeffgoldblum': 949,\n",
              " 'extincion': 950,\n",
              " 'intens': 951,\n",
              " 'ros': 952,\n",
              " 'angelinajolie': 953,\n",
              " 'malef': 954,\n",
              " 'esfer': 955,\n",
              " 'jackblack': 956,\n",
              " 'fall': 957,\n",
              " 'empen': 958,\n",
              " 'inexpert': 959,\n",
              " 'apasion': 960,\n",
              " 'niet': 961,\n",
              " 'wilson': 962,\n",
              " 'tomhanks': 963,\n",
              " 'superior': 964,\n",
              " 'geni': 965,\n",
              " 'ambici': 966,\n",
              " 'permanec': 967,\n",
              " 'gobern': 968,\n",
              " 'vuel': 969,\n",
              " 'rebecc': 970,\n",
              " 'espan': 971,\n",
              " 'profesional': 972,\n",
              " 'pag': 973,\n",
              " 'amad': 974,\n",
              " 'jonmchu': 975,\n",
              " 'alegr': 976,\n",
              " 'cort': 977,\n",
              " 'juventud': 978,\n",
              " 'divid': 979,\n",
              " 'escenari': 980,\n",
              " 'romant': 981,\n",
              " 'woodyharrelson': 982,\n",
              " 'sauron': 983,\n",
              " 'obten': 984,\n",
              " 'atent': 985,\n",
              " 'leonardodicaprio': 986,\n",
              " 'stevecarell': 987,\n",
              " 'ardill': 988,\n",
              " 'convirti': 989,\n",
              " 'sombrerer': 990,\n",
              " 'reloj': 991,\n",
              " 'preocup': 992,\n",
              " 'odi': 993,\n",
              " 'deport': 994,\n",
              " 'pilot': 995,\n",
              " 'jamesmcavoy': 996,\n",
              " 'arthur': 997,\n",
              " 'ee': 998,\n",
              " 'epoc': 999,\n",
              " 'luj': 1000,\n",
              " ...}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8eiGMiL6pyLs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save tokenizer\n",
        "import pickle\n",
        "\n",
        "# saving\n",
        "with open('tokenizer.pickle', 'wb') as handle:\n",
        "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
        "\n",
        "# loading\n",
        "#with open('tokenizer.pickle', 'rb') as handle:\n",
        "#    tokenizer = pickle.load(handle)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CTsC2-KlqZ7u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Crear pre-trained emmbeding\n",
        "\n",
        "# def create_embedding_matrix(filepath, word_index, embedding_size):\n",
        "#     vocab_size = len(word_index) + 1  # Adding again 1 because of reserved 0 index\n",
        "#     embedding_matrix = np.zeros((vocab_size, embedding_size))\n",
        "\n",
        "#     with open(filepath, encoding='utf-8') as f:\n",
        "#         for line in f:\n",
        "#             word, *vector = line.split()\n",
        "#             if word in word_index:\n",
        "#                 idx = word_index[word] \n",
        "#                 embedding_matrix[idx] = np.array(\n",
        "#                     vector, dtype=np.float32)[:embedding_size]\n",
        "\n",
        "#     return embedding_matrix\n",
        "  \n",
        "# embedding_matrix = create_embedding_matrix(\n",
        "#     'gdrive/My Drive/TFG/SBW-vectors-300-min5.txt',\n",
        "#     tokenizer.word_index, embedding_size)\n",
        "\n",
        "# print(embedding_matrix[2])\n",
        "# print(len(embedding_matrix[2]))\n",
        "\n",
        "# nonzero_elements = np.count_nonzero(np.count_nonzero(embedding_matrix, axis=1))\n",
        "# nonzero_elements / vocab_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XHqpVvAjjQY8",
        "colab_type": "code",
        "outputId": "6c7b973a-6943-4200-e2fb-5d2ffe54c7ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "X_train = pad_sequences(X_train, padding='pre', maxlen=maxlen)\n",
        "X_test = pad_sequences(X_test, padding='pre', maxlen=maxlen)\n",
        "\n",
        "X_train[1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "          0,    0,    0,    0, 4923,  822, 4924, 1914, 1237, 1294,    6,\n",
              "       4925, 2865, 8951, 2413, 4926,  405,   19, 1569,  302,  788, 1915,\n",
              "       4254, 1237, 1294,    6,  109, 4927, 4590,  272, 1185, 4255, 4928,\n",
              "       1295,  334,   68, 1398, 4929,   97, 1237,  872, 1805,  272,   55,\n",
              "        423,   81, 3044], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UB9lmFFWab7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from tensorflow.keras import backend as K\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "#Optimizer\n",
        "\n",
        "from keras import optimizers\n",
        "\n",
        "adam = optimizers.Adam()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ifIZiMr2LdSS",
        "colab_type": "code",
        "outputId": "a7be7ae6-a862-48f4-db4a-e4e3e456d10d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.utils import class_weight\n",
        "\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced',\n",
        "                                                 np.unique(y_train),\n",
        "                                                 y_train)\n",
        "\n",
        "class_weights"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97755961, 1.02349486])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TO2rjJmBj28t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Model 1\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "# from tensorflow.keras.layers import Embedding\n",
        "# from tensorflow.keras.layers import LSTM\n",
        "# from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# model.add(Embedding(vocab_size,embedding_size, input_length=maxlen))\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(500, activation='elu', kernel_initializer='he_uniform'))\n",
        "# model.add(Dropout(0.5))\n",
        "# model.add(Dense(1, activation='sigmoid', kernel_initializer='he_uniform'))\n",
        "# model.compile(optimizer=adam,\n",
        "#               loss='binary_crossentropy',\n",
        "#               metrics=['acc'])\n",
        "\n",
        "# model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X3Jtoe5qztD0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Model 2\n",
        "\n",
        "# from tensorflow.keras.models import Sequential\n",
        "# from tensorflow.keras.layers import Dense, Dropout, Activation\n",
        "# from tensorflow.keras.layers import Embedding, BatchNormalization\n",
        "# from tensorflow.keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D,GlobalAveragePooling1D\n",
        "\n",
        "# model = Sequential()\n",
        "\n",
        "# # we start off with an efficient embedding layer which maps\n",
        "# # our vocab indices into embedding_dims dimensions\n",
        "# model.add(Embedding(vocab_size,\n",
        "#                     embedding_size,\n",
        "#                     input_length=maxlen))\n",
        "\n",
        "\n",
        "# # we add a Convolution1D, which will learn filters\n",
        "# # word group filters of size filter_length:\n",
        "# model.add(Conv1D(filters,\n",
        "#                  kernel_size,\n",
        "#                  padding='valid',\n",
        "#                  strides=1, kernel_initializer='he_uniform'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('elu'))\n",
        "\n",
        "# # we use max pooling:\n",
        "\n",
        "# model.add(GlobalMaxPooling1D())\n",
        "\n",
        "# # We add a vanilla hidden layer:\n",
        "# model.add(Dense(150, kernel_initializer='he_uniform'))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('elu'))\n",
        "# model.add(Dropout(0.5))\n",
        "\n",
        "# # We project onto a single unit output layer, and squash it with a sigmoid:\n",
        "# model.add(Dense(1))\n",
        "# model.add(BatchNormalization())\n",
        "# model.add(Activation('sigmoid'))\n",
        "\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer=tf.keras.optimizers.Nadam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, schedule_decay=0.004),\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m4opiVy5h3t7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Input\n",
        "from keras.layers import Embedding,CuDNNLSTM, SpatialDropout1D, Reshape, Flatten, BatchNormalization\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
        "from keras.optimizers import Adam, Adagrad\n",
        "\n",
        "\n",
        "class MyLayers:\n",
        "\n",
        "    @staticmethod\n",
        "    def my_conv1d(kernel_size, layer, filters=10, strides=1, act='relu', reg=None):\n",
        "        \n",
        "        c1d = keras.layers.Conv1D(filters=filters, kernel_size=kernel_size, padding='valid', strides=strides,\n",
        "                                     kernel_initializer='he_uniform', kernel_regularizer=reg)(layer)\n",
        "        \n",
        "        if act in ['relu','elu','gelu','sigmoid']:\n",
        "          if act == 'gelu':\n",
        "            act = MyLayers.gelu\n",
        "          c1d = keras.layers.BatchNormalization()(c1d)\n",
        "          c1d = keras.layers.Activation(act)(c1d)\n",
        "        \n",
        "        else:\n",
        "          c1d = keras.layers.Activation(act)(c1d)\n",
        "          c1d = keras.layers.BatchNormalization()(c1d)\n",
        "          \n",
        "        return c1d\n",
        "\n",
        "    @staticmethod\n",
        "    def my_dense(neurons, ant, act='sigmoid', ini='glorot_uniform', reg=None):\n",
        "      \n",
        "        dense = keras.layers.Dense(neurons, kernel_initializer=ini, kernel_regularizer=reg)(ant)\n",
        "\n",
        "        if act in ['relu','elu','gelu','sigmoid']:\n",
        "          if act == 'gelu':\n",
        "            act = MyLayers.gelu\n",
        "          dense = keras.layers.BatchNormalization()(dense)\n",
        "          dense = keras.layers.Activation(act)(dense)\n",
        "        \n",
        "        else:\n",
        "          dense = keras.layers.Activation(act)(dense)\n",
        "\n",
        "        return dense\n",
        "\n",
        "    @staticmethod\n",
        "    def gelu(x):\n",
        "        return 0.5 * x * (1 + tf.keras.backend.tanh(np.sqrt(2 / np.pi) * (x + 0.044715 * tf.keras.backend.pow(x, 3))))\n",
        "\n",
        "    @staticmethod\n",
        "    def custom_sigmoid(x):\n",
        "        return keras.backend.sigmoid(x) + tf.keras.backend.epsilon()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F7r7BcGTDyEV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Model 3\n",
        "\n",
        "# words = Input(shape=(maxlen,))\n",
        "# em =  Embedding(input_dim = vocab_size, output_dim = embedding_size, weights=[embedding_matrix], trainable=True)(words)\n",
        "# em = Dropout(0.3)(em) \n",
        "# c1 = my_conv1d(2,em, filters=500)\n",
        "# c2 = my_conv1d(3,em, filters=500)\n",
        "# c3 = my_conv1d(5,em, filters=500)\n",
        "\n",
        "# g1 = GlobalMaxPooling1D()(c1)\n",
        "# g2 = GlobalMaxPooling1D()(c2)\n",
        "# g3 = GlobalMaxPooling1D()(c3)\n",
        "\n",
        "# con = Concatenate(axis=1)([g1,g2,g3])\n",
        "\n",
        "# dense = Dropout(0.5)(con) \n",
        "# pred = my_dense(1,dense)\n",
        "# model = Model(inputs=words, outputs=pred)\n",
        "\n",
        "# model.compile(optimizer = 'adam',\n",
        "#               loss = 'binary_crossentropy',\n",
        "#               metrics = ['accuracy'])\n",
        "  \n",
        "# model.summary()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNfu7h5_eety",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # Model RNN\n",
        "\n",
        "# from tensorflow.keras.layers import Bidirectional, LSTM, Flatten\n",
        "\n",
        "# words = Input(shape=(maxlen,))\n",
        "# em =  Embedding(input_dim = vocab_size, output_dim = embedding_size, weights=[embedding_matrix], trainable=True)(words)\n",
        "# #em = Dropout(0.3)(em) \n",
        "\n",
        "# lstm_1 = Bidirectional(LSTM(64, name='blstm_1',\n",
        "# activation='tanh',\n",
        "# recurrent_activation='hard_sigmoid',\n",
        "# recurrent_dropout=0.0,\n",
        "# dropout=0.5, \n",
        "# kernel_initializer='glorot_uniform',\n",
        "# return_sequences=True),\n",
        "# merge_mode='concat')(em)\n",
        "\n",
        "# lstm_1 = BatchNormalization()(lstm_1)\n",
        "\n",
        "# #Flatten\n",
        "# g1 = Flatten()(lstm_1)\n",
        "\n",
        "# drop3 = Dropout(0.5)(g1)\n",
        "\n",
        "# pred = my_dense(1,drop3)\n",
        "# model = Model(inputs=words, outputs=pred)\n",
        "\n",
        "# model.compile(optimizer = 'adam',\n",
        "#               loss = 'binary_crossentropy',\n",
        "#               metrics = ['accuracy'])\n",
        "  \n",
        "# model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EUVg8huVWO3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 5 cnn + rnn\n",
        "\n",
        "from keras.layers import Bidirectional, CuDNNGRU, GRU, SpatialDropout1D\n",
        "\n",
        "def custom_model_gpu(embedding_size, dropout, filters, kernel, maxp, gnup, neurons, act):\n",
        "  words = Input(shape=(maxlen,))\n",
        "  em =  Embedding(input_dim = vocab_size, output_dim = embedding_size)(words)\n",
        "  em = SpatialDropout1D(dropout)(em) \n",
        "\n",
        "  c = MyLayers.my_conv1d(kernel ,em, filters=filters, act=act)\n",
        "  m = MaxPooling1D(pool_size=maxp)(c)\n",
        "  d = Dropout(dropout)(m) \n",
        "\n",
        "  gru = CuDNNGRU(gnup, kernel_initializer='glorot_uniform', return_sequences=True)(d)\n",
        "  gru = BatchNormalization()(gru)\n",
        "  gru = GlobalMaxPooling1D()(gru)\n",
        "  drop = Dropout(dropout)(gru)\n",
        "\n",
        "  pred = MyLayers.my_dense(neurons=neurons, ant=drop, act=act)\n",
        "  pred = MyLayers.my_dense(1, pred, act='sigmoid')\n",
        "\n",
        "  model = Model(inputs=words, outputs=pred)\n",
        "\n",
        "  return model\n",
        "\n",
        "def custom_model_cpu(embedding_size, dropout, filters, kernel, maxp, gnup, neurons, act):\n",
        "  words = Input(shape=(maxlen,))\n",
        "  em =  Embedding(input_dim = vocab_size, output_dim = embedding_size)(words)\n",
        "  em = SpatialDropout1D(dropout)(em) \n",
        "\n",
        "  c = MyLayers.my_conv1d(kernel ,em, filters=filters, act=act)\n",
        "  m = MaxPooling1D(pool_size=maxp)(c)\n",
        "  d = Dropout(dropout)(m) \n",
        "\n",
        "  gru = GRU(gnup, kernel_initializer='glorot_uniform', activation='tanh',\n",
        "            recurrent_activation='sigmoid', return_sequences=True, reset_after=True)(d)\n",
        "  gru = BatchNormalization()(gru)\n",
        "  gru = GlobalMaxPooling1D()(gru)\n",
        "  drop = Dropout(dropout)(gru)\n",
        "\n",
        "  pred = MyLayers.my_dense(neurons=neurons, ant=drop, act=act)\n",
        "  pred = MyLayers.my_dense(1, pred)\n",
        "\n",
        "  model = Model(inputs=words, outputs=pred)\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyLjMA4sNLxr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import glob\n",
        "\n",
        "files = glob.glob(\"gdrive/My Drive/TFG/models/*\")\n",
        "for f in files:\n",
        "    os.remove(f)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnxStx2B2E5Y",
        "colab_type": "code",
        "outputId": "3d2434d4-c717-4343-fa4b-91e5d95804bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "import os\n",
        "\n",
        "files = os.listdir(\"gdrive/My Drive/TFG/models/\")\n",
        "files.sort(reverse=True)\n",
        "print(files)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['weights-14-0.74.hdf5', 'weights-13-0.73.hdf5', 'weights-06-0.71.hdf5', 'weights-05-0.68.hdf5', 'weights-04-0.65.hdf5', 'weights-03-0.58.hdf5', 'weights-01-0.51.hdf5']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8QA3f7kV1RzZ",
        "colab_type": "code",
        "outputId": "b4886028-5022-49db-c25b-b2652a4b06f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = custom_model_gpu(embedding_size=150,dropout=0.5,filters=64,kernel=3,maxp=2,gnup=32,neurons=8,act='gelu')\n",
        "model.load_weights(\"gdrive/My Drive/TFG/models/\" + files[0])\n",
        "model.compile(optimizer = 'adam', loss = 'binary_crossentropy',  metrics = ['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:203: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 80, 150)           1524300   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_1 (Spatial (None, 80, 150)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 78, 64)            28864     \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 78, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 78, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 39, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 39, 64)            0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_1 (CuDNNGRU)       (None, 39, 32)            9408      \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 39, 32)            128       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "batch_normalization_3 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "_________________________________________________________________\n",
            "batch_normalization_4 (Batch (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,563,265\n",
            "Trainable params: 1,563,055\n",
            "Non-trainable params: 210\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpcVR1msrl13",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.callbacks import ModelCheckpoint\n",
        "\n",
        "filepath=\"gdrive/My Drive/TFG/models/weights-{epoch:02d}-{val_acc:.2f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', save_best_only=True, verbose=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XYVWkz6Atce",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_one_hot(x):\n",
        "  if x==1:\n",
        "    return [0,1]\n",
        "  else:\n",
        "    return [1,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ztZRYyfkAGaa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train2 = np.array([get_one_hot(x) for x in y_train])\n",
        "y_test2 = np.array([get_one_hot(x) for x in y_test])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aOM3z3P9DWdn",
        "colab_type": "code",
        "outputId": "5fa67452-9f36-4b4b-ed61-28d19fb9b45f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "y_train2"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0],\n",
              "       [1, 0],\n",
              "       [1, 0],\n",
              "       ...,\n",
              "       [1, 0],\n",
              "       [0, 1],\n",
              "       [0, 1]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 198
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlDCu0kkHg4E",
        "colab_type": "code",
        "outputId": "af4e024c-48cc-4726-d05d-e73e45af89c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=32,\n",
        "                    class_weight=class_weights,\n",
        "                    callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 2788 samples, validate on 167 samples\n",
            "Epoch 1/20\n",
            "2788/2788 [==============================] - 13s 5ms/step - loss: 0.8099 - acc: 0.4821 - val_loss: 0.7116 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00001: val_acc improved from -inf to 0.50898, saving model to gdrive/My Drive/TFG/models/weights-01-0.51.hdf5\n",
            "Epoch 2/20\n",
            "2788/2788 [==============================] - 2s 817us/step - loss: 0.7463 - acc: 0.5352 - val_loss: 0.7185 - val_acc: 0.5090\n",
            "\n",
            "Epoch 00002: val_acc did not improve from 0.50898\n",
            "Epoch 3/20\n",
            "2788/2788 [==============================] - 2s 805us/step - loss: 0.6344 - acc: 0.6496 - val_loss: 0.6620 - val_acc: 0.5808\n",
            "\n",
            "Epoch 00003: val_acc improved from 0.50898 to 0.58084, saving model to gdrive/My Drive/TFG/models/weights-03-0.58.hdf5\n",
            "Epoch 4/20\n",
            "2788/2788 [==============================] - 2s 800us/step - loss: 0.4963 - acc: 0.8099 - val_loss: 0.6167 - val_acc: 0.6527\n",
            "\n",
            "Epoch 00004: val_acc improved from 0.58084 to 0.65269, saving model to gdrive/My Drive/TFG/models/weights-04-0.65.hdf5\n",
            "Epoch 5/20\n",
            "2788/2788 [==============================] - 2s 821us/step - loss: 0.4187 - acc: 0.9114 - val_loss: 0.6181 - val_acc: 0.6826\n",
            "\n",
            "Epoch 00005: val_acc improved from 0.65269 to 0.68263, saving model to gdrive/My Drive/TFG/models/weights-05-0.68.hdf5\n",
            "Epoch 6/20\n",
            "2788/2788 [==============================] - 2s 798us/step - loss: 0.3639 - acc: 0.9509 - val_loss: 0.6095 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00006: val_acc improved from 0.68263 to 0.70659, saving model to gdrive/My Drive/TFG/models/weights-06-0.71.hdf5\n",
            "Epoch 7/20\n",
            "2788/2788 [==============================] - 2s 847us/step - loss: 0.3245 - acc: 0.9735 - val_loss: 0.6112 - val_acc: 0.6766\n",
            "\n",
            "Epoch 00007: val_acc did not improve from 0.70659\n",
            "Epoch 8/20\n",
            "2788/2788 [==============================] - 2s 831us/step - loss: 0.2978 - acc: 0.9806 - val_loss: 0.6337 - val_acc: 0.6707\n",
            "\n",
            "Epoch 00008: val_acc did not improve from 0.70659\n",
            "Epoch 9/20\n",
            "2788/2788 [==============================] - 2s 830us/step - loss: 0.2741 - acc: 0.9846 - val_loss: 0.6385 - val_acc: 0.6707\n",
            "\n",
            "Epoch 00009: val_acc did not improve from 0.70659\n",
            "Epoch 10/20\n",
            "2788/2788 [==============================] - 2s 814us/step - loss: 0.2538 - acc: 0.9857 - val_loss: 0.6271 - val_acc: 0.7006\n",
            "\n",
            "Epoch 00010: val_acc did not improve from 0.70659\n",
            "Epoch 11/20\n",
            "2788/2788 [==============================] - 2s 810us/step - loss: 0.2418 - acc: 0.9860 - val_loss: 0.6291 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00011: val_acc did not improve from 0.70659\n",
            "Epoch 12/20\n",
            "2788/2788 [==============================] - 2s 788us/step - loss: 0.2168 - acc: 0.9918 - val_loss: 0.6482 - val_acc: 0.6886\n",
            "\n",
            "Epoch 00012: val_acc did not improve from 0.70659\n",
            "Epoch 13/20\n",
            "2788/2788 [==============================] - 2s 798us/step - loss: 0.2094 - acc: 0.9914 - val_loss: 0.6083 - val_acc: 0.7305\n",
            "\n",
            "Epoch 00013: val_acc improved from 0.70659 to 0.73054, saving model to gdrive/My Drive/TFG/models/weights-13-0.73.hdf5\n",
            "Epoch 14/20\n",
            "2788/2788 [==============================] - 2s 812us/step - loss: 0.1920 - acc: 0.9918 - val_loss: 0.6031 - val_acc: 0.7365\n",
            "\n",
            "Epoch 00014: val_acc improved from 0.73054 to 0.73653, saving model to gdrive/My Drive/TFG/models/weights-14-0.74.hdf5\n",
            "Epoch 15/20\n",
            "2788/2788 [==============================] - 2s 820us/step - loss: 0.1822 - acc: 0.9925 - val_loss: 0.6442 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00015: val_acc did not improve from 0.73653\n",
            "Epoch 16/20\n",
            "2788/2788 [==============================] - 2s 831us/step - loss: 0.1692 - acc: 0.9943 - val_loss: 0.6736 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00016: val_acc did not improve from 0.73653\n",
            "Epoch 17/20\n",
            "2788/2788 [==============================] - 2s 801us/step - loss: 0.1638 - acc: 0.9910 - val_loss: 0.6651 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00017: val_acc did not improve from 0.73653\n",
            "Epoch 18/20\n",
            "2788/2788 [==============================] - 2s 838us/step - loss: 0.1521 - acc: 0.9946 - val_loss: 0.6824 - val_acc: 0.7066\n",
            "\n",
            "Epoch 00018: val_acc did not improve from 0.73653\n",
            "Epoch 19/20\n",
            "2788/2788 [==============================] - 2s 798us/step - loss: 0.1400 - acc: 0.9957 - val_loss: 0.7015 - val_acc: 0.6946\n",
            "\n",
            "Epoch 00019: val_acc did not improve from 0.73653\n",
            "Epoch 20/20\n",
            "2788/2788 [==============================] - 2s 807us/step - loss: 0.1350 - acc: 0.9935 - val_loss: 0.6979 - val_acc: 0.7186\n",
            "\n",
            "Epoch 00020: val_acc did not improve from 0.73653\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E32LWBFAkrSq",
        "colab_type": "code",
        "outputId": "667aa632-8bae-4c46-e56c-763c2bd5aecc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        }
      },
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "def plot_history(history):\n",
        "    acc = history.history['acc']\n",
        "    val_acc = history.history['val_acc']\n",
        "    loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    x = range(1, len(acc) + 1)\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(x, acc, 'b', label='Training acc')\n",
        "    plt.plot(x, val_acc, 'r', label='Validation acc')\n",
        "    plt.title('Training and validation accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(x, loss, 'b', label='Training loss')\n",
        "    plt.plot(x, val_loss, 'r', label='Validation loss')\n",
        "    plt.title('Training and validation loss')\n",
        "    plt.legend()\n",
        "    \n",
        "plot_history(history)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFCCAYAAADyoRvmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 864x360 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-L6gkT1k1yQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_score = model.predict(X_test)\n",
        "threshold = 0.5\n",
        "#y_pred= model.predict_classes(X_neutral)\n",
        "#y_test = y_netural\n",
        "\n",
        "y_pred = y_score.copy()\n",
        "y_pred[y_pred >=threshold] = 1\n",
        "y_pred[y_pred <threshold] = 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7JLI_WVJkwcP",
        "colab_type": "code",
        "outputId": "7909e769-11ee-48f9-95b1-5f90e68ea3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import cohen_kappa_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_score\n",
        "from sklearn.metrics import recall_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "print(\"Confusion Matrix: \\n\" + str(confusion_matrix(y_test, y_pred)))\n",
        "print(\"Accuracy: {:.4f}\".format(accuracy_score(y_test, y_pred)))\n",
        "print(\"Kappa: {:.4f}\".format(cohen_kappa_score(y_test, y_pred)))\n",
        "print(\"Precision: {:.4f}\".format(precision_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"Recall: {:.4f}\".format(recall_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"F1: {:.4f}\".format(f1_score(y_test, y_pred,pos_label=1)))\n",
        "print(\"Auc: {:.4f}\".format(roc_auc_score(y_test, y_pred)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Confusion Matrix: \n",
            "[[60 25]\n",
            " [19 63]]\n",
            "Accuracy: 0.7365\n",
            "Kappa: 0.4736\n",
            "Precision: 0.7159\n",
            "Recall: 0.7683\n",
            "F1: 0.7412\n",
            "Auc: 0.7371\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRm0NJMfMmah",
        "colab_type": "code",
        "outputId": "ca1bfa46-3df0-49f3-b43a-1b09d1adf67f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.73      0.72      0.72        85\n",
            "           1       0.71      0.72      0.72        82\n",
            "\n",
            "    accuracy                           0.72       167\n",
            "   macro avg       0.72      0.72      0.72       167\n",
            "weighted avg       0.72      0.72      0.72       167\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEwxrc1K4zZ_",
        "colab_type": "code",
        "outputId": "fe3e834d-0583-4ecf-b960-910c3b5ca914",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "model2 = custom_model_cpu(embedding_size=150,dropout=0.5,filters=64,kernel=3,maxp=2,gnup=32,neurons=8,act='gelu')\n",
        "model2.load_weights(\"gdrive/My Drive/TFG/models/\" + files[0])\n",
        "model2.compile(optimizer = 'adam', loss = 'binary_crossentropy',  metrics = ['accuracy'])\n",
        "\n",
        "model2.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 80)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 80, 150)           1524300   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_2 (Spatial (None, 80, 150)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_2 (Conv1D)            (None, 78, 64)            28864     \n",
            "_________________________________________________________________\n",
            "batch_normalization_5 (Batch (None, 78, 64)            256       \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 78, 64)            0         \n",
            "_________________________________________________________________\n",
            "max_pooling1d_2 (MaxPooling1 (None, 39, 64)            0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 39, 64)            0         \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 39, 32)            9408      \n",
            "_________________________________________________________________\n",
            "batch_normalization_6 (Batch (None, 39, 32)            128       \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_2 (Glob (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 8)                 264       \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 8)                 32        \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 8)                 0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 9         \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,563,265\n",
            "Trainable params: 1,563,055\n",
            "Non-trainable params: 210\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMGJtSoJ5Ftn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2.save('gdrive/My Drive/TFG/models/my_model_movie_like.h5') "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxyaibcxQlBW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Parameter space\n",
        "param_grid = dict(dropout = [0.5],\n",
        "                  filters1 = [256,512],\n",
        "                  filters2 = [256,512],\n",
        "                  kernel = [2,3],\n",
        "                  maxp = [3,5],\n",
        "                  gnup = [64,128,256],\n",
        "                  act = [\"relu\", MyLayers.gelu],\n",
        "                  epochs=[20])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aN3ce7nAkNdh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "model = KerasClassifier(build_fn = custom_model, verbose=1, batch_size = 8)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVy1mNY5Qfad",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "\n",
        "grid = RandomizedSearchCV(estimator = model, param_distributions = param_grid, verbose=2, cv = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMuazieNQoTd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "grid_result = grid.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CnXJE453d-d8",
        "colab_type": "code",
        "outputId": "cc5b5adc-ac2a-4944-e6cf-d9006839de0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "grid.best_score_"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5281385447383787"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juL129Onc-rV",
        "colab_type": "code",
        "outputId": "793eb91d-4038-4afc-bdb7-b751a37614c5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        }
      },
      "source": [
        " # summarize results\n",
        "means = pd.DataFrame(grid_result.cv_results_['mean_test_score'], columns = ['Mean'] )\n",
        "stds = pd.DataFrame(grid_result.cv_results_['std_test_score'], columns = ['SD'])\n",
        "params = pd.DataFrame(grid_result.cv_results_['params'])\n",
        "\n",
        "result = pd.concat([means, stds, params],axis = 1).sort_values(by=['Mean'], ascending=False)\n",
        "print(result.to_string(index=False))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "     Mean        SD                                         act  dropout  epochs  filters1  filters2  gnup  kernel  maxp\n",
            " 0.528139  0.009420  <function MyLayers.gelu at 0x7fd6cc6fc1e0>      0.5      20       512       512    64       3     5\n",
            " 0.518038  0.022393  <function MyLayers.gelu at 0x7fd6cc6fc1e0>      0.5      20       512       256    64       3     5\n",
            " 0.516595  0.020947  <function MyLayers.gelu at 0x7fd6cc6fc1e0>      0.5      20       512       512   128       2     3\n",
            " 0.516595  0.020947  <function MyLayers.gelu at 0x7fd6cc6fc1e0>      0.5      20       512       512   256       3     3\n",
            " 0.516595  0.020947  <function MyLayers.gelu at 0x7fd6cc6fc1e0>      0.5      20       512       512   256       2     3\n",
            " 0.516595  0.020947                                        relu      0.5      20       512       256   256       2     3\n",
            " 0.516595  0.020947                                        relu      0.5      20       256       512   128       3     5\n",
            " 0.516595  0.020947                                        relu      0.5      20       512       512   256       2     3\n",
            " 0.516595  0.020947                                        relu      0.5      20       256       256   256       3     3\n",
            " 0.516595  0.020947                                        relu      0.5      20       256       512   128       2     5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpHwseayFPeI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Model 6 Attention with LSTM\n",
        "from keras.engine.topology import Layer\n",
        "\n",
        "def dot_product(x, kernel):\n",
        "    \"\"\"\n",
        "    Wrapper for dot product operation, in order to be compatible with both\n",
        "    Theano and Tensorflow\n",
        "    Args:\n",
        "        x (): input\n",
        "        kernel (): weights\n",
        "    Returns:\n",
        "    \"\"\"\n",
        "    if K.backend() == 'tensorflow':\n",
        "        return K.squeeze(K.dot(x, K.expand_dims(kernel)), axis=-1)\n",
        "    else:\n",
        "        return K.dot(x, kernel)\n",
        "    \n",
        "\n",
        "class AttentionWithContext(Layer):\n",
        "    \"\"\"\n",
        "    Attention operation, with a context/query vector, for temporal data.\n",
        "    Supports Masking.\n",
        "    Follows the work of Yang et al. [https://www.cs.cmu.edu/~diyiy/docs/naacl16.pdf]\n",
        "    \"Hierarchical Attention Networks for Document Classification\"\n",
        "    by using a context vector to assist the attention\n",
        "    # Input shape\n",
        "        3D tensor with shape: `(samples, steps, features)`.\n",
        "    # Output shape\n",
        "        2D tensor with shape: `(samples, features)`.\n",
        "    How to use:\n",
        "    Just put it on top of an RNN Layer (GRU/LSTM/SimpleRNN) with return_sequences=True.\n",
        "    The dimensions are inferred based on the output shape of the RNN.\n",
        "    Note: The layer has been tested with Keras 2.0.6\n",
        "    Example:\n",
        "        model.add(LSTM(64, return_sequences=True))\n",
        "        model.add(AttentionWithContext())\n",
        "        # next add a Dense layer (for classification/regression) or whatever...\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,\n",
        "                 W_regularizer=None, u_regularizer=None, b_regularizer=None,\n",
        "                 W_constraint=None, u_constraint=None, b_constraint=None,\n",
        "                 bias=True, **kwargs):\n",
        "\n",
        "        self.supports_masking = True\n",
        "        self.init = initializers.get('glorot_uniform')\n",
        "\n",
        "        self.W_regularizer = regularizers.get(W_regularizer)\n",
        "        self.u_regularizer = regularizers.get(u_regularizer)\n",
        "        self.b_regularizer = regularizers.get(b_regularizer)\n",
        "\n",
        "        self.W_constraint = constraints.get(W_constraint)\n",
        "        self.u_constraint = constraints.get(u_constraint)\n",
        "        self.b_constraint = constraints.get(b_constraint)\n",
        "\n",
        "        self.bias = bias\n",
        "        super(AttentionWithContext, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        assert len(input_shape) == 3\n",
        "\n",
        "        self.W = self.add_weight((input_shape[-1], input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_W'.format(self.name),\n",
        "                                 regularizer=self.W_regularizer,\n",
        "                                 constraint=self.W_constraint)\n",
        "        if self.bias:\n",
        "            self.b = self.add_weight((input_shape[-1],),\n",
        "                                     initializer='zero',\n",
        "                                     name='{}_b'.format(self.name),\n",
        "                                     regularizer=self.b_regularizer,\n",
        "                                     constraint=self.b_constraint)\n",
        "\n",
        "        self.u = self.add_weight((input_shape[-1],),\n",
        "                                 initializer=self.init,\n",
        "                                 name='{}_u'.format(self.name),\n",
        "                                 regularizer=self.u_regularizer,\n",
        "                                 constraint=self.u_constraint)\n",
        "\n",
        "        super(AttentionWithContext, self).build(input_shape)\n",
        "\n",
        "    def compute_mask(self, input, input_mask=None):\n",
        "        # do not pass the mask to the next layers\n",
        "        return None\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        uit = dot_product(x, self.W)\n",
        "\n",
        "        if self.bias:\n",
        "            uit += self.b\n",
        "\n",
        "        uit = K.tanh(uit)\n",
        "        ait = dot_product(uit, self.u)\n",
        "\n",
        "        a = K.exp(ait)\n",
        "\n",
        "        # apply mask after the exp. will be re-normalized next\n",
        "        if mask is not None:\n",
        "            # Cast the mask to floatX to avoid float64 upcasting in theano\n",
        "            a *= K.cast(mask, K.floatx())\n",
        "\n",
        "        # in some cases especially in the early stages of training the sum may be almost zero\n",
        "        # and this results in NaN's. A workaround is to add a very small positive number ε to the sum.\n",
        "        # a /= K.cast(K.sum(a, axis=1, keepdims=True), K.floatx())\n",
        "        a /= K.cast(K.sum(a, axis=1, keepdims=True) + K.epsilon(), K.floatx())\n",
        "\n",
        "        a = K.expand_dims(a)\n",
        "        weighted_input = x * a\n",
        "        return K.sum(weighted_input, axis=1)\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape[0], input_shape[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQdIyysEFQrY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.layers import Bidirectional, CuDNNGRU, SpatialDropout1D\n",
        "from keras.layers import Bidirectional\n",
        "from keras.layers import GRU, CuDNNGRU\n",
        "\n",
        "from keras import optimizers\n",
        "from keras import backend as K\n",
        "from keras.engine.topology import Layer\n",
        "from keras import initializers, regularizers, constraints\n",
        "from keras.models import Sequential,Model\n",
        "from keras.layers import Dense, Dropout, Activation, Convolution1D, MaxPooling1D, Input, AveragePooling1D\n",
        "from keras.layers import Embedding, SpatialDropout1D, Reshape, Flatten, BatchNormalization\n",
        "from keras.layers import Conv1D, GlobalMaxPooling1D, GlobalAveragePooling1D, Concatenate\n",
        "from keras.optimizers import Adam, Adagrad\n",
        "\n",
        "def model_lstm_atten(n_embedding,gru,act1,act2,neurons):\n",
        "    inp = Input(shape=(maxlen,))\n",
        "    x = Embedding(input_dim = vocab_size, output_dim = n_embedding)(inp)\n",
        "    x = SpatialDropout1D(0.5)(x)\n",
        "    x = CuDNNGRU(gru, kernel_initializer='glorot_uniform', return_sequences=True)(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = AttentionWithContext()(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.5)(x)\n",
        "    x = MyLayers.my_dense(neurons,x,act='relu', ini='he_uniform', reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01))\n",
        "    x = MyLayers.my_dense(1,x,act='sigmoid', reg=keras.regularizers.l1_l2(l1=0.01, l2=0.01))\n",
        "    model = Model(inputs=inp, outputs=x)\n",
        "    model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "    return model\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JRudSMxBGPiz",
        "colab_type": "code",
        "outputId": "3db79adf-25c6-414c-b17f-cb034ac25344",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 642
        }
      },
      "source": [
        "model = model_lstm_atten(n_embedding=150,gru=16,act1='gelu',act2='gelu',neurons=32)\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "embedding_3 (Embedding)      (None, 100, 150)          1403100   \n",
            "_________________________________________________________________\n",
            "spatial_dropout1d_3 (Spatial (None, 100, 150)          0         \n",
            "_________________________________________________________________\n",
            "cu_dnngru_3 (CuDNNGRU)       (None, 100, 16)           8064      \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 100, 16)           64        \n",
            "_________________________________________________________________\n",
            "attention_with_context_3 (At (None, 16)                288       \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 16)                64        \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 16)                0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 32)                544       \n",
            "_________________________________________________________________\n",
            "batch_normalization_11 (Batc (None, 32)                128       \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 1)                 33        \n",
            "_________________________________________________________________\n",
            "batch_normalization_12 (Batc (None, 1)                 4         \n",
            "_________________________________________________________________\n",
            "activation_6 (Activation)    (None, 1)                 0         \n",
            "=================================================================\n",
            "Total params: 1,412,289\n",
            "Trainable params: 1,412,159\n",
            "Non-trainable params: 130\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YF5eyjHOHJVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=vocab_size, output_dim=150))\n",
        "model.add(Conv1D(64, 3, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(GlobalMaxPooling1D())\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))            \n",
        "optimizer = optimizers.Adam(lr=0.001)\n",
        "model.compile(optimizer=optimizer,loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9uRtgrdPISWN",
        "colab_type": "code",
        "outputId": "fba10ef2-48af-4739-af3d-7697b069753b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 399
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_8 (Embedding)      (None, None, 150)         1403100   \n",
            "_________________________________________________________________\n",
            "conv1d_5 (Conv1D)            (None, None, 64)          28864     \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, None, 64)          0         \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_5 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_15 (Dense)             (None, 8)                 520       \n",
            "_________________________________________________________________\n",
            "dense_16 (Dense)             (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 1,432,493\n",
            "Trainable params: 1,432,493\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Taz_Kl8tLj_S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "history = model.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    verbose=True,\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    batch_size=4,\n",
        "                    class_weight=class_weights)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gOoBJXtzWmR",
        "colab_type": "code",
        "outputId": "28c51b56-ea7a-4d53-9702-abad43962460",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.72      0.75      0.73        64\n",
            "           1       0.71      0.68      0.70        59\n",
            "\n",
            "    accuracy                           0.72       123\n",
            "   macro avg       0.72      0.71      0.71       123\n",
            "weighted avg       0.72      0.72      0.71       123\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJ1mQbvOJaQl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('nice_movie' + '_model2.h5')  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nvz8Z9-J-TRJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tmdbsimple\n",
        "\n",
        "import tmdbsimple as tmdb\n",
        "\n",
        "tmdb.API_KEY = '38dd5c6c01713ef99903275d51e2fd68'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-kzUQdq863L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_likeness(film):\n",
        "  \n",
        "  search = tmdb.Search()\n",
        "  response = search.movie(query=film,language='es-ES')\n",
        "  \n",
        "  print(response)\n",
        "  \n",
        "\n",
        "  if len(response['results']) >= 1:\n",
        "    over = response['results'][0]['overview']\n",
        "    score = response['results'][0]['vote_average']\n",
        "    \n",
        "    id_movie = response['results'][0]['id']\n",
        "    \n",
        "    movie = tmdb.Movies(id_movie)\n",
        "    \n",
        "    actors = get_actors(movie.credits()['cast'])\n",
        "    director = get_director(movie.credits()['crew'])\n",
        "    \n",
        "    over = clean_overview(str(over))\n",
        "    over = delete_stop_words(over)\n",
        "\n",
        "    over = actors + ' ' + over\n",
        "    over = director + over\n",
        "    \n",
        "    print(over)\n",
        "    \n",
        "    X_over = tokenizer.texts_to_sequences(np.array([over]))\n",
        "    X_over = pad_sequences(X_over, padding='post', maxlen=maxlen)\n",
        "\n",
        "    probability = model.predict(X_over)\n",
        "    print(probability)\n",
        "    probability = probability[0][0] * 0.75 + (score/10)*0.25\n",
        "    \n",
        "    if (probability >= 0.5):\n",
        "        pred = 1\n",
        "        print(probability)\n",
        "        if (probability < 0.5):\n",
        "          probability = 0.5\n",
        "        \n",
        "    else:\n",
        "        pred = 0\n",
        "    \n",
        "    return (str(pred) , str(probability), score/10)\n",
        "  \n",
        "  else:\n",
        "    \n",
        "    return 'No existe la peli'\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BRvFNL5nBlPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "movie = tmdb.Movies(64)\n",
        "    \n",
        "get_director(movie.credits()['crew'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYO4-m5wL3Ll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "get_likeness(\"la boda de mi mejor amiga\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuJocWX_CC8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_embds = model.layers[1].get_weights()[0]\n",
        "word_list = []\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    word_list.append(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rvDRkNV0CFrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.manifold import TSNE\n",
        "\n",
        "X_embedded = TSNE(n_components=2).fit_transform(word_embds)\n",
        "number_of_words = 1000\n",
        "trace = go.Scatter(\n",
        "    x = X_embedded[0:number_of_words,0], \n",
        "    y = X_embedded[0:number_of_words, 1],\n",
        "    mode = 'markers',\n",
        "    text= word_list[0:number_of_words]\n",
        ")\n",
        "layout = dict(title= 't-SNE 1 vs t-SNE 2 for sirst 1000 words ',\n",
        "              yaxis = dict(title='t-SNE 2'),\n",
        "              xaxis = dict(title='t-SNE 1'),\n",
        "              hovermode= 'closest')\n",
        "fig = dict(data = [trace], layout= layout)\n",
        "py.iplot(fig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fnSAd3BxBzGF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import xgboost as xgb\n",
        "\n",
        "#model = xgb.XGBClassifier(max_depth=10,n_estimators=150,silent=False,objective='binary:logistic')\n",
        "model = xgb.XGBClassifier()\n",
        "model.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR7WdupnB7pd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_score = model.predict_proba(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FcrD_SolC9Qt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install finetune"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FFzRg88aDFdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from finetune import Classifier\n",
        "\n",
        "model = Classifier()               # Load base model\n",
        "model.fit(X_train, y_train)          # Finetune base model on custom data\n",
        "y_pred = model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}